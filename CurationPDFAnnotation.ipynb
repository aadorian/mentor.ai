{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CurationPDFAnnotation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Extracción de paper using OpenAI as Exploring Guide"
      ],
      "metadata": {
        "id": "xDGP0aP_ZOMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/github/DerwenAI/spaCy_tuTorial/blob/master/Extract_Text_from_PDF.ipynb#scrollTo=iifLgV2uaMGM"
      ],
      "metadata": {
        "id": "UTfvxJhob1B5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3MvmXcsaOfI",
        "outputId": "09a9b390-2692-472b-c9fb-526558ea1b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pdfx in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: pdfminer.six==20201018 in /usr/local/lib/python3.7/dist-packages (from pdfx) (20201018)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfx) (4.0.0)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20201018->pdfx) (37.0.2)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20201018->pdfx) (2.4.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six==20201018->pdfx) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six==20201018->pdfx) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfx\n",
        "pdf = pdfx.PDFx(\"paperOAI.pdf\")\n",
        "pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93NtrkpAaToX",
        "outputId": "6afcdd81-d800-4fad-e687-de3f8a7246da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pdfx.PDFx at 0x7fc20ae80d50>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = pdf.get_text()\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "q_L2j33Fb4st",
        "outputId": "d710d012-4985-4540-ee71-b1025bdf7590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2\\n2\\n0\\n2\\n \\ny\\na\\nM\\n \\n3\\n1\\n \\n \\n]\\nL\\nC\\n.\\ns\\nc\\n[\\n \\n \\n2\\nv\\n3\\n5\\n3\\n4\\n0\\n.\\n4\\n0\\n2\\n2\\n:\\nv\\ni\\nX\\nr\\na\\n\\nShould we tweet this? Generative response modeling for\\npredicting reception of public health messaging on Twitter\\n\\nAbraham Sanders\\nRensselaer Polytechnic Institute\\nTroy, New York, USA\\nsandea5@rpi.edu\\n\\nJohn S. Erickson\\nRensselaer Polytechnic Institute\\nTroy, New York, USA\\nerickj4@rpi.edu\\n\\nDebjani Ray-Majumder\\nRensselaer Polytechnic Institute\\nTroy, New York, USA\\nraymad@rpi.edu\\n\\nKristin P. Bennett\\nRensselaer Polytechnic Institute\\nTroy, New York, USA\\nbennek@rpi.edu\\n\\nABSTRACT\\nThe way people respond to messaging from public health organiza-\\ntions on social media can provide insight into public perceptions\\non critical health issues, especially during a global crisis such as\\nCOVID-19. It could be valuable for high-impact organizations such\\nas the US Centers for Disease Control and Prevention (CDC) or\\nthe World Health Organization (WHO) to understand how these\\nperceptions impact reception of messaging on health policy recom-\\nmendations. We collect two datasets of public health messages and\\ntheir responses from Twitter relating to COVID-19 and Vaccines,\\nand introduce a predictive method which can be used to explore\\nthe potential reception of such messages. Specifically, we harness\\na generative model (GPT-2) to directly predict probable future re-\\nsponses and demonstrate how it can be used to optimize expected\\nreception of important health guidance. Finally, we introduce a\\nnovel evaluation scheme with extensive statistical testing which\\nallows us to conclude that our models capture the semantics and\\nsentiment found in actual public health responses.\\n\\nCCS CONCEPTS\\n• Computing methodologies → Discourse, dialogue and prag-\\nmatics; • Information systems → Sentiment analysis.\\n\\nKEYWORDS\\ntweet response generation, sentiment analysis, public health, COVID-\\n19, vaccines\\n\\n1 INTRODUCTION\\nDuring the COVID-19 pandemic, Twitter and other social media\\nmessaging by public health organizations played a significant role\\nin their strategies to enact proposed mitigations to potential risks\\nwith varying effectiveness [23]. As such, recent works have focused\\non topical, semantic, and sentiment analysis of COVID-19 and vac-\\ncine related Twitter discourse, many leveraging natural language\\nprocessing (NLP) technologies. For example, Sanders et al. [20]\\nclustered tweets relating to mask-wearing in the early days of the\\nCOVID-19 pandemic to discover prevalent themes, perceptions, and\\nsentiments. Cotfas et al. [7] applied machine learning for vaccine\\nstance detection using tweets collected in the month following the\\nannouncement of a COVID-19 vaccine. Our study follows similar\\nmotivation - to investigate the way the general population reacts\\n\\nto messaging from major public health agencies (e.g., US CDC, Eu-\\nropean CDC, and WHO) on a variety of topics including COVID-19\\nand vaccines. Unlike previous work in this area, we investigate the\\nfeasibility and utility of using state-of-the-art text generation models\\nto directly simulate typical response distributions to novel public\\nhealth messages on Twitter. These simulations, combined with sen-\\ntiment analysis, can be used to help public health organizations\\nunderstand the specific opinions and concerns of their audience in\\norder to develop more effective health messaging strategies.\\n\\nIn this study, we collect two datasets of public health tweets: (1)\\nCOVID-19 related public health messages from March 1st, 2020 to\\nSeptember 30th, 2020, and (2) vaccine-related public health mes-\\nsages from October 1st, 2021 to January 31st, 2022. These datasets\\ninclude the original messages and samples of their responses, both\\nin the form of direct replies and quote-tweets (retweets with com-\\nments). Using each dataset, we fine-tune a GPT-2 [16] language\\nmodel to predict responses to the public health tweets and evaluate\\nits effectiveness in terms of semantic and sentiment similarity with\\nknown responses. To evaluate the models, we establish “ground-\\ntruth” baselines for semantics and sentiment on each dataset by\\ncomparing two distinct samples of known responses to each mes-\\nsage. We also establish “random-chance” baselines by likewise com-\\nparing each sample of known responses with a sample of random\\nresponses for any message in each dataset. We then use our models\\nto generate responses to each test message compare them with the\\nknown response samples. Through rigorous statistical testing we\\nfind that our models are able to generate responses consistent with\\nknown samples in terms of semantics and sentiment. Thus, insights\\non perceptions toward particular public health issues can be gained\\nfrom analyzing the generated response distributions. We envision\\nour methods being able to aid public health decision makers and\\nsocial media content managers proactively model how the public\\nwill react to future messages, increasing the likelihood that their\\ntweets are well received and have the intended impact.\\n\\nThe remainder of this paper is organized as follows: (1) we\\npresent two datasets of Twitter public health messages and their\\nresponses, one related to COVID-19 and one related to Vaccines; (2)\\nwe fine-tune GPT-2 to generate responses on each of these datasets,\\nand construct upper (ground-truth) and lower (random-chance)\\nbound baselines against which to evaluate it; (3) we visually demon-\\nstrate the capabilities of our models using test set examples and\\n\\n\\x0cTable 1: Public health account screen names\\n\\nEuropean CDC Accounts 4\\n\\nESCAIDE ECDCPHT ecdc_tb ECDC_VPD ECDC_HIVAIDS ecdc_flu ECDC_Outbreaks ecdc_eu\\nU.S. CDC Accounts 5\\n\\ncdcgov cdcdirector CDC_eHealth CDCespanol BRFSS CDCasthma CDC_DASH CDCDiabetes\\ncdc_drh CDCEnvironment CDC_Cancer CDC_EIDjournal CDC_EPHTracking CDC_Genomics\\nCDC_HIVAIDS CDCMicrobeNet CDC_NCBDDD CDC_NCEZID CDC_TB CDC_AMD\\nCDCChronic CDCEmergency CDCFlu CDCGlobal CDCGreenHealthy CDCHaiti\\nCDCHeart_Stroke US_CDCIndia CDChep CDCInjury CDCKenya CDCMakeHealthEZ\\nCDCMMWR CDCNPIN CDCObesity cdcpcd CDCRwanda CDCsouthafrica CDCSTD\\nCDCTobaccofree CDCTravel CPSTF DrDeanCDC DrKhabbazCDC DrMartinCDC\\nDrMerminCDC DrNancyM_CDC DrReddCDC MillionHeartsUS NCHStats niosh NIOSHMining\\nNIOSH_MVSafety NIOSH_NPPTL NIOSH_TWH nioshbreathe NIOSHConstruct NIOSHespanol\\nNIOSHFACE nioshfishing nioshnoise NIOSHoilandgas WTCHealthPrgm\\n\\nOther Public Health Accounts\\n\\nWHO InjectionSafety\\n\\nwalk through our envisioned public health use case; (4) we per-\\nform extensive statistical testing to compare our models against\\nthe baselines, finding that GPT-2 can effectively capture semantics\\nand sentiment in typical response distributions to messages in our\\ntest sets; and (5) we conclude with a discussion of limitations and\\nfuture directions of our work including a review of related works\\nfrom the natural language generation (NLG) literature. We have\\nreleased our data and code on GitHub, 1 and, in compliance with the\\nTwitter content redistribution policy,2 we only publish the tweet\\nIDs corresponding to the actual tweets used in this work.\\n\\n2 DATA COLLECTION\\nAs in [20], we used the Twitter streaming API to collect a random\\nsample of tweets during the collection periods for each respective\\ndataset (COVID-19 & Vaccine public health messages). We collected\\nthese datasets by filtering the streaming API using COVID-19 and\\nVaccine related keywords, respectively. Since we aim to study the\\nresponse distributions to public health tweets, we focus only on\\nthose tweets which have responses either in quote-tweet or direct\\nreply form. Collection of these tweets and their responses was done\\nvia Tweepy, a python library for accessing the Twitter API, and they\\nwere stored in Elasticsearch3 for efficient search and retrieval. Each\\ndataset was then filtered by screen name to include only tweets from\\npublic health organizations and their responses. The organizations\\nselected and their respective accounts are shown in Table 1.\\n\\n2.1 COVID-19 Public Health Messaging\\nOur dataset of COVID-19 related public health messages and their\\nresponses contains 8,475 original messages authored by these ac-\\ncounts and 70,331 responses to these messages. The original mes-\\nsages were authored between March 1st, 2020 and September 30th,\\n2020. The majority of the collected tweets originate from the WHO\\naccount, followed by CDCgov, as seen in Figure 1. This data was\\ncollected as follows: (1) We collected 295,468,580 original tweets\\nfrom the Twitter Streaming API over the collection period using\\nthe same set of COVID-19 related filter keyphrases as used in [20];\\n\\n1Available at https://github.com/TheRensselaerIDEA/generative-response-modeling\\n2See https://developer.twitter.com/en/developer-terms/agreement-and-policy\\n3See https://www.elastic.co/elasticsearch\\n4See https://www.ecdc.europa.eu/en/about-us/press-and-media/ecdc-social-media\\n5See https://www.cdc.gov/socialmedia/tools/Twitter.html\\n\\nFigure 1: Top ten public health accounts by number of tweets for\\nthe COVID-19 and Vaccines datasets.\\n\\n(2) These tweets were filtered to keep only those that were in re-\\nsponse to (either via quote or direct reply) a message from one of\\nthe public health accounts in Table 1; (3) As the streaming API re-\\nturned quoted tweets but not (direct) replied-to tweets, these were\\nseparately requested using the Twitter Status API.\\n\\n2.2 Vaccine Public Health Messaging\\nOur dataset of Vaccine related public health messages and their re-\\nsponses contains 3,060 original messages authored by the accounts\\nin Table 1 and 61,009 responses to these messages. The original\\nmessages were authored between October 1st, 2021 and January\\n31st, 2022. The majority of the collected tweets originate from the\\nWHO account, followed by CDCgov, as is the case in the COVID-19\\ndataset (see Figure 1). This dataset was collected by the same proce-\\ndure outlined for the COVID-19 dataset in Section 2.1, with the only\\ndifference being the filter keyphrases. Here, all filter keyphrases\\nwere vaccine related, selected by doing a term-frequency analy-\\nsis on a random sample of approximately 10,000 tweets collected\\nusing the keyphrase “vaccine” (see our code release for complete\\nlisting). Using these keyphrases we collected 52,282,174 original\\ntweets before filtering for responses to the public health accounts.\\n\\n3 EXPERIMENTAL SETUP\\nAs discussed in Section 1, we train GPT-2 on the task of tweet\\nresponse generation. This task is notably different from other text\\ngeneration tasks in that it suffers from an extreme form of the\\none-to-many problem seen in dialogue response generation, where\\nan utterance can have many equally valid responses [8, 10, 24].\\nSpecifically, each public health message in our datasets has multiple\\nresponses, and we train GPT-2 to model the distribution of typical\\nresponses for each message. This means that the same message\\nfrom the same author is repeated many times in the training set,\\neach instance with a different target response. Once trained in this\\nmanner, temperature sampling can be used to generate a range of\\nlikely responses to an input author and message.\\n\\nAs previously mentioned, we evaluate this method by comparing\\nmodel-generated responses to known responses. Specifically, given\\na known sample of responses to a particular message and author,\\nwe need to determine how well a model-generated sample of re-\\nsponses captures the semantics (e.g., meaning, topic, intent) and the\\nsentiment polarity (e.g., positive, negative, neutral) of the known\\nresponses. This is akin to measuring retrieval recall - how well the\\nmodel-generated response distribution “covers” that of the ground-\\ntruth. To measure sentiment we use a publicly available RoBERTa\\n\\n2\\n\\n\\x0cTable 2: Training & Test set statistics\\n\\nTable 3: GPT-2 training & inference examples\\n\\nCOVID-19 Public Health dataset\\n\\nSet\\n\\n# of messages.\\n\\nTrain\\nTest\\n\\n7,860\\n155\\n\\nVaccine Public Health dataset\\n\\n# of responses Avg. # resp. per msg.\\n5 ± 8∗\\n60∗∗\\n\\n39,020\\n9,300\\n\\nSet\\n\\n# of messages.\\n\\n# of responses Avg. # resp. per msg.\\n\\n2790\\n140\\n\\nTrain\\nTest\\n*: Mean ± standard deviation, both rounded to the nearest integer.\\n**: Exactly 60 responses were sampled for each message in the test set.\\n\\n27,878\\n8,400\\n\\n10 ± 16∗\\n60∗∗\\n\\n[13] model6 fine-tuned on the sentiment classification task of the\\nTweetEval benchmark [3]. We score the sentiment of each message\\nand response in our datasets in the range [−1, 1] by multiplying\\nthe sentiment class probabilities predicted by RoBERTa for nega-\\ntive, neutral and positive by {−1, 0, 1} respectively and summing\\nthe result. To measure semantic similarity we compute sentence\\nembeddings for each message and response in our datasets, and\\nmeasure cosine similarity between embeddings. To compute the\\nembeddings we use a publicly available MiniLM [22] model7 fine-\\ntuned for semantic textual similarity using a contrastive objective\\non over one billion training pairs from 32 distinct datasets.\\nWe now provide details of our experimental set up.\\n\\n3.1 Train / Test Split\\nFor each dataset, we set aside a test set of public health messages\\nincluding all messages with at least 60 responses. For all experi-\\nments we choose a sample size of 30 responses, ensuring that we\\ncan randomly select two distinct samples for the ground-truth base-\\nline. We clean the message text by removing hyperlinks and emojis,\\nand remove all messages that are duplicated by the same author.\\nThis last step is taken since responses to duplicated messages often\\ndepend on external context beyond the message itself such as a\\nhyperlink or embedded entity which may vary between the dupli-\\ncates. As such, a model trained on message text alone is unlikely to\\naccurately predict responses to such messages.\\n\\nAfter setting aside the test set, the remainder of the message-\\nauthor-response triples in each dataset are used for fine-tuning GPT-\\n2. As done for the test set, we clean the message and response text by\\nremoving hyperlinks and emojis, and remove duplicated messages\\nfrom the same authors. Unlike the test set, we allow one instance\\nof each duplicated message (along with its responses) to remain in\\nthe training set. As a final step, we remove any remaining message\\nfrom the training set that is identical in content to a message in the\\ntest set. Statistics for the training and test sets for the COVID-19\\nand Vaccine datasets are provided in Table 2.\\n\\n3.2 Response Generation Model\\nWe then fine-tune the 762 million parameter GPT-2 model8 on\\nthe response generation task. Each training example consists of a\\npublic health message, the author account’s screen name, and one\\nresponse, delimited by three special tokens we add to the model’s\\n\\n6Obtained from https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment\\n7Obtained from https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2\\n8Obtained from https://huggingface.co/gpt2-large\\n\\n3\\n\\nTraining Examples:\\n\\n<|message|>Is your child worried about #COVID19? Learn the facts so you can answer your\\nchildren’s questions. Make sure to explain the simple things they can do, like washing their\\nhands often. Learn more here:<|author|>CDCgov<|response|>Great resource for parents and\\nteachers. #COVID19 #ProtectKidsHealth<|endoftext|>\\n\\n<|message|>How children can #WearAMask properly. Read more about children & masks in\\nrelation to #COVID19<|author|>WHO<|response|>How long back into school until kids are\\ntrading their avengers masks like pogs?<|endoftext|>\\n\\n<|message|>How children can #WearAMask properly. Read more about children & masks in\\nrelation to #COVID19<|author|>WHO<|response|>Children do not need to wear masks!\\nGet lost!!<|endoftext|>\\n\\nInference Example (not actual model output):\\n\\nPrompt: <|message|>How will people respond to THIS?<|author|>CDCdirector<|response|>\\nOutput sample 1: Like this! <|endoftext|>\\nOutput sample 2: And this! <|endoftext|>\\n. . .\\nOutput sample N: #DefinitelyThis. <|endoftext|>\\n\\nTable 4: Model training statistics\\n\\nDataset\\n\\n# of train ex.\\n\\n# of val ex.\\n\\n# of epochs\\n\\nFinal val PPL.\\n\\nCOVID-19\\nVaccines\\n\\n35,118\\n25,090\\n\\n3,902\\n2,788\\n\\n2\\n2\\n\\n3.36\\n2.82\\n\\nex = examples; val = validation; PPL = perplexity\\n\\nvocabulary: (1) <|message|> to indicate the following text is the\\npublic health message; (2) <|author|> to indicate the following text\\nis the screen name of the message author; and (3) <|response|> to\\nindicate the following text is a response to the message. At inference\\ntime, this enables generated response samples to be conditioned on\\nthe message text and author by prompting GPT-2 with the message\\nand author followed by a <|response|> token as seen in Table 3.\\n\\nBefore fine-tuning, 10% of the training set is held out as a val-\\nidation set. Fine-tuning is then done with the AdamW optimizer\\n[15] with an initial learning rate of 3 × 10−5 for a maximum of 15\\nepochs. Validation and checkpointing is done 4 times per epoch, and\\ntraining is terminated early if three epochs elapse with no improve-\\nment in validation loss. Once training completes, the checkpoint\\ncorresponding to the lowest validation perplexity is selected as the\\nfinal model. We train separate GPT-2 models on the COVID-19 and\\nVaccine datasets and report training statistics for both in Table 4.\\nAfter training, each fine-tuned model is used to generate 30\\nresponses to each message in its respective test set. All genera-\\ntion is done with beam sampling using num_beams=3, top_k=50,\\ntop_p=0.95, and temperature=1.5.\\n\\n3.3 Evaluation & Baselines\\nFinally, we use the test set of each dataset to establish the ground-\\ntruth and random-chance baselines which function as expected\\nupper and lower bounds, respectively, for semantic and sentiment\\nsimilarity measurements. For each message in the test set, we sam-\\nple: (1) 60 known responses, and (2) 30 responses to random mes-\\nsages in the dataset. The 60 known responses are split into two\\ndistinct “ground-truth” sets - a Primary set and a Reference set\\nused for establishing a baseline. Thus, for each test message we\\ncompare the 30 primary ground-truth responses with:\\n\\n(1) the 30 reference responses (ground-truth baseline).\\n(2) the 30 model-generated responses (model evaluation).\\n\\n\\x0cFigure 2: An illustration of our model evaluation scheme for a single test message. For each test message, N=30 generated responses are com-\\npared with the primary ground-truth sample of N=30 known responses. The sentence embeddings and sentiment scores for each response are\\nthen used to perform statistical testing for semantic and sentiment similarity. The ground-truth and random-chance baselines are computed\\nthe same way, replacing the generated responses with the reference ground-truth and random response samples respectively.\\n\\n(3) the 30 random responses (random-chance baseline).\\n\\nFigure 2 illustrates this evaluation scheme. As shown, we use several\\nstatistical tests to measure semantic and sentiment similarity for\\nthe baselines and for model evaluation. Details of these tests and\\ntheir results are provided in Section 5.\\n\\n4 QUALITATIVE RESULTS\\n4.1 Model Output Examples\\nIn Figure 3 we show primary ground-truth and model-generated re-\\nsponses for two messages from each test set (COVID-19 & Vaccines).\\nFor each message, we show the top five ground-truth responses\\nranked in descending order of mean cosine similarity (defined in\\nSection 5) with the model-generated responses, and likewise we\\nshow the top five model-generated responses ranked in descending\\norder of mean cosine similarity with the ground-truth responses.\\nThis filtering and ordering is done for the sake of brevity as it is not\\npractical to fit all 60 × 4 responses in this document. We observe\\nthat the generated responses capture many of the same opinions\\nand concerns present in the known responses. We summarize some\\nof the key similarities evident in the examples:\\n\\nThe first example shows a test message from the COVID-19\\ndataset where CDCDirector recommends that schools can re-open\\nsafely. The known and generated responses both exhibit themes of\\nmistrust toward the CDC (shown in red), allegations of bowing to\\nthe Trump administration (shown in orange), implication of shame\\nand disgrace toward the CDC (shown in purple), concern for the\\nwell-being of school children (shown in brown), and references\\nto loss of former respect (shown in blue). The second example\\nshows a test message from the COVID-19 dataset where WHO calls\\nfor unity in the face of the pandemic. The known and generated\\n\\n4\\n\\nresponses both exhibit themes of mistrust toward the WHO (shown\\nin red) and allegations of conspiracy with China (shown in blue).\\nThe third example shows a test message from the Vaccines dataset\\nwhere CDCgov urges pregnant people and those planning to get\\npregnant to get vaccinated against COVID-19. The known and\\ngenerated responses both exhibit themes of concern for the effects\\non unborn children (shown in red), concern for the vaccines getting\\nFDA approval (shown in brown), and feelings of encouragement\\ntoward the recommendation (shown in blue). The fourth example\\nshows a test message from Vaccines where CDCDirector discusses\\nupdating pediatric vaccine recommendations to include children\\n5-11 years old. The known and generated responses both exhibit\\nfeelings of gratefulness and acknowledgement of the importance\\nof pediatric vaccination (shown in red).\\n\\n4.2 Envisioned Use Case Walk-through\\nWe anticipate that public health organizations may find value in\\nbeing able to “preview” public reception to any potential message\\non health policy or recommendations. As such, we envision our\\nmethod being incorporated as a social media insights tool that\\ncan help avoid negative receptions where possible with the aim to\\nimprove adherence to health guidance.\\n\\nTo demonstrate this use case, we invent a tweet encouraging\\nvaccination against COVID-19 and we suppose it is being consid-\\nered by the ECDC_EU content manager for future public release.\\nWe first use the generator model trained on the Vaccines dataset\\nto predict a set of 30 responses. We then modify the tone of the\\nmessage to reduce directness and implication of personal respon-\\nsibility and use it to generate a new set of 30 responses. We use\\nthe RoBERTa sentiment classifier to score each response in both\\nsets and compute the mean and standard deviation over the scores\\n\\n\\x0cMessage (CDCDirector; COVID-19 dataset):\\nTogether, we can open schools safely. This fall, school may look different in some communities b/c of #COVID19 as face masks, distancing, & hand hygiene meet bookbags & homework.\\n\\nNew CDC tools will help us make decisions for the upcoming school year.\\n\\nPrimary ground-truth responses:\\n@CDCDirector @CDCgov Shame on you and the @CDC. Trump canceled the @GOP convention, but it’s just fine sending our kids back to school. The curve has NOT been flattened\\n\\nand we are trending in the wrong direction, but send kids back to school? What has happened to the once great CDC? Shameful.\\n\\n@CDCDirector @CDCgov Sad to see the once esteemed CDC become the patsy of an administration that doesn’t respect or understand data. Luckily, the American public does seem\\n\\nto understand death tolls.\\n\\n@CDCDirector @CDCgov CDC is misleading America parents and putting children’s in great harm with its new guidelines for schools during this pandemic. There’s not enough data\\n\\nto support younger children’s are less likely to contract and spread this virus. YOU ARE PLAYING GOD.\\n\\n@CDCDirector @CDCgov We the people are wondering if the cdc is taking bribes to cook the books....\\n@CDCDirector @CDCgov But the Republican Convention is not safe? The CDC is supposed to protect the American people and not do one person’s bidding.\\n\\nRemember your Hippocratic oath do no harm\\n\\nGenerated responses:\\n@CDCDirector @CDCgov The CDC has lost its credibility. You should be removed immediately. You are not leading. You are a Trump puppet. Resign.\\n@CDCDirector How do you expect schools to be safe when you keep changing the testing recommendations? You are not a doctor, you are a politician. You have\\n\\ndestroyed the credibility of the CDC. Resign!\\n\\n@CDCDirector You should be removed from office immediately. You are a disgrace to the once respected CDC.\\n@CDCDirector @CDCgov Why are you putting children at risk? You say it will be safe, but you also say it will be deadly for children to be in schools. The CDC needs to be\\n\\n@CDCDirector @CDCgov Why is your department still pushing for more testing? You are a disgrace to the once respected CDC by not standing up for science and the American people.\\n\\ndismantled and put in place someone who can be trusted. You’re a disgrace.\\n\\nYou are complicit in thousands of deaths! Stand up to Trump and do your job!\\n\\nMessage (WHO; COVID-19 dataset):\\n“#COVID19 has taken so much from us, but it has also given us a unique opportunity: -To put aside our differences -To break down barriers -To see and seek the best in each other -To lift\\n\\nour voices for #HealthForAll”-@DrTedros during the One world, #TogetherAtHome\\n\\nPrimary ground-truth responses:\\n@WHO @DrTedros \"#COVID19 has taken so much from us, but it has also given us a unique opportunity: -To reveal the corruption and incompetence of @WHO -To have a glimpse to\\n\\n@WHO @DrTedros Why not let China fund your escapades? You can’t have solidarity with people or an organization you don’t trust. #ChinaLiedPeopleDied #WHOLiedPeopleDied\\n\\nthe dictatorship of the CCP\\n\\n#DefundWHO #CCPVirus #XiJinping #winnietheflu\\n\\n@WHO @DrTedros Keep the meaningless platitudes coming, I’m sure that’s the key to stopping this pandemic you opened the door to through your pandering to China. Bang up job.\\n@WHO @DrTedros Let’s be inclusive and include ! Amazing that the country EXCLUDED from the @WHO handed the Wuhan Virus the best.\\n@WHO @DrTedros -To shill for china\\n\\nGenerated responses:\\n@WHO @DrTedros How dare you chime in on a global pandemic with the help of China in the middle of a global economic crisis. The Chinese Communist Party should be held\\n\\nfully accountable for this global tragedy.\\n\\n@WHO @DrTedros #ChinaLiedPeopleDied China should be brought up on charges for this global pandemic. We need justice.\\n@WHO @DrTedros WHO and CHINA LIED and PEOPLE DIED! INVESTIGATE\\n@WHO @DrTedros The Chinese are not your friend. You should be kicked out of every country of the world. You are the cause of this global crisis.\\n@WHO @DrTedros @DrTedros, you must resign! You are a disgrace and a danger to the world! The whole world is suffering from your failures! China is suffering from you!\\n\\nMessage (CDCgov; Vaccines dataset):\\nURGENT: If you are pregnant, recently pregnant, or plan to get pregnant, get vaccinated against #COVID19 as soon as possible. Getting vaccinated can protect you from severe illness from\\n\\nCOVID-19, and a healthy parent is important for a healthy baby. More:\\n\\nPrimary ground-truth responses:\\n@CDCgov My pregnant WIFE, will not be getting vaccinated. Not enough studies on how it will affect our soon to be son!\\nIt is alarming to see that only 31% of pregnant people are vaccinated, but it is encouraging to see the CDC speak out about the importance of pregnant people receiving\\n\\ntheir Covid-19 vaccine. #GburgGHFall21\\n\\n@CDCgov Do you not even care about the pregnant men that can die? What’s the statistics on that? Why aren’t you encouraging them to get the vaccine???\\nToday: @CDC recommends #COVID19Vaccine if you’re pregnant, recently pregnant, or plan to get pregnant. #ArmyMedicine #InThisTogether\\n@CDCgov @CDPHE How did the FDA categorize the Covid vaccines? Category C? Has to be a C. Let’s see those studies - oh wait you are doing them NOW! Criminal\\n\\nGenerated responses:\\n@CDCgov So why are pregnant women and people who have already had covid vaccinated against covid sick and dying?\\n@CDCgov What about the babies that are being born after these vaccines?\\n@CDCgov What about the pregnant women who get vaccinated and then get covid and die? The babies? Who’s going to pay for this?\\nThe @CDCgov is telling pregnant women to get vaccinated, but the @US_FDA has not authorized or recommended it for pregnant women. When will the @CDCgov and @CDCDirector\\n\\ndo their jobs and approve COVAXIN?\\n\\n#Pregnant people: Get vaccinated against #COVID19 if you’re pregnant. #Gratitude #WeArePalmGarden\\n\\nMessage (CDCDirector; Vaccines dataset):\\nToday, I endorsed ACIP’s recommendation that children 5-11 yrs old should be vaccinated against #COVID19 w/ Pfizer-BioNTech pediatric vaccine. This expands vaccine recommendations to\\n\\nover 28M kids in US & now allows providers to begin vaccinating them.\\n\\nPrimary ground-truth responses:\\n@CDCDirector Do not vaccinate children with this cv vaccine. They have natural immunity and the vax doesn’t work. HCG and Ivermetin does. Leave the Children alone you monsters\\nIt has happened. I am grateful for your efforts in keeping out children safe! #cdc #Covid19vaxxed #COVIDVaccination #safe\\nAll 5-11 year old - let go, line up and get vaccinated against #Covid19. Help make this world #Covid19 free!\\nChildren 5-11 years old are now authorized to receive the Pfizer COVID vaccine. A huge step forward in our continued to efforts to combat COVID and keep our kids safe.\\n\\nGenerated responses:\\n@CDCDirector @CDCgov What about the kids who are not eligible for the vaccine? When are you going to talk about that? What are you waiting for?\\n@CDCDirector @ACIP When can kids under 5 get the vaccine? It is the most important vaccine for them.\\nThank you @CDCgov for recommending this vaccine for children! We now need to support the @US_FDA and @NIH to approve this vaccine for 5-11 year olds. We can’t simply hope for the\\n\\n@CDCDirector Please Protect: Yourself Your Family Other People Get Fully #Vaccinated Against: #COVID19 #Influenza / Flu Measles, Mumps, Polio, HPV, etc Wear a Mask Public Places Public\\n\\npandemic to end on its own.\\n\\nTransportation Wash Your Hands @CDCgov\\n\\nFigure 3: Example generated responses to test set messages on both datasets. Elements of each response that share similar themes are high-\\nlighted with the same color (e.g., red text in the first example indicates mistrust and red text in the last example indicates gratefulness). We\\nobserve that the generated responses capture many of the same opinions and concerns as the primary (known) responses.\\n\\n5\\n\\n\\x0cMessage (ECDC_EU; Avg. response sentiment: −0.253 ± 0.491):∗\\nIt is your duty and responsibility to get vaccinated. It is the only way to finally end this pandemic.\\n\\nGenerated responses:\\n@ECDC_EU Vaccines don’t work, unless you can prove otherwise, and you can’t prove that they don’t work. You can kill me with a vaccine and the FDA won’t investigate.\\n\\nWhy are you still allowed to promote this poison?\\n\\n@ECDC_EU So you are telling me that if I get vaccinated with #COVAXIN, the virus will be eliminated in the world? I don’t think so.\\n@ECDC_EU You need #COVAXIN to end this pandemic.\\nIt is your duty to get vaccinated. It is the only way to finally end this pandemic. #N564Health\\n@ECDC_EU The only way to end this pandemic is to do the opposite of what the EU does. Approve Covaxin, and end the pandemic. There’s absolutely no justification for the EU to do the opposite\\n\\nof what the US does. Approve #covaxin and help end this pandemic.\\n\\n@ECDC_EU The vaccine is not as good as the previous two vaccines. It’s better to get sick and die than not get the vaccine.\\n@ECDC_EU @WHO_Europe @EU_Health @EFSA_EU @EU_Commission @Eurosurveillanc @EU_ECHA @EMA_News @Eurosurveillanc @EU_opendata @EU_EESC @eupatientsforum\\nNot the vaccine but self-discipline to obey the SOP. Do not use vaccine to threaten people. Not funny poking people with needle. It is a crime against human rights for any government\\nto force people to take an experimental drug. Test is the more effective\\n\\n@ECDC_EU Vaccinated people are dying and spreading covid. They are also spreading the vaccine. The vaccinated are dying and spreading covid. The vaccinated are spreading the vaccine.\\n\\nThe vaccinated spread covid. The vaccinated spread covid.\\n@ECDC_EU How many of your staff have already had the jab?\\n@ECDC_EU So is your duty to put all of those deaths and injuries and long term health problems into the vaxx numbers?\\nModified message (ECDC_EU; Avg. response sentiment: 0.218 ± 0.632):∗\\nThank you for doing your part by getting vaccinated! Together we can finally end this pandemic.\\n\\nGenerated responses:\\n#VaccinesWork to save lives and protect economies. Don’t delay, vaccinate today! #VaccinesSaveLives\\n@ECDC_EU @EU_Health @EU_Commission @SKyriakidesEU @vonderleyen @EU_ECHA @EMA_News @EU_Commission @Eurosurveillanc @EU_Health @EFSA_EU Approve Covaxin\\nWe can end #COVID19 by getting vaccinated! Together we can finally end this pandemic. #VaccinesWork\\n@ECDC_EU How does this help the end of the pandemic? How does this help the world\\n\\nwhen we can no longer produce vaccines? How does this help reduce the transmission of the virus? What is wrong with you?\\n\\n@ECDC_EU I have taken the 2 Pfizer, 1 Moderna and 1 Janssen vaccines. I have received my booster shot and I am awaiting my 2nd shot. What can I do to ensure that I am protected against\\n\\nCovid-19 and will be able to get my 2nd shot?\\n\\n#VaccinesWork to save lives. Don’t delay, vaccinate today! #VaccinesSaveLives\\nWe can end this pandemic! We have the tools to do it! Get the #COVID19 vaccine as soon as you can!\\nThank you for doing your part #VaccinEquity\\n@ECDC_EU The vax doesn’t work at all! Why are you still pushing it?\\n@ECDC_EU @EU_Health @SKyriakidesEU @EMA_News @EU_Commission @Eurosurveillanc @EU_ECHA @EFSA_EU @EU_CoR @EUCouncil @Europarl_EN Approve #COVAXIN\\n\\n*: First 10 of 30 shown. Sentiment mean and std. dev. computed across all 30 responses.\\n\\nFigure 4: Use case: ECDC_EU considers a “future” message for public release. The Vaccines model anticipates a more positive reception after\\nthe message is reworded to reduce directness and implication of personal responsibility. The modified message text is highlighted in red.\\n\\nin each set. In Figure 4, we show the effect of the modification:\\nthe mean sentiment increases by 0.47 on the scale of [-1, 1]. The\\nstandard deviation also increases, indicating that the responses\\ncontinue to retain examples of negative concerns (they just become\\nless prevalent). We highlight the modified portion of the message in\\nred and show the first ten examples from each set to help illustrate\\nthe achieved difference.\\n\\nThe proposed methods may also be generalized beyond public\\nhealth - any organization with a presence on Twitter may tailor\\nour method to their requirements by indexing their existing tweets\\nand their responses in Elasticsearch and then fine-tuning GPT-2.\\nWe also note that our method is easily adaptable to other social\\nmedia platforms beyond Twitter, as long as a mechanism exists in\\nthe platform for public response (e.g., Reddit).\\n\\n5 QUANTITATIVE RESULTS\\nWe now describe in detail our statistical testing, the purpose of\\nwhich is to confirm that our models capture the true semantic and\\nsentiment distributions of known responses as we expect.\\n\\n5.1 Semantic Similarity\\nFor each test message, we aim to establish if the model generates\\nresponses that capture the semantics (e.g., meanings, topics, in-\\ntents) present in the known responses. To do so, we compute the\\nmax pairwise cosine similarity between the sentence embedding\\nof each known primary ground-truth response and those of the\\nreference, generated, and random responses. This yields three sets\\nof 30 max cosine similarity values for each test message - one for\\n\\n6\\n\\nthe ground-truth baseline, one for the model evaluation, and one\\nfor the random-chance baseline. We choose max instead of mean\\ncosine similarity so that primary ground-truth responses will be\\nconsidered “covered” by the model if at least one similar response\\nshows up in the generated sample [10]. We then perform three sta-\\ntistical tests on each set to compare the model with the baselines: (1)\\nthe Area Under Regression Error Characteristic Curve (AUC-REC)\\n[4] to compare the expected cosine similarity error for the model\\nand baselines; (2) a two-tailed paired t-test to compare the average\\nmax cosine similarity between the model and baselines; and (3) a\\nPearson’s correlation between the max cosine similarity values of\\nthe model and those of the baselines.\\n\\n5.1.1 AUC-REC. We introduce the AUC-REC approach for assess-\\ning semantic similarity of the primary, reference, generated, and\\nrandom response sets. Regression Error Characteristic (REC) curves\\ngeneralize the principles behind the Receiver Operator Character-\\nistic (ROC) curves to regression models [4]. The ROC curve is\\ntypically used to present the quality of a binary classification model\\nby comparing its true-positive rate (along the y-axis) to its false-\\npositive rate (along the x-axis). The area under the resulting curve\\n(AUC-ROC) is a metric that summarizes the extent to which the\\nclassifier can correctly identify positive examples without mistak-\\ning negative examples as positive. The REC curve applies a similar\\npremise to regression models: for each of an increasing series of\\nerror tolerances (along the x-axis) it shows the “accuracy” of the\\nmodel within that tolerance (along the y-axis). Specifically, the\\naccuracy is the percentage of examples for which the continuous\\ntarget value can be predicted within the given error tolerance. The\\n\\n\\x0cTable 5: Semantic Similarity: AUC-REC Results\\n\\nComparison\\n\\nALL WHO CDCgov\\n\\nCDCDirector\\n\\nCOVID-19 dataset\\n\\nPrimary vs. Reference\\nPrimary vs. Model\\nPrimary vs. Random\\nModel % Difference∗\\nVaccines dataset\\n\\n0.571\\n0.539\\n0.458\\n\\n0.565\\n0.517\\n0.442\\n\\n0.558\\n0.544\\n0.466\\n\\n71.7%\\n\\n61.0%\\n\\n84.8%\\n\\n0.610\\n0.595\\n0.500\\n\\n86.4%\\n\\nComparison\\n\\nALL WHO CDCgov\\n\\nCDCDirector\\n\\nPrimary vs. Reference\\nPrimary vs. Model\\nPrimary vs. Random\\nModel % Difference∗\\n*: Model % Difference: 100 * (Model - Random) / (Reference - Random)\\n\\n0.653\\n0.620\\n0.546\\n\\n0.616\\n0.592\\n0.544\\n\\n0.599\\n0.576\\n0.538\\n\\n66.7%\\n\\n69.2%\\n\\n62.3%\\n\\n0.626\\n0.609\\n0.559\\n\\n74.6%\\n\\narea over the resulting curve approximates the total expected error\\nof the model, and thus the area under the curve can be used to\\napproximate model quality in the same manner as ROC curves.\\n\\nWe use the REC curves to directly compare the ground-truth\\nbaseline (Primary vs. Reference), the model evaluation (Primary\\nvs. Model), and the random-chance baseline (Primary vs. Random)\\nusing min cosine distance as the error metric. We construct each\\nREC curve as follows: (1) we concatenate the sets of 30 max cosine\\nsimilarity scores for each of 𝑀 test messages, yielding a single list\\nof cosine similarities for all 𝑀 × 30 primary ground-truth responses\\n(e.g., for the COVID-19 dataset, this yields 155 × 30 = 4, 650 max\\ncosine similarities); (2) we normalize the resulting list so that the\\nhighest score is 1; and (3) we subtract all values in the list from 1\\nto convert them to cosine distances. All three resulting lists (one\\nfor the model evaluation and two for the baselines) are then used\\nto construct the REC curves and AUC values as described in [4].\\nFigure 5 shows the curves with corresponding AUC measurements\\nfor the model and baselines on both datasets. In Table 5 we report\\nthe AUC scores for the full test set (ALL) and report them again\\nseparately for each twitter account with at least 20 messages in the\\ntest set of both datasets (WHO, CDCgov, CDCDirector). REC plots\\nfor these individual accounts are provided in Appendix A.\\n\\nTo compare model performance across datasets and test accounts,\\nwe compute the Model % Difference, which is the position of the\\nmodel evaluation AUC relative to the distance between the up-\\nper and lower bounds established by the two baselines (e.g., 100%\\nindicates model equals reference, and 0% indicates model equals\\nrandom). Note that for both datasets and for each account, the min\\ncosine distance AUC for the model evaluation is much closer to\\nthat of the ground-truth baseline than to that of the random-chance\\nbaseline (e.g., Model % Difference = 71.7% for COVID-19 and 66.7%\\nfor Vaccines). This indicates that the model is able to capture and\\nreproduce the true semantics of typical responses to messages and\\nauthors in our test sets. In the COVID-19 dataset, the model had an\\neasier time reproducing the semantic content of responses to the\\nCDCgov and CDCDirector accounts compared to the WHO and\\naccount (e.g., Model % Difference = 86.4% for CDCDirector, 84.8%\\nfor CDCgov, and only 61.0% for WHO). However in the Vaccines\\ndataset, the model had the easiest time with CDCDirector, followed\\nby WHO and then CDCgov (e.g., Model % Difference = 74.6% for\\nCDCDirector, 69.2% for WHO, and only 62.3% for CDCgov).\\n\\n7\\n\\nFigure 5: REC curves using the min cosine distance error metric\\non the full test sets of the COVID-19 (Left) and Vaccines (Right)\\ndatasets.\\n\\n5.1.2 Paired t-Tests. We follow up the REC-AUC analysis with\\nconfirmatory two-tailed paired t-tests to directly compare the dif-\\nferences in average max cosine similarity between the model eval-\\nuation and the baselines. We again concatenate the sets of 30 max\\ncosine similarity scores for each of 𝑀 test messages, yet this time\\nwe do not normalize them or convert them to cosine distance. This\\nyields three lists of 𝑀 × 30 max cosine similarities (one for the\\nmodel evaluation and two for the baselines), and we run two t-tests:\\n(1) comparing difference in mean between the lists for both base-\\nlines, and (2) comparing the difference in mean between the model\\nevaluation list and the random-chance baseline list. Each test is run\\nwith the null hypothesis that there is no difference between the\\nmeans of the lists, giving a p-value at the 5% significance level for\\nany observed differences.\\n\\nIn Table 6 we report the results of these tests for both datasets. We\\nagain report results for each full test set (ALL) and breakdowns for\\neach twitter account with at least 20 messages in the test sets (WHO,\\nCDCgov, CDCDirector). Also, as done previously for AUC-REC,\\nwe compare model performance across datasets and test accounts\\nusing Model % Difference. This time we do so using the differences\\nin means for max cosine similarity confirmed via the t-tests. We\\nobserve an absolute difference of less than 1% between the Model\\n% Differences obtained for the paired t-tests and those obtained\\nfor the AUC-REC scores (e.g., on the full COVID-19 test set we\\nhave Model % Difference = 71.7% for AUC-REC and 70.8% for the\\npaired t-tests, and on the full Vaccines test set we have Model %\\nDifference = 66.7% for AUC-REC and 67.6% for the paired t-tests).\\nThis provides confirmation for the conclusions drawn from the\\nAUC-REC results; that is, that the model can meaningfully capture\\nand reproduce response semantics for test messages and authors.\\n\\n5.1.3 Correlation. Finally, we perform a correlation study between\\nthe max cosine similarity scores of the ground-truth baseline (Pri-\\nmary vs. Reference) and those of the random-chance baseline (Pri-\\nmary vs. Random). The purpose of this study is to identify the base\\nlevel of semantic relatedness that any pair of random responses\\n(to any message) has in each dataset, and investigate the degree to\\n\\n\\x0cTable 6: Diff. in Mean for max cosine Sim. (paired t-test)\\n\\nTable 7: Sentiment Similarity: Results of pair wise Chi-Square tests\\n\\nCOVID-19 dataset (all results significant at 𝑝 ≪ 0.01)\\n\\nCOVID-19 dataset\\n\\nComparison\\n\\nALL\\n\\nWHO\\n\\nCDCgov\\n\\nCDCDirector\\n\\nComparison\\n\\nALL WHO CDCgov\\n\\nCDCDirector\\n\\nGT vs. Random Baselines\\nME vs. Random Baseline\\nModel % Difference∗\\n83.9%\\nVaccines dataset (all results significant at 𝑝 ≪ 0.01)\\n\\n+0.113\\n+0.080\\n\\n+0.124\\n+0.076\\n\\n+0.093\\n+0.078\\n\\n70.8%\\n\\n61.3%\\n\\n+0.110\\n+0.095\\n\\n86.4%\\n\\nComparison\\n\\nALL\\n\\nWHO\\n\\nCDCgov\\n\\nCDCDirector\\n\\n+0.071\\n+0.048\\n\\nGT vs. Random Baselines\\nME vs. Random Baseline\\nModel % Difference∗\\n*: Model % Difference: 100 * (ME vs. Random Baseline) / (GT vs. Random Baselines)\\nGT = Ground-truth; ME = Model Evaluation\\n\\n+0.108\\n+0.074\\n\\n+0.061\\n+0.038\\n\\n+0.067\\n+0.050\\n\\n67.6%\\n\\n68.5%\\n\\n62.3%\\n\\n74.6%\\n\\nPrimary vs. Reference\\nPrimary vs. Model\\nPrimary vs. Random\\n\\n72.9%\\n55.5%\\n43.9%\\n\\n77.1%\\n49.4%\\n41.0%\\n\\n70.4%\\n65.9%\\n65.9%\\n\\nVaccines dataset\\n\\nComparison\\n\\nALL WHO CDCgov\\n\\nCDCDirector\\n\\nPrimary vs. Reference\\nPrimary vs. Model\\nPrimary vs. Random\\n\\n63.6%\\n52.8%\\n43.6%\\n\\n82.6%\\n34.8%\\n43.5%\\n\\n59.1%\\n57.7%\\n45.0%\\n\\n65.4%\\n57.7%\\n19.2%\\n\\n58.1%\\n55.8%\\n44.2%\\n\\n5.2 Sentiment Similarity\\nHaving established that the model effectively generates semanti-\\ncally similar responses to messages from the different accounts,\\nwe now analyze the sentiments that are reflected by the modeled\\nresponses and compare them against the sentiments reflected in\\nPrimary, Reference and Random responses. We assess if the sen-\\ntiments expressed by the Model and the Primary, Reference and\\nRandom populations are distributed similarly.\\n\\nAs discussed in Section 3, we use RoBERTa to assign sentiment\\nscores for each response. We bin the score (𝑠) of each primary, refer-\\nence, generated, and random response into three classes: (1) Nega-\\ntive, where 1 ≤ 𝑠 < −0.25, (2) Neutral, where −0.25 ≤ 𝑠 ≤ 0.25, and\\n(3) Positive, where 0.25 < 𝑠 ≤ 1. We then perform three Chi-square\\ntests for each test message to compare the class distribution of its\\nprimary ground-truth responses and those of its reference, gener-\\nated, and random responses. The Chi-squared statistic represents\\nthe difference that exists between observed and expected counts, if\\nthere is no relationship in the population. The null hypothesis of\\neach test assumes there is no difference in class distribution, and\\nthe p-value gives the probability that any observed differences are\\ndue to chance. This yields three p-values for each message - one\\nfor the ground-truth baseline, one for the model evaluation, and\\none for the random-chance baseline. The percentage of messages\\nwhere we fail to reject the null hypothesis with a significance level\\nof 5% is counted for the model and the baselines. These percentages\\nreflect the proportion of messages for which there is no significant\\ndifference in the sentiment distribution between the compared sets.\\nIn Table 7 we report the percentage of test tweets for which there\\nis no significant difference in sentiment distribution on the basis\\nof failures to reject the null hypothesis in pair wise Chi-Square\\ntests, for Primary vs. Reference, Primary vs. Model and Primary\\nvs Random comparison sets, for both the COVID19 and Vaccine\\ndatasets. Analyzing the percentage values in each column for the\\norganizations, the Primary vs. Reference comparison set provides\\nthe greatest match in sentiments distributions (72.9% for COVID-19\\nand 63.6% for Vaccines, for ALL organizations) followed by Primary\\nvs. Model (55.5% for COVID-19 and 52.8% for Vaccines, for ALL\\norganizations). The Model has a greater match of sentiments than\\nthe Primary vs. Random test (43.9% for COVID-19 and 43.6% for\\nVaccines, for ALL organizations).\\n\\nThus, the sentiment analysis results on the model-generated\\nresponses reflect that the model mostly captures the sentiment\\ndistributions of the known ground-truth responses. Only in one\\ninstance, Vaccine data set for WHO, the model generated responses\\n\\nFigure 6: Pearson correlation between max cosine similarities of\\nthe ground-truth baseline and the random-chance baseline on the\\nfull test sets of the COVID-19 (Left) and Vaccines (Right) datasets.\\n\\nwhich this increases for pairs of responses to the same messages.\\nThis captures the difficulty inherent in learning to predict seman-\\ntics conditional on individual messages and authors. For example,\\nimagine a degenerate dataset in which all responses are the same\\nregardless of the message; in such a scenario there would not be\\nmuch for the model to learn, and we would see a perfect linear\\ncorrelation between the two baselines.\\n\\nWe use the same concatenated lists of 𝑀 × 30 max cosine similar-\\nities used in the t-tests, this time only using the ones for the ground-\\ntruth and random-chance baselines. For each dataset, we compute\\nthe Pearson’s correlation coefficient 𝑟 between these two lists. As\\nseen in Figure 6, we observe that COVID-19 has more semantically\\ndiverse responses with correlation 𝑟 = 0.58 p-value < 2.2 × 10−16\\nbetween the ground-truth and random-chance baselines, while Vac-\\ncines is much less so with 𝑟 = 0.71 p-value < 2.2 × 10−16 between\\nbaselines. This indicates that Vaccines presents an “easier” problem\\nfor the model with respect to learning semantic distributions. This\\nexplains why model evaluation metrics are better for Vaccines (e.g.,\\nlower validation perplexity, higher AUC) than for the COVID-19\\ndataset, yet we see higher Model % Differences for COVID-19. Al-\\nthough we have already established using the AUC-REC and t-test\\nanalysis that GPT-2 is effective at generating semantically correct\\nresponse distributions on both datasets, this correlation analysis\\nshows that use of such a model has more utility on the COVID-19\\ndataset than on the Vaccine dataset. When considering how a newly\\nauthored COVID-19 related tweet would be received, a user is less\\nlikely to find accurate insight by simply looking at related historical\\nresponses and would benefit more from a generative model.\\n\\n8\\n\\n\\x0cFigure 7: Distribution of sentiments including all organizations,\\nfor COVID 19 data (Top) and Vaccine data (Bottom)\\n\\nFigure 8: Distribution of sentiments for individual organizations,\\nfor COVID 19 data (Top) and Vaccine data (Bottom)\\n\\nyield a worse percentage than Random when compared against the\\nPrimary sentiment distribution.\\n\\nTo further investigate how close the sentiment values from the\\nModel, Primary and Random responses are, we looked at the density\\ndistribution of the raw sentiment values from RoBERTa for ALL\\norganizations. Figure 7 represents the density distribution of the\\nsentiment scores provided for the Primary, Model (generated) and\\nRandom responses for ALL tweets for each data set.\\n\\nThe density distribution of sentiments from the Primary, Model\\nand Random responses reflect highest density peaks for negative\\nsentiments (peaking close to sentiment value of -1.0). To understand\\nif this is due to the relative differences of public message reception\\nfrom different organizations, we investigate the density distribution\\nobtained from the sentiments from Primary ground truth messages\\nand responses for each public health organization in Figure 8.\\n\\nWe note that there seem to be more negative sentiments in the\\nground truth responses for CDCgov and CDCDirector accounts,\\nwhen compared with that for the WHO. It is important to note that\\nour models are text (response) generators and not directly trained\\nto predict sentiment class likelihood. Also, since the models are not\\ntrained separately for each organization, the relative differences in\\nresponse sentiments between WHO and other organizations may\\ncontribute to the diminished performance we observe capturing\\nthe true sentiment distribution in responses to WHO messages (as\\nreflected in results from Vaccine data in Table 7).\\n\\n9\\n\\n6 RELATED WORK\\nWe review relevant works which introduce methods for generating\\nsocial media text (e.g., tweets), or which use social media text as a\\nbasis for learning to generate conversational responses. DialoGPT\\n[25] is a GPT-2-based dialogue response generator trained on 147\\nmillion “conversations” constructed as distinct paths through com-\\nment chains on Reddit. PLATO [1], PLATO-2 [2], and BlenderBot\\n[17] are recent open-domain neural conversational models that\\nalso use social media responses in pre-training (PLATO uses both\\nReddit and Twitter, the others use Reddit only). Cetinkaya et al. [6]\\npropose a neural encoder-decoder-reranker framework for building\\nchatbots that can participate in Twitter conversations by learning\\nto take a side on a controversial issue (e.g., gun control). Tran &\\nPopowich and Roy et al. both explore methods for generating tweets\\nto notify the public about traffic incidents [19, 21]. Lofi & Krestel\\npropose a method to use open government data to generate tweets\\nthat inform the public on ongoing political processes [14]. Finally,\\nin perhaps the most related work to ours, Garvey et al. [9] propose\\na system designed to aid social media content managers design\\ntweets that will be received well and become popular. Their system\\nincludes semantic and sentiment analysis components capable of\\nestimating a tweet’s target engagement, which is used in turn with\\na custom probabilistic generative model to synthesize tweets. Al-\\nthough we share the same motivations and envisioned use cases,\\nwhat differentiates our work is that Garvey et al. use generative\\nmodeling to help a user craft a proposed message and assign it an\\nestimated engagement score, while our method generates responses\\n\\n\\x0cto a proposed message. This provides users with a view of what\\npeople might actually say if the message goes public, offering cru-\\ncial insights into the specific concerns that lead to a message being\\nreceived well (or not). We believe that our methods complement\\nGarvey et al. well - specifically, an organization which adopts both\\ntools might craft promising candidate tweets via Garvey et al. and\\nthen preview their reception with our models.\\n\\n7 CONCLUSION\\nWe conclude with a summary of our contributions and a discussion\\nof limitations, future directions, and ethical considerations.\\n\\n7.1 Contributions\\nOur main contributions are as follows: (1) we collected two datasets\\nof public health messages and their responses on Twitter, one in\\ncontext of COVID-19 and one in context of Vaccines; (2) we trained\\ntwo GPT-2 text generators - one for each dataset - both capable of\\ncapturing and reproducing the semantic and sentiment distributions\\nin known responses to public health messages; (3) we demonstrate\\nour envisioned use case in which a public health organization uses\\nour models to optimize expected reception for important health\\nguidance; and (4) we introduce a novel evaluation scheme with\\nextensive statistical testing to confirm that our models capture\\nsemantics and sentiment as we qualitatively observe.\\n\\n7.2 Limitations and Future Directions\\nHere we note several key limitations of our study and discuss ways\\nin which future work may address them. Specifically, we discuss\\nthe issues of: (1) factuality of generated responses; (2) quality of\\nsemantic and sentiment similarity measurement; (3) opportunities\\nfor further evaluation; and (4) generalization beyond this study.\\n\\n7.2.1 Generated Response Factuality. Language models such as\\nGPT-2 are prone to generate factually inaccurate output, often\\ntimes “hallucinating” details (e.g., names, places, quantities, etc.)\\nin the absence of external knowledge [12]. For example, many of\\nthe generated responses in Figures 3 and 4 tag users and/or display\\nhashtags that do not make sense considering the response text.\\nAdditionally, our response generator models are prone to tempo-\\nral drift unless continually re-trained on up-to-date samples from\\nTwitter. For example, our COVID-19 dataset was collected during\\nthe spring and summer of 2020 (the early months of the pandemic)\\nand thus would not generate accurate responses to tweets concern-\\ning late-pandemic issues such as vaccine boosters, relaxed mask\\nrecommendations, and return-to-office policies.\\n\\nA potential remedy for language model hallucination and tempo-\\nral drift is to take advantage of recent generative models capable of\\nintegrated information retrieval from knowledge bases (e.g., RAG\\n[11]). Retrieval-augmented response generation would allow re-\\nsponse predictions to incorporate rapidly evolving information (e.g.,\\nbreaking news updates) without needing constant re-training, and\\ncould increase the general correctness of generated responses with\\nrespect to common world knowledge. Additionally, maintaining an\\nup-to-date knowledge base of current events requires less compu-\\ntational resources than continually training language models.\\n\\n10\\n\\nSemantic & Sentiment Measurement Quality. In our study we\\n7.2.2\\nuse off-the-shelf pre-trained models for computing sentence em-\\nbeddings and sentiment scores. Specifically, the MiniLM sentence\\nembedding model was pre-trained on over one billion sentence pairs\\nfrom 32 distinct datasets. These include Wikipedia, various Q&A\\ncollections, comments from social media forums such as Reddit,\\nQuora, Stack Exchange, and Yahoo Answers, and many others. The\\nRoBERTa sentiment classifier was fine-tuned on the dataset used in\\nthe TweetEval sentiment analysis task, which is the SemEval 2017\\nTwitter sentiment analysis dataset [18] with over 50,000 labeled\\nEnglish tweets. Since these models have already been exposed to\\nlarge-scale corpora and perform well on their respective bench-\\nmarks, we deemed them sufficient for measuring semantic similarity\\nand sentiment on our datasets. However, this comes with the limita-\\ntion that these models have not seen specialized terminology (e.g.,\\nCOVID-19) or entities (e.g., names, places) of significance beyond\\nthe topical and temporal scope of their training sets.\\n\\nTo mitigate this, it is possible to do additional fine-tuning of the\\nsentence embedding and sentiment models on the collected tweets\\nto ensure the most robust semantic and sentiment comparisons.\\nWe encourage any future work employing our methods to explore\\nthis avenue. We note that sentence pairs for further training of\\nthe embedding model can be mined from raw tweet collections\\nautomatically (e.g., select positive example pairs from the same\\nreply threads and negative example pairs at random), but labeling\\nnew tweets for sentiment polarity requires manual effort.\\n\\n7.2.3 Opportunities for Further Evaluation. In this work we eval-\\nuate one type of model for response generation (GPT-2). We rec-\\nognize that response generation is a well studied area, specifically\\nin conversational contexts (e.g., see Section 6), and thus there is\\nopportunity to compare different response generation models on\\nthis task. For example, more recent, larger-scale generative models\\n(e.g., GPT-3 [5]) are likely to produce higher quality responses at\\nthe cost of increased compute for training and evaluation. However,\\nwe note that new language models are constantly being developed\\nand improved, and our proposed methodology supports the replace-\\nment of GPT-2 with any current or future text generation model\\nwithout changing the nature of the task, evaluation, or its use-cases.\\nWe also note the need for end-user validation by our target\\naudience (e.g., public health social media managers). This could\\nbe in the form of a trial where users use our models, perhaps in\\ncombination with the tools of Garvey et al., to respond to their\\nmessages and then compare the system’s predictions with actual\\nresponses on Twitter. Such a study may yield valuable information\\nregarding the effectiveness of our methods as day-to-day tools and\\nproduce directions for future improvement.\\n\\n7.2.4 Generalization Beyond This Study. Our statistical evaluations\\ndemonstrate the effectiveness of generative response modeling in\\nreproducing the sentiment and semantics of public health responses\\non Twitter. However, as briefly noted in Section 4.2, there is ample\\nopportunity to generalize our method to other settings. Some possi-\\nbilities for future work include: (1) allowing the response generator\\nto be conditioned on attributes of the responder (e.g., geographical\\nregion, age, etc.) to provide insights into how targeted popula-\\ntions might react to a message; (2) training expanded models on\\nadditional author types beyond public health organizations (e.g.,\\n\\n\\x0c[11] P Lewis, E Perez, A Piktus, F Petroni, V Karpukhin, N Goyal, H Küttler, M\\nLewis, W-t Yih, T Rocktäschel, et al. 2020. Retrieval-augmented generation\\nfor knowledge-intensive nlp tasks. Advances in Neural Information Processing\\nSystems 33 (2020), 9459–9474.\\n\\n[12] T Liu, Y Zhang, C Brockett, Y Mao, Z Sui, W Chen, and B Dolan. 2021. A\\ntoken-level reference-free hallucination detection benchmark for free-form text\\ngeneration. arXiv preprint arXiv:2104.08704 (2021).\\n\\n[13] Y Liu, M Ott, N Goyal, J Du, M Joshi, D Chen, O Levy, M Lewis, L Zettlemoyer, and\\nV Stoyanov. 2019. RoBERTa: A Robustly Optimized BERT Pretraining Approach.\\nCoRR abs/1907.11692 (2019). arXiv:1907.11692 http://arxiv.org/abs/1907.11692\\niParticipate: Automatic Tweet Generation from\\nLocal Government Data. In Database Systems for Advanced Applications, S-G\\nLee, Z Peng, X Zhou, Y-S Moon, R Unland, and J Yoo (Eds.). Springer, Berlin,\\nHeidelberg, 295–298.\\n\\n[14] C Lofi and R Krestel. 2012.\\n\\n[15] I Loshchilov and F Hutter. 2019. Decoupled Weight Decay Regularization. In Intl\\nConf on Learning Representations. https://openreview.net/forum?id=Bkg6RiCqY7\\n[16] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever,\\net al. 2019. Language models are unsupervised multitask learners. OpenAI blog\\n1, 8 (2019), 9.\\n\\n[17] S Roller, E Dinan, N Goyal, D Ju, M Williamson, Y Liu, J Xu, M Ott, EM Smith, Y-\\nLan Boureau, and J Weston. 2021. Recipes for Building an Open-Domain Chatbot.\\nIn Proc of the 16th Conference of the European Chapter of the Assoc for Compu-\\ntational Linguistics: Main Volume. Association for Computational Linguistics,\\nOnline, 300–325. https://doi.org/10.18653/v1/2021.eacl-main.24\\n\\n[18] S Rosenthal, N Farra, and P Nakov. 2017. SemEval-2017 Task 4: Sentiment\\nAnalysis in Twitter. In Proc of the 11th Intl Workshop on Semantic Evaluation\\n(SemEval-2017). Association for Computational Linguistics, Vancouver, Canada,\\n502–518. https://doi.org/10.18653/v1/S17-2088\\n\\n[19] B Roy, P Dutta, and S Choudhury. 2022. Probabilistic Traffic Tweet Generation\\nModel. In Advances in Distributed Computing and Machine Learning, J P Sahoo,\\nA K Tripathy, M Mohanty, K-C Li, and A K Nayak (Eds.). Springer, Singapore,\\n250–260.\\n\\n[20] A C Sanders, R C White, L S Severson, R Ma, R McQueen, H C A Paulo, Y\\nZhang, J S Erickson, and K P Bennett. 2021. Unmasking the conversation on\\nmasks: Natural language processing for topical sentiment analysis of COVID-19\\nTwitter discourse. In AMIA Annual Symposium Proc, Vol. 2021. American Medical\\nInformatics Association, 555.\\n\\n[21] K Tran and F Popowich. 2016. Automatic Tweet Generation From Traffic Incident\\nData. In Proc of the 2nd Intl Workshop on Natural Language Generation and\\nthe Semantic Web (WebNLG 2016). Association for Computational Linguistics,\\nEdinburgh, Scotland, 59–66. https://aclanthology.org/W16-3512\\n\\n[22] W Wang, F Wei, L Dong, H Bao, N Yang, and M Zhou. 2020. MiniLM: Deep\\nSelf-Attention Distillation for Task-Agnostic Compression of Pre-Trained Trans-\\nformers. arXiv:2002.10957 [cs.CL]\\n\\n[23] Y Wang, H Hao, and L Sundahl Platt. 2021. Examining risk and crisis com-\\nmunications of government agencies and stakeholders during early-stages\\nof COVID-19 on Twitter. Computers in Human Behavior 114 (2021), 106568.\\nhttps://doi.org/10.1016/j.chb.2020.106568\\n\\n[24] Bo Wei, S Lu, L Mou, H Zhou, P Poupart, G Li, and Z Jin. 2019. Why Do Neural\\nDialog Systems Generate Short and Meaningless Replies? a Comparison between\\nDialog and Translation. In ICASSP 2019 - 2019 IEEE Intl Conf on Acoustics, Speech\\nand Signal Processing (ICASSP). 7290–7294. https://doi.org/10.1109/ICASSP.2019.\\n8682634\\n\\n[25] Y Zhang, S Sun, M Galley, Y-C Chen, C Brockett, X Gao, J Gao, J Liu, and B Dolan.\\n2020. DIALOGPT : Large-Scale Generative Pre-training for Conversational\\nResponse Generation. In Proc of the 58th Annual Meeting of the Association for\\nComputational Linguistics: System Demonstrations. Association for Computational\\nLinguistics, Online, 270–278. https://doi.org/10.18653/v1/2020.acl-demos.30\\n\\npolitical organizations and large corporations); and (3) targeting\\nother social media platforms (e.g., Facebook and Reddit).\\n\\n7.3 Ethical Considerations\\nWe recognize the potential dangers presented by the use of language\\nmodels such as GPT-2 to emulate unfiltered public discourse as\\nwe do in this study. The examples in Figure 3 make evident the\\ndegree to which such models can be prompted to emit vitriol in\\nthis setting, and there is obvious direction for misuse. We take\\nthis opportunity to reiterate that our intended use case is to allow\\nsocial media representatives for impactful organizations to gain\\naccurate perspectives on the way their messages may be received\\nby the public, which requires preserving the real semantics and\\nsentiment of social media discourse regardless of its toxicity. We do\\nnot support or condone the use of our methods, models, or data for\\nany purpose that may directly or indirectly cause harm to others.\\n\\nACKNOWLEDGMENTS\\nThis study was supported by the Rensselaer Institute for Data Ex-\\nploration and Applications (IDEA), the Rensselaer Data INCITE\\nLab, and a grant from the United Health Foundation. Additionally,\\nwe thank Brandyn Sigouin, Thomas Shweh, and Haotian Zhang for\\ntheir participation in the exploratory phase of this project via the\\nData INCITE Lab.\\n\\nREFERENCES\\n[1] S Bao, H He, F Wang, H Wu, and H Wang. 2020. PLATO: Pre-trained Dialogue\\nGeneration Model with Discrete Latent Variable. In Proc of the 58th Annual\\nMeeting of the Assoc. for Computational Linguistics. Association for Computational\\nLinguistics, Online, 85–96. https://doi.org/10.18653/v1/2020.acl-main.9\\n\\n[2] S Bao, H He, F Wang, H Wu, H Wang, W Wu, Z Guo, Z Liu, and X Xu. 2021. PLATO-\\n2: Towards Building an Open-Domain Chatbot via Curriculum Learning. In\\nFindings of the Assoc. for Computational Linguistics: ACL-IJCNLP 2021. Association\\nfor Computational Linguistics, Online, 2513–2525. https://doi.org/10.18653/v1/\\n2021.findings-acl.222\\n\\n[3] F Barbieri, J Camacho-Collados, L Espinosa Anke, and L Neves. 2020. TweetEval:\\nUnified Benchmark and Comparative Evaluation for Tweet Classification. In\\nFindings of the Assoc for Computational Linguistics: EMNLP 2020. Association for\\nComputational Linguistics, Online, 1644–1650. https://doi.org/10.18653/v1/2020.\\nfindings-emnlp.148\\n\\n[4] J Bi and K P Bennett. 2003. Regression error characteristic curves. In Proceedings\\n\\nof the 20th Intl conf on machine learning (ICML-03). 43–50.\\n\\n[5] T Brown, B Mann, N Ryder, M Subbiah, J D Kaplan, P Dhariwal, A Neelakantan,\\nP Shyam, G Sastry, A Askell, et al. 2020. Language models are few-shot learners.\\nAdvances in neural information processing systems 33 (2020), 1877–1901.\\n\\n[6] Y M Çetinkaya, İ Hı Toroslu, and H Davulcu. 2020. Developing a Twitter bot that\\ncan join a discussion using state-of-the-art architectures. Social network analysis\\nand mining 10, 1 (2020), 1–21.\\n\\n[7] L-A Cotfas, C Delcea, I Roxin, C Ioanăş, D S Gherai, and F Tajariol. 2021. The\\nLongest Month: Analyzing COVID-19 Vaccination Opinions Dynamics From\\nTweets in the Month Following the First Vaccine Announcement. IEEE Access 9\\n(2021), 33203–33223. https://doi.org/10.1109/ACCESS.2021.3059821\\n\\n[8] M Galley, C Brockett, A Sordoni, Y Ji, M Auli, C Quirk, M Mitchell, J Gao, and\\nB Dolan. 2015. deltaBLEU: A Discriminative Metric for Generation Tasks with\\nIntrinsically Diverse Targets. In Proc of the 53rd Annual Meeting of the Assoc\\nfor Computational Linguistics and the 7th Intl Joint Conf on Natural Language\\nProcessing (Volume 2: Short Papers). Association for Computational Linguistics,\\nBeijing, China, 445–450. https://doi.org/10.3115/v1/P15-2073\\n\\n[9] M D. Garvey, J Samuel, and A Pelaez. 2021. Would you please like my tweet?! An\\nartificially intelligent, generative probabilistic, and econometric based system\\ndesign for popularity-driven tweet content generation. Decision Support Systems\\n144 (2021), 113497. https://doi.org/10.1016/j.dss.2021.113497\\n\\n[10] P Gupta, S Mehri, T Zhao, A Pavel, M Eskenazi, and J Bigham. 2019. Investigating\\nEvaluation of Open-Domain Dialogue Systems With Human Generated Multiple\\nReferences. In Proc of the 20th Annual SIGdial Meeting on Discourse and Dialogue.\\nAssociation for Computational Linguistics, Stockholm, Sweden, 379–391. https:\\n//doi.org/10.18653/v1/W19-5944\\n\\n11\\n\\n\\x0cA ADDITIONAL REC PLOTS\\nThe following shows the semantic similarity REC curves for each individual public health organization account with at least 20 messages in\\nthe test set of both datasets. Figure 9 shows REC curves for the COVID-19 dataset and Figure 10 for the Vaccines dataset. The REC curves for\\neach full test set (left-most plot in each figure) are provided here again to facilitate comparison.\\n\\nFigure 9: REC curves using the min cosine distance error metric on the test set of the COVID-19 dataset.\\n\\nFigure 10: REC curves using the min cosine distance error metric on the test set of the Vaccines dataset.\\n\\n12\\n\\n\\x0c'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z_JeYxT6deGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metadata"
      ],
      "metadata": {
        "id": "MtnW02Lwdi2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf.get_metadata()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QcFtdKjdXTx",
        "outputId": "f6fe0d83-9ca2-40a7-d1ee-a085db723df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CreationDate': 'D:20220516014245Z',\n",
              " 'Creator': 'LaTeX with acmart 2022/04/09 v1.84 Typesetting articles for the Association for Computing Machinery and hyperref 2020-05-15 v7.00e Hypertext links for LaTeX',\n",
              " 'ModDate': 'D:20220516014245Z',\n",
              " 'PTEX.Fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
              " 'Pages': 12,\n",
              " 'Producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
              " 'Subject': '-  Computing methodologies  ->  Discourse, dialogue and pragmatics.-  Information systems  ->  Sentiment analysis.',\n",
              " 'Title': 'Should we tweet this? Generative response modeling for predicting reception of public health messaging on Twitter',\n",
              " 'Trapped': 'False',\n",
              " 'dc': {'creator': ['Abraham Sanders',\n",
              "   'Debjani Ray-Majumder',\n",
              "   'John S. Erickson',\n",
              "   'Kristin P. Bennett'],\n",
              "  'date': ['2022-05-16T01:42:45Z'],\n",
              "  'description': {'en': '-  Computing methodologies  ->  Discourse, dialogue and pragmatics.-  Information systems  ->  Sentiment analysis.',\n",
              "   'x-default': '-  Computing methodologies  ->  Discourse, dialogue and pragmatics.-  Information systems  ->  Sentiment analysis.'},\n",
              "  'format': 'application/pdf',\n",
              "  'identifier': 'info:doi/10.1145/3501247.3531574',\n",
              "  'language': ['en'],\n",
              "  'publisher': ['Association for Computing Machinery'],\n",
              "  'source': 'main.tex',\n",
              "  'subject': ['tweet response generation',\n",
              "   'sentiment analysis',\n",
              "   'public health',\n",
              "   'COVID-19',\n",
              "   'vaccines'],\n",
              "  'title': {'en': 'Should we tweet this? Generative response modeling for predicting reception of public health messaging on Twitter',\n",
              "   'x-default': 'Should we tweet this? Generative response modeling for predicting reception of public health messaging on Twitter'},\n",
              "  'type': ['Text']},\n",
              " 'http://iptc.org/std/Iptc4xmpCore/1.0/xmlns/': {'CiAdrCity': 'Troy',\n",
              "  'CiAdrCtry': 'USA',\n",
              "  'CiAdrRegion': 'New York',\n",
              "  'CiEmailWork': 'sandea5@rpi.edu'},\n",
              " 'http://prismstandard.org/namespaces/basic/2.1/': {'aggregationType': 'book',\n",
              "  'complianceProfile': 'three',\n",
              "  'doi': '10.1145/3501247.3531574',\n",
              "  'isbn': '978-1-4503-9191-7',\n",
              "  'number': '1',\n",
              "  'publicationName': \"14th ACM Web Science Conference 2022 (WebSci '22), June 26â•ﬁ29, 2022, Barcelona, Spain\",\n",
              "  'volume': '1'},\n",
              " 'http://www.aiim.org/pdfa/ns/extension/': {},\n",
              " 'http://www.aiim.org/pdfa/ns/field#': {'description': 'Contact information Web URL(s)',\n",
              "  'name': 'CiUrlWork',\n",
              "  'valueType': 'Text'},\n",
              " 'http://www.aiim.org/pdfa/ns/property#': {'category': 'external',\n",
              "  'description': \"Document's subtitle\",\n",
              "  'name': 'subtitle',\n",
              "  'valueType': 'Text'},\n",
              " 'http://www.aiim.org/pdfa/ns/schema#': {'namespaceURI': 'http://prismstandard.org/namespaces/basic/2.1/',\n",
              "  'prefix': 'prism',\n",
              "  'schema': 'PRISM Basic Metadata'},\n",
              " 'http://www.aiim.org/pdfa/ns/type#': {'description': 'Basic set of information to get in contact with a person',\n",
              "  'namespaceURI': 'http://iptc.org/std/Iptc4xmpCore/1.0/xmlns/',\n",
              "  'prefix': 'Iptc4xmpCore',\n",
              "  'type': 'ContactInfo'},\n",
              " 'pdf': {'Keywords': 'tweet response generation, sentiment analysis, public health, COVID-19, vaccines',\n",
              "  'PDFVersion': '1.5',\n",
              "  'Producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2'},\n",
              " 'rdf': {'li': 'en'},\n",
              " 'xap': {'CreateDate': '2022-05-16T01:42:45Z',\n",
              "  'CreatorTool': 'LaTeX with acmart 2022/04/09 v1.84 Typesetting articles for the Association for Computing Machinery and hyperref 2020-05-15 v7.00e Hypertext links for LaTeX',\n",
              "  'MetadataDate': '2022-05-16T01:42:45Z',\n",
              "  'ModifyDate': '2022-05-16T01:42:45Z'},\n",
              " 'xapmm': {'DocumentID': 'uuid:2bbb13ea-3905-495f-ba3e-a39bb1395fdc',\n",
              "  'InstanceID': 'uuid:882bb1d7-a8d7-4f7f-9759-05fd139bb675',\n",
              "  'RenditionClass': 'default',\n",
              "  'VersionID': '1'}}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf.get_references_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uj13536c3om",
        "outputId": "0511abf6-cd50-48ff-8996-53b2b73a375a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf.get_references_as_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwVV8zNpd3Od",
        "outputId": "8cb63a07-cc75-4982-ea5e-fe0506ed0897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'arxiv': ['2002.10957', '1907.11692'],\n",
              " 'url': ['https://doi.org/10.18653/v1/2020.acl-main.9',\n",
              "  'https://doi.org/10.18653/v1/W19-5944',\n",
              "  'https://doi.org/10.18653/v1/2020',\n",
              "  'https://doi.org/10.1109/ACCESS.2021.3059821',\n",
              "  'https://orcid.org/0000-0003-3078-4566',\n",
              "  'https://doi.org/10.18653/v1/2021.findings-acl.222',\n",
              "  'https://doi.org/10.1109/ICASSP.2019.8682634',\n",
              "  'https://doi.org/10.1016/j.chb.2020.106568',\n",
              "  'https://doi.org/10.18653/v1/2020.findings-emnlp.148',\n",
              "  'cs.CL',\n",
              "  'https://orcid.org/0000-0001-6433-9490',\n",
              "  'https://doi.org/10.18653/v1/2020.acl-demos.30',\n",
              "  'https://developer.twitter.com/en/developer-terms/agreement-and-policy',\n",
              "  'https://orcid.org/0000-0002-8782-105X',\n",
              "  'https://orcid.org/0000-0002-5231-2239',\n",
              "  'https://www.ecdc.europa.eu/en/about-us/press-and-media/ecdc-social-media',\n",
              "  'https://doi.org/10.18653/v1/2021.eacl-main.24',\n",
              "  'https://www.cdc.gov/socialmedia/tools/Twitter.html',\n",
              "  'https://doi.org/10.1016/j.dss.2021.113497',\n",
              "  'https://openreview.net/forum?id=Bkg6RiCqY7',\n",
              "  'https://doi.org/10.1109/ICASSP.2019',\n",
              "  'https://doi.org/10.18653/v1/S17-2088',\n",
              "  'https://www.elastic.co/elasticsearch',\n",
              "  'doi.org/10.18653/v1/W19-5944',\n",
              "  'https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2',\n",
              "  'https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment',\n",
              "  'https://github.com/TheRensselaerIDEA/generative-response-modeling',\n",
              "  'https://doi.org/10.18653/v1/',\n",
              "  'https://aclanthology.org/W16-3512',\n",
              "  '2104.08704',\n",
              "  'https://doi.org/10.3115/v1/P15-2073',\n",
              "  'https://huggingface.co/gpt2-large']}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ver detalle de info en JSON"
      ],
      "metadata": {
        "id": "A6IfYVWfe0St"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf.download_pdfs(\"target-directory\")"
      ],
      "metadata": {
        "id": "nQVhHfLFeUUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTV-JTbCjKzE",
        "outputId": "ce94bcc5-858b-452b-f47a-bffccd742c7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPDF2\n",
            "  Downloading PyPDF2-2.4.1-py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from PyPDF2) (4.1.1)\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-2.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing required modules \n",
        "import PyPDF2 \n",
        "    \n",
        "# creating a pdf file object \n",
        "pdfFileObj = open('paperOAI.pdf', 'rb') \n",
        "    \n",
        "# creating a pdf reader object \n",
        "pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
        "# printing number of pages in pdf file \n",
        "print(pdfReader.numPages) \n",
        "print(pdfReader.metadata) \n",
        "\n",
        "# creating a page object \n",
        "pageObj = pdfReader.getPage(0) \n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWCcskfRjRSC",
        "outputId": "04ffeab1-31af-4f3f-f2af-34720dfb5359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "{'/CreationDate': 'D:20220516014245Z', '/Creator': 'LaTeX with acmart 2022/04/09 v1.84 Typesetting articles for the Association for Computing Machinery and hyperref 2020-05-15 v7.00e Hypertext links for LaTeX', '/ModDate': 'D:20220516014245Z', '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', '/Producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', '/Subject': '-  Computing methodologies  ->  Discourse, dialogue and pragmatics.-  Information systems  ->  Sentiment analysis.', '/Title': 'Should we tweet this? Generative response modeling for predicting reception of public health messaging on Twitter', '/Trapped': '/False'}\n",
            "<built-in method index of list object at 0x7fc0ce1ffcd0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(pageObj.extractText()) \n",
        "    \n",
        "# closing the pdf file object \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaEKgPe5j_UZ",
        "outputId": "701374d1-1d3b-4c22-fdbe-54223638a673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Should we tweet this? Generative response modeling for\n",
            "predicting reception of public health messaging on Twitter\n",
            "Abraham Sanders\n",
            "Rensselaer Polytechnic Institute\n",
            "Troy, New York, USA\n",
            "sandea5@rpi.edu Debjani Ray-Majumder\n",
            "Rensselaer Polytechnic Institute\n",
            "Troy, New York, USA\n",
            "raymad@rpi.edu\n",
            "John S. Erickson\n",
            "Rensselaer Polytechnic Institute\n",
            "Troy, New York, USA\n",
            "erickj4@rpi.edu Kristin P. Bennett\n",
            "Rensselaer Polytechnic Institute\n",
            "Troy, New York, USA\n",
            "bennek@rpi.edu\n",
            "ABSTRACT\n",
            "The way people respond to messaging from public health organiza-\n",
            "tions on social media can provide insight into public perceptions\n",
            "on critical health issues, especially during a global crisis such as\n",
            "COVID-19. It could be valuable for high-impact organizations such\n",
            "as the US Centers for Disease Control and Prevention (CDC) or\n",
            "the World Health Organization (WHO) to understand how these\n",
            "perceptions impact reception of messaging on health policy recom-\n",
            "mendations. We collect two datasets of public health messages and\n",
            "their responses from Twitter relating to COVID-19 and Vaccines,\n",
            "and introduce a predictive method which can be used to explore\n",
            "the potential reception of such messages. Specifically, we harness\n",
            "a generative model (GPT-2) to directly predict probable future re-\n",
            "sponses and demonstrate how it can be used to optimize expected\n",
            "reception of important health guidance. Finally, we introduce a\n",
            "novel evaluation scheme with extensive statistical testing which\n",
            "allows us to conclude that our models capture the semantics and\n",
            "sentiment found in actual public health responses.\n",
            "CCS CONCEPTS\n",
            "•Computing methodologies→Discourse, dialogue and prag-\n",
            "matics;•Information systems→Sentiment analysis.\n",
            "KEYWORDS\n",
            "tweet response generation, sentiment analysis, public health, COVID-\n",
            "19, vaccines\n",
            "1 INTRODUCTION\n",
            "During the COVID-19 pandemic, Twitter and other social media\n",
            "messaging by public health organizations played a significant role\n",
            "in their strategies to enact proposed mitigations to potential risks\n",
            "with varying effectiveness [23]. As such, recent works have focused\n",
            "on topical, semantic, and sentiment analysis of COVID-19 and vac-\n",
            "cine related Twitter discourse, many leveraging natural language\n",
            "processing (NLP) technologies. For example, Sanders et al. [20]\n",
            "clustered tweets relating to mask-wearing in the early days of the\n",
            "COVID-19 pandemic to discover prevalent themes, perceptions, and\n",
            "sentiments. Cotfas et al. [7] applied machine learning for vaccine\n",
            "stance detection using tweets collected in the month following the\n",
            "announcement of a COVID-19 vaccine. Our study follows similar\n",
            "motivation - to investigate the way the general population reactsto messaging from major public health agencies (e.g., US CDC, Eu-\n",
            "ropean CDC, and WHO) on a variety of topics including COVID-19\n",
            "and vaccines. Unlike previous work in this area, we investigate the\n",
            "feasibility and utility of using state-of-the-arttext generation models\n",
            "to directly simulate typical response distributions to novel public\n",
            "health messages on Twitter. These simulations, combined with sen-\n",
            "timent analysis, can be used to help public health organizations\n",
            "understand the specific opinions and concerns of their audience in\n",
            "order to develop more effective health messaging strategies.\n",
            "In this study, we collect two datasets of public health tweets: (1)\n",
            "COVID-19 related public health messages from March 1st, 2020 to\n",
            "September 30th, 2020, and (2) vaccine-related public health mes-\n",
            "sages from October 1st, 2021 to January 31st, 2022. These datasets\n",
            "include the original messages and samples of their responses, both\n",
            "in the form of direct replies and quote-tweets (retweets with com-\n",
            "ments). Using each dataset, we fine-tune a GPT-2 [16] language\n",
            "model to predict responses to the public health tweets and evaluate\n",
            "its effectiveness in terms of semantic and sentiment similarity with\n",
            "known responses. To evaluate the models, we establish “ground-\n",
            "truth” baselines for semantics and sentiment on each dataset by\n",
            "comparing two distinct samples of known responses to each mes-\n",
            "sage. We also establish “random-chance” baselines by likewise com-\n",
            "paring each sample of known responses with a sample of random\n",
            "responses for any message in each dataset. We then use our models\n",
            "to generate responses to each test message compare them with the\n",
            "known response samples. Through rigorous statistical testing we\n",
            "find that our models are able to generate responses consistent with\n",
            "known samples in terms of semantics and sentiment. Thus, insights\n",
            "on perceptions toward particular public health issues can be gained\n",
            "from analyzing the generated response distributions. We envision\n",
            "our methods being able to aid public health decision makers and\n",
            "social media content managers proactively model how the public\n",
            "will react to future messages, increasing the likelihood that their\n",
            "tweets are well received and have the intended impact.\n",
            "The remainder of this paper is organized as follows: (1) we\n",
            "present two datasets of Twitter public health messages and their\n",
            "responses, one related to COVID-19 and one related to Vaccines; (2)\n",
            "we fine-tune GPT-2 to generate responses on each of these datasets,\n",
            "and construct upper (ground-truth) and lower (random-chance)\n",
            "bound baselines against which to evaluate it; (3) we visually demon-\n",
            "strate the capabilities of our models using test set examples and\n",
            "arXiv:2204.04353v2  [cs.CL]  13 May 2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdfFileObj.close() "
      ],
      "metadata": {
        "id": "eqaHq-gykHHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**how can i extract comment from a pdf file?**\n",
        "\n",
        "There is no surefire way to extract comments from a PDF file, but there are a few methods you can try. One is to open the PDF in a text editor and search for the comment tags, which are typically denoted by %% or %%. Another method is to use a PDF editing tool that allows you to view and edit the comments.\n",
        "\n",
        "**there is a library in python? **\n",
        "\n",
        "Yes, there is a library in Python that can be used to extract comments from a PDF file. The library is called PDFMiner, and it can be found here: https://pypi.python.org/pypi/pdfminer/."
      ],
      "metadata": {
        "id": "4eeSRrYTE8ps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pypi.org/project/pdfannot/"
      ],
      "metadata": {
        "id": "hMCgAMrvOWPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiaB1K7MRgA8",
        "outputId": "49522d17-87e2-40bd-b697-49f8df3e1e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from PyPDF2) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cPiKfc5Pj55",
        "outputId": "d2f55b10-eddd-437f-a5b4-94d1d57a4fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from PyPDF2) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "\n",
        "reader = PyPDF2.PdfFileReader('paperOAI.pdf')\n",
        "reader.getDocumentInfo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL1anzQOSFUZ",
        "outputId": "c1520d66-5f02-4ff5-a9e5-d922dbf8d63c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'/CreationDate': 'D:20220516014245Z',\n",
              " '/Creator': 'LaTeX with acmart 2022/04/09 v1.84 Typesetting articles for the Association for Computing Machinery and hyperref 2020-05-15 v7.00e Hypertext links for LaTeX',\n",
              " '/ModDate': 'D:20220516014245Z',\n",
              " '/PTEX.Fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
              " '/Producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
              " '/Subject': '-  Computing methodologies  ->  Discourse, dialogue and pragmatics.-  Information systems  ->  Sentiment analysis.',\n",
              " '/Title': 'Should we tweet this? Generative response modeling for predicting reception of public health messaging on Twitter',\n",
              " '/Trapped': '/False'}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reader.getPage(2-1).extractText()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "ELxnS3_2SYj2",
        "outputId": "2ad4f9c4-2241-467d-9bdd-bdc85059ea46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Table 1:Public health account screen names\\n\\nEuropean CDC Accounts4\\n\\nESCAIDE ECDCPHT ecdc_tb ECDC_VPD ECDC_HIVAIDS ecdc_flu ECDC_Outbreaks ecdc_eu\\n\\nU.S. CDC Accounts5\\n\\ncdcgov cdcdirector CDC_eHealth CDCespanol BRFSS CDCasthma CDC_DASH CDCDiabetes\\ncdc_drh CDCEnvironment CDC_Cancer CDC_EIDjournal CDC_EPHTracking CDC_Genomics\\nCDC_HIVAIDS CDCMicrobeNet CDC_NCBDDD CDC_NCEZID CDC_TB CDC_AMD\\nCDCChronic CDCEmergency CDCFlu CDCGlobal CDCGreenHealthy CDCHaiti\\nCDCHeart_Stroke US_CDCIndia CDChep CDCInjury CDCKenya CDCMakeHealthEZ\\nCDCMMWR CDCNPIN CDCObesity cdcpcd CDCRwanda CDCsouthafrica CDCSTD\\nCDCTobaccofree CDCTravel CPSTF DrDeanCDC DrKhabbazCDC DrMartinCDC\\nDrMerminCDC DrNancyM_CDC DrReddCDC MillionHeartsUS NCHStats niosh NIOSHMining\\nNIOSH_MVSafety NIOSH_NPPTL NIOSH_TWH nioshbreathe NIOSHConstruct NIOSHespanol\\nNIOSHFACE nioshfishing nioshnoise NIOSHoilandgas WTCHealthPrgm\\n\\nOther Public Health Accounts\\n\\nWHO InjectionSafety\\n\\nwalk through our envisioned public health use case; (4) we per-\\nform extensive statistical testing to compare our models against\\nthe baselines, finding that GPT-2 can effectively capture semantics\\nand sentiment in typical response distributions to messages in our\\ntest sets; and (5) we conclude with a discussion of limitations and\\nfuture directions of our work including a review of related works\\nfrom the natural language generation (NLG) literature. We have\\nreleased our data and code on GitHub,1and, in compliance with the\\nTwitter content redistribution policy,2we only publish the tweet\\nIDs corresponding to the actual tweets used in this work.\\n2 DATA COLLECTION\\nAs in [20], we used the Twitter streaming API to collect a random\\nsample of tweets during the collection periods for each respective\\ndataset (COVID-19 & Vaccine public health messages). We collected\\nthese datasets by filtering the streaming API using COVID-19 and\\nVaccine related keywords, respectively. Since we aim to study the\\nresponse distributions to public health tweets, we focus only on\\nthose tweets which have responses either in quote-tweet or direct\\nreply form. Collection of these tweets and their responses was done\\nvia Tweepy, a python library for accessing the Twitter API, and they\\nwere stored in Elasticsearch3for efficient search and retrieval. Each\\ndataset was then filtered by screen name to include only tweets from\\npublic health organizations and their responses. The organizations\\nselected and their respective accounts are shown in Table 1.\\n2.1 COVID-19 Public Health Messaging\\nOur dataset of COVID-19 related public health messages and their\\nresponses contains 8,475 original messages authored by these ac-\\ncounts and 70,331 responses to these messages. The original mes-\\nsages were authored between March 1st, 2020 and September 30th,\\n2020. The majority of the collected tweets originate from the WHO\\naccount, followed by CDCgov, as seen in Figure 1. This data was\\ncollected as follows: (1) We collected 295,468,580 original tweets\\nfrom the Twitter Streaming API over the collection period using\\nthe same set of COVID-19 related filter keyphrases as used in [20];\\n\\n1Available at https://github.com/TheRensselaerIDEA/generative-response-modeling\\n2See https://developer.twitter.com/en/developer-terms/agreement-and-policy\\n3See https://www.elastic.co/elasticsearch\\n4See https://www.ecdc.europa.eu/en/about-us/press-and-media/ecdc-social-media\\n5See https://www.cdc.gov/socialmedia/tools/Twitter.html\\n\\nFigure 1:Top ten public health accounts by number of tweets for\\nthe COVID-19 and Vaccines datasets.\\n(2) These tweets were filtered to keep only those that were in re-\\nsponse to (either via quote or direct reply) a message from one of\\nthe public health accounts in Table 1; (3) As the streaming API re-\\nturned quoted tweets but not (direct) replied-to tweets, these were\\nseparately requested using the Twitter Status API.\\n2.2 Vaccine Public Health Messaging\\nOur dataset of Vaccine related public health messages and their re-\\nsponses contains 3,060 original messages authored by the accounts\\nin Table 1 and 61,009 responses to these messages. The original\\nmessages were authored between October 1st, 2021 and January\\n31st, 2022. The majority of the collected tweets originate from the\\nWHO account, followed by CDCgov, as is the case in the COVID-19\\ndataset (see Figure 1). This dataset was collected by the same proce-\\ndure outlined for the COVID-19 dataset in Section 2.1, with the only\\ndifference being the filter keyphrases. Here, all filter keyphrases\\nwere vaccine related, selected by doing a term-frequency analy-\\nsis on a random sample of approximately 10,000 tweets collected\\nusing the keyphrase “vaccine” (see our code release for complete\\nlisting). Using these keyphrases we collected 52,282,174 original\\ntweets before filtering for responses to the public health accounts.\\n3 EXPERIMENTAL SETUP\\nAs discussed in Section 1, we train GPT-2 on the task of tweet\\nresponse generation. This task is notably different from other text\\ngeneration tasks in that it suffers from an extreme form of the\\none-to-many problem seen in dialogue response generation, where\\nan utterance can have many equally valid responses [8,10,24].\\nSpecifically, each public health message in our datasets has multiple\\nresponses, and we train GPT-2 to model thedistributionof typical\\nresponses for each message. This means that the same message\\nfrom the same author is repeated many times in the training set,\\neach instance with a different target response. Once trained in this\\nmanner, temperature sampling can be used to generate a range of\\nlikely responses to an input author and message.\\nAs previously mentioned, we evaluate this method by comparing\\nmodel-generated responses to known responses. Specifically, given\\na known sample of responses to a particular message and author,\\nwe need to determine how well a model-generated sample of re-\\nsponses captures the semantics (e.g., meaning, topic, intent) and the\\nsentiment polarity (e.g., positive, negative, neutral) of the known\\nresponses. This is akin to measuring retrievalrecall- how well the\\nmodel-generated response distribution “covers” that of the ground-\\ntruth. To measure sentiment we use a publicly available RoBERTa\\n2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reader.getXmpMetadata().pdf_keywords\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "ahK3UwqgU6wI",
        "outputId": "86ae8fba-aee8-4212-d72a-237c14b8a27d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tweet response generation, sentiment analysis, public health, COVID-19, vaccines'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reader.getXmpMetadata().pdf_pdfversion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "6mL_ZUS3SzOq",
        "outputId": "fd05d5c1-39d3-4fb0-de46-f155b6aaf950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reader.getPage(2-1).get_contents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "643XUcvQahhG",
        "outputId": "1d6805d3-8942-4007-ce90-802704e24855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method PageObject.get_contents of {'/Type': '/Page', '/Annots': [IndirectObject(91, 0), IndirectObject(92, 0), IndirectObject(93, 0), IndirectObject(94, 0), IndirectObject(95, 0), IndirectObject(96, 0), IndirectObject(97, 0), IndirectObject(98, 0), IndirectObject(99, 0), IndirectObject(100, 0), IndirectObject(101, 0), IndirectObject(102, 0), IndirectObject(103, 0), IndirectObject(104, 0), IndirectObject(105, 0), IndirectObject(106, 0), IndirectObject(107, 0), IndirectObject(108, 0), IndirectObject(109, 0), IndirectObject(110, 0), IndirectObject(111, 0), IndirectObject(112, 0), IndirectObject(113, 0), IndirectObject(114, 0), IndirectObject(115, 0), IndirectObject(116, 0), IndirectObject(117, 0), IndirectObject(118, 0), IndirectObject(119, 0), IndirectObject(120, 0), IndirectObject(121, 0), IndirectObject(122, 0), IndirectObject(123, 0), IndirectObject(124, 0), IndirectObject(125, 0), IndirectObject(126, 0), IndirectObject(127, 0), IndirectObject(128, 0), IndirectObject(129, 0), IndirectObject(130, 0), IndirectObject(131, 0), IndirectObject(132, 0)], '/Contents': IndirectObject(133, 0), '/MediaBox': [0, 0, 612, 792], '/Parent': IndirectObject(12, 0), '/Resources': IndirectObject(134, 0)}>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import *\n",
        "import pprint\n",
        "reader = PdfFileReader(\"paperOAI.pdf\")\n",
        "for page in reader.pages:\n",
        "    try :\n",
        "        for annot in page[\"/Annots\"] :\n",
        "            print (annot.getObject())   \n",
        "            print (\"\")\n",
        "    except : \n",
        "        # there are no annotations on this page\n",
        "        pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHSrkUc2gRa_",
        "outputId": "fca75ce2-24ba-45fe-ea6b-b830e9ee143c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://orcid.org/0000-0002-5231-2239'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [138.837, 651.499, 227.517, 661.842]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://orcid.org/0000-0001-6433-9490'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [371.678, 648.88, 487.77, 661.842]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://orcid.org/0000-0003-3078-4566'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [141.824, 591.195, 223.761, 603.457]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://orcid.org/0000-0002-8782-105X'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [384.874, 593.114, 473.35, 603.086]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.WANG2021106568', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [151.311, 182.183, 161.642, 189.811]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.sanders2021unmasking', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [281.454, 149.307, 291.785, 156.934]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.9354776', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [146.535, 116.43, 152.697, 124.058]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.radford2019language', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [509.081, 372.914, 519.412, 380.542]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 107.00001, 558.7436, 127.81305], '/C': [1, 1, 0], '/QuadPoints': [372.48175, 127.81305, 558.7436, 127.81305, 372.48175, 121.95802, 558.7436, 121.95802, 317, 119, 376, 119, 317, 107.00001, 376, 107.00001], '/T': 'Alejandro Adorjan', '/Contents': 'What is upper (ground-truth) and lower (random-chance) bound baselines?\\n\\nUpper bound baselines are the best possible performance that can be achieved by a model, while lower bound baselines are the worst possible performance that can be achieved by a model.', '/CreationDate': \"D:20220702162411-07'00'\", '/M': \"D:20220702162411-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [442, 283, 471, 294], '/C': [1, 1, 0], '/QuadPoints': [442, 294, 471, 294, 442, 283, 471, 283], '/T': 'Alejandro Adorjan', '/Contents': 'What is a dataset in ML?\\n\\nA dataset is a collection of data that is used to train a machine learning model.', '/CreationDate': \"D:20220702162249-07'00'\", '/M': \"D:20220702162249-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [400, 305, 499, 316], '/C': [1, 1, 0], '/QuadPoints': [400, 316, 499, 316, 400, 305, 499, 305], '/T': 'Alejandro Adorjan', '/Contents': 'what is “random-chance” baselines ?\\n\\nA random-chance baseline is a performance metric that measures the likelihood of achieving a certain result by chance alone. This metric is used to compare the results of a model to the results that could be expected by chance, and to determine whether the model is performing better than random.', '/CreationDate': \"D:20220702162058-07'00'\", '/M': \"D:20220702162058-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [76, 671, 537, 707.47894], '/C': [1, 1, 0], '/QuadPoints': [85.04, 707.47894, 527.32104, 707.47894, 85.04, 696.375, 527.32104, 696.375, 76, 690, 537, 690, 76, 671, 537, 671], '/T': 'Alejandro Adorjan', '/Contents': \"Sumarize the paper Should we tweet this? Generative response modeling for\\npredicting reception of public health messaging on Twitter\\n\\nThe paper examines the feasibility of using a generative response model to predict the reception of public health messaging on Twitter. The model is based on a dataset of tweets from the Centers for Disease Control and Prevention (CDC) and tweets from the general public. The model is trained on a variety of factors, including the content of the tweets, the timing of the tweets, and the user's followers. The model is then used to predict the probability that a tweet will be retweeted, favorited, or replied to. The results show that the model is able to accurately predict the reception of public health messaging on Twitter.\", '/CreationDate': \"D:20220702184819-07'00'\", '/M': \"D:20220702184819-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [525, 337.99997, 558, 348.99997], '/C': [1, 1, 0], '/QuadPoints': [525, 348.99997, 558, 348.99997, 525, 337.99997, 558, 337.99997], '/T': 'Alejandro Adorjan', '/Contents': 'What is ground-truth baseline in ML?\\n\\nA ground-truth baseline is a standard against which to measure the performance of a machine learning algorithm. It is typically the performance of a simple, rule-based algorithm that is hard-coded with knowledge about the problem domain.', '/CreationDate': \"D:20220702161954-07'00'\", '/M': \"D:20220702161954-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [96, 212.99998, 178, 223.99998], '/C': [1, 1, 0], '/QuadPoints': [96, 223.99998, 178, 223.99998, 96, 212.99998, 178, 212.99998], '/T': 'Alejandro Adorjan', '/Contents': 'What is COVID-19 pandemic?\\n\\nThe COVID-19 pandemic is a global outbreak of the novel coronavirus. The outbreak began in China in December 2019 and has since spread to over 100 countries around the world. The World Health Organization has declared the outbreak a Public Health Emergency of International Concern. As of March 2020, over 100,000 cases of COVID-19 have been reported, with over 3,000 deaths. The majority of cases have been in China, but the virus is now spreading rapidly in other countries, including Italy, Iran, and South Korea.', '/CreationDate': \"D:20220702175442-07'00'\", '/M': \"D:20220702175442-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [53, 346, 294.04922, 366.17007], '/C': [1, 1, 0], '/QuadPoints': [241.22964, 366.17007, 294.04922, 366.17007, 241.22964, 360.315, 294.04922, 360.315, 53, 357, 92, 357, 53, 346, 92, 346], '/T': 'Alejandro Adorjan', '/Contents': 'What is the difference semantics and\\nsentiment?\\n\\nSemantics is the study of meaning in language. It is the study of how words and phrases are used in order to convey meaning. Sentiment is the emotional response that a person has to a piece of content.', '/CreationDate': \"D:20220702175353-07'00'\", '/M': \"D:20220702175353-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [59, 401, 126, 412.00003], '/C': [1, 1, 0], '/QuadPoints': [59, 412.00003, 126, 412.00003, 59, 401, 126, 401], '/T': 'Alejandro Adorjan', '/Contents': 'What is a generative model ?\\n\\nA generative model is a statistical model that can be used to generate new examples that are similar to the training data.', '/CreationDate': \"D:20220702175247-07'00'\", '/M': \"D:20220702175247-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [52, 278, 117, 289], '/C': [1, 1, 0], '/QuadPoints': [52, 289, 117, 289, 52, 278, 117, 278], '/T': 'Alejandro Adorjan', '/Contents': 'Extract 3 keywords: \\nThe way people respond to messaging from public health organiza-\\ntions on social media can provide insight into public perceptions\\non critical health issues, especially during a global crisis such as\\nCOVID-19. It could be valuable for high-impact organizations such\\nas the US Centers for Disease Control and Prevention (CDC) or\\nthe World Health Organization (WHO) to understand how these\\nperceptions impact reception of messaging on health policy recom-\\nmendations. We collect two datasets of public health messages and\\ntheir responses from Twitter relating to COVID-19 and Vaccines,\\nand introduce a predictive method which can be used to explore\\nthe potential reception of such messages. Specifically, we harness\\na generative model (GPT-2) to directly predict probable future re-\\nsponses and demonstrate how it can be used to optimize expected\\nreception of important health guidance. Finally, we introduce a\\nnovel evaluation scheme with extensive statistical testing which\\nallows us to conclude that our models capture the semantics and\\nsentiment found in actual public health responses.\\n\\n\\n\\nPublic health, social media, messaging, COVID-19, vaccines', '/CreationDate': \"D:20220702214728-07'00'\", '/M': \"D:20220702214728-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [77.00001, 478, 285, 489], '/C': [1, 1, 0], '/QuadPoints': [77.00001, 489, 285, 489, 77.00001, 478, 285, 478], '/T': 'Alejandro Adorjan', '/Contents': 'What is the (CDC)?\\n\\nCDC stands for the Centers for Disease Control and Prevention. It is a national public health institute in the United States.', '/CreationDate': \"D:20220702175204-07'00'\", '/M': \"D:20220702175204-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [423, 502.00003, 560, 513], '/C': [1, 1, 0], '/QuadPoints': [423, 513, 560, 513, 423, 502.00003, 560, 502.00003], '/T': 'Alejandro Adorjan', '/Contents': 'What are the state-of-the-art text generation models?\\n\\nThere is no one answer to this question as the state of the art in text generation models is constantly changing. Some recent examples of text generation models include the Transformer model, the GPT-2 model, and the XLNet model.', '/CreationDate': \"D:20220702175844-07'00'\", '/M': \"D:20220702175844-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [96, 147, 119, 158], '/C': [1, 1, 0], '/QuadPoints': [96, 158, 119, 158, 96, 147, 119, 147], '/T': 'Alejandro Adorjan', '/Contents': 'What is (NLP)?\\n\\nNLP is a form of artificial intelligence that is used to interpret and understand human language. It is used to analyze text and identify patterns that can be used to make predictions or recommendations.', '/CreationDate': \"D:20220702175521-07'00'\", '/M': \"D:20220702175521-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 238.99997, 558.20575, 270.2791], '/C': [1, 1, 0], '/QuadPoints': [449.25296, 270.2791, 558.20575, 270.2791, 449.25296, 264.42404, 558.20575, 264.42404, 317.955, 259.32004, 558.20245, 259.32004, 317.955, 253.46497, 558.20245, 253.46497, 317, 249.99998, 507, 249.99998, 317, 238.99997, 507, 238.99997], '/T': 'Alejandro Adorjan', '/Contents': 'What ML algorithm can we apply if we use a : \"rigorous statistical testing we\\nfind that our models are able to generate responses consistent with\\nknown samples in terms of semantics and sentiment\"\\n\\nA supervised learning algorithm could be used in this case, such as a support vector machine or a decision tree.\\n\\nCan you show me an example in python to try them?\\n\\nHere is an example of a support vector machine applied to sentiment analysis:\\n\\nhttp://scikit-learn.org/stable/auto_examples/svm/plot_sentiment_analysis.html\\n\\nCan you show me the source code ?\\n\\nThe source code for the example above can be found here:\\n\\nhttp://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC', '/CreationDate': \"D:20220702180542-07'00'\", '/M': \"D:20220702180542-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 195, 432.99997, 206.00002], '/C': [1, 1, 0], '/QuadPoints': [317, 206.00002, 432.99997, 206.00002, 317, 195, 432.99997, 195], '/T': 'Alejandro Adorjan', '/Contents': \"What are social media content managers? \\n\\nA social media content manager is a professional who creates and manages content for social media sites.\\n\\nfor example ?\\n\\nSome social media content managers work for companies and organizations, creating and managing content for the company's social media accounts. Others are self-employed, working with a variety of clients to create and manage social media content.\\n\\ncan you name 3 most important media content managers?\\n\\n1. Facebook Content Manager\\n2. Twitter Content Manager\", '/CreationDate': \"D:20220702180230-07'00'\", '/M': \"D:20220702180230-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [67, 465.99997, 200, 478], '/C': [1, 1, 0], '/QuadPoints': [67, 478, 200, 478, 67, 465.99997, 200, 465.99997], '/T': 'Alejandro Adorjan', '/Contents': 'Who is World Health Organization (WHO)?\\n\\nThe World Health Organization (WHO) is a specialized agency of the United Nations that is concerned with international public health.', '/CreationDate': \"D:20220702175128-07'00'\", '/M': \"D:20220702175128-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [489.00003, 107.00001, 532, 119], '/C': [1, 1, 0], '/QuadPoints': [489.00003, 119, 532, 119, 489.00003, 107.00001, 532, 107.00001], '/T': 'Alejandro Adorjan', '/Contents': 'What visual tools are available to explore ML results?\\n\\n\\nThere are many visual tools available to explore ML results. Some of the more popular ones include:\\n\\n-TensorBoard\\n-Keras\\n-matplotlib\\n-seaborn\\n-pandas\\n-numpy', '/CreationDate': \"D:20220702180716-07'00'\", '/M': \"D:20220702180716-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [436, 228.00002, 508, 238.99997], '/C': [1, 1, 0], '/QuadPoints': [436, 238.99997, 508, 238.99997, 436, 228.00002, 508, 228.00002], '/T': 'Alejandro Adorjan', '/Contents': 'What are public health issues?\\n\\nPublic health issues are those which concern the health of the population as a whole. They include such matters as immunization against communicable diseases, control of environmental factors that may have an impact on health, and promotion of healthy lifestyles.', '/CreationDate': \"D:20220702182011-07'00'\", '/M': \"D:20220702182011-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [479, 370, 559, 382], '/C': [1, 1, 0], '/QuadPoints': [479, 382, 559, 382, 479, 370, 559, 370], '/T': 'Alejandro Adorjan', '/Contents': 'Resume in 500 words the article: \\nLanguage models are unsupervised multitask learners.\\n\\nIn natural language processing, a language model is a probabilistic model that assigns probabilities to sequences of words. A language model is a type of statistical model for predicting the next word in a sequence given the sequence of words already observed.\\n\\nLanguage models are used in a number of applications such as speech recognition, machine translation, and spelling correction.\\n\\nA language model is typically trained on a large corpus of text such as news articles or books. The training data is used to estimate the probabilities of different sequences of words.\\n\\nThe most common type of language model is the n-gram model. An n-gram is a sequence of n words. The n-gram model estimates the probabilities of different n-grams occurring in a sequence.\\n\\nThe n-gram model is a simple statistical model that makes a number of simplifying assumptions. However, it has been found to be surprisingly effective at modeling natural language data.\\n\\nLanguage models are unsupervised multitask learners. That is, they learn from data without any supervision or task-specific training. This makes them very powerful tools for NLP applications.', '/CreationDate': \"D:20220702181932-07'00'\", '/M': \"D:20220702181932-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [544, 480, 558, 490.99997], '/C': [1, 1, 0], '/QuadPoints': [544, 490.99997, 558, 490.99997, 544, 480, 558, 480], '/T': 'Alejandro Adorjan', '/Contents': 'What is sentiment analysis?\\n\\nSentiment analysis is the process of determining whether a piece of writing is positive, negative, or neutral. It can be used to analyze reviews, articles, social media posts, or any other type of text.\\n\\nShow me an python example of sentiment analysis\\n\\nHere is a very basic example of sentiment analysis using the TextBlob library in Python:\\n\\nfrom textblob import TextBlob\\ntext = \"This is a great movie!\"\\nblob = TextBlob(text)\\nprint(blob.sentiment)\\n# returns Sentiment(polarity=0.8, subjectivity=0.75)\\nIn this example, the TextBlob library is used to analyze a piece of text and determine that it is positive.\\n\\nShow me a more complex example.\\n\\nHere is a more complex example of sentiment analysis using the VADER library in Python:\\n\\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\\ntext = \"I hate this movie!\"\\nanalyzer = SentimentIntensityAnalyzer()\\nscores = analyzer.polarity_scores(text)\\nprint(scores)\\n# returns {\\'neg\\': 0.706, \\'neu\\': 0.294, \\'pos\\': 0.0, \\'compound\\': -0.4404}\\nIn this example, the VADER library is used to analyze a piece of text and determine that it is negative.', '/CreationDate': \"D:20220702180054-07'00'\", '/M': \"D:20220702180054-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [117, 637, 250, 649], '/C': [1, 1, 0], '/QuadPoints': [117, 649, 250, 649, 117, 637, 250, 637], '/T': 'Alejandro Adorjan', '/Contents': 'Where is Rensselaer Polytechnic Institute?\\n\\nRensselaer Polytechnic Institute is located in Troy, New York, USA.', '/CreationDate': \"D:20220702181311-07'00'\", '/M': \"D:20220702181311-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'Hfootnote.4', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [137.724, 675.435, 142.763, 683.448]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'Hfootnote.5', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [119.055, 652.587, 124.094, 660.601]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'Hfootnote.1', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [189.347, 450.582, 195.219, 462.433]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'Hfootnote.2', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [190.502, 439.623, 196.375, 451.474]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.sanders2021unmasking', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [77.058, 394.548, 87.39, 402.176]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'Hfootnote.3', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [152.102, 295.918, 157.975, 305.756]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'table.caption.5', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [265.215, 261.028, 271.377, 271.297]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'figure.caption.6', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [233.055, 170.105, 239.3, 180.373]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.sanders2021unmasking', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [280.107, 139.241, 290.439, 146.869]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://github.com/TheRensselaerIDEA/generative-response-modeling'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [90.961, 114.913, 294.503, 125.317]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://developer.twitter.com/en/developer-terms/agreement-and-policy'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [67.257, 106.501, 275.754, 116.905]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://www.elastic.co/elasticsearch'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [67.257, 98.089, 171.333, 108.493]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://www.ecdc.europa.eu/en/about-us/press-and-media/ecdc-social-media'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [67.131, 89.677, 290.314, 100.081]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://www.cdc.gov/socialmedia/tools/Twitter.html'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [67.257, 81.265, 217.848, 91.67]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'table.caption.5', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [447.238, 537.753, 453.412, 548.187]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'table.caption.5', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [350.054, 457.592, 356.299, 467.86]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'figure.caption.6', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [385.186, 413.756, 391.264, 424.19]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'subsection.2.1', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [496.041, 402.846, 508.138, 413.066]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'section.1', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [409.022, 301.637, 415.267, 310.987]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.galley-etal-2015-deltableu', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [522.469, 258.896, 528.631, 266.524]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.gupta-etal-2019-investigating', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [531.64, 258.896, 541.971, 266.524]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.8682634', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [544.98, 258.976, 555.311, 266.524]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 223, 558.2015, 243.93205], '/C': [1, 1, 0], '/QuadPoints': [358.0749, 243.93205, 558.2015, 243.93205, 358.0749, 238.07698, 558.2015, 238.07698, 317, 235, 424.99997, 235, 317, 223, 424.99997, 223], '/T': 'Alejandro Adorjan', '/Contents': 'Create a python code of how to train GPT-2 to model the distribution of typical\\nresponses in Tweeter.\\n\\n1. Install the GPT-2 model:\\n\\npip install gpt-2-simple\\n\\n2. Train the GPT-2 model:\\n\\ngpt-2-simple train --dataset=tweeter.txt', '/CreationDate': \"D:20220702163820-07'00'\", '/M': \"D:20220702163820-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [53, 493.99997, 294.04367, 514.34406], '/C': [1, 1, 0], '/QuadPoints': [258.29767, 514.34406, 294.04367, 514.34406, 258.29767, 508.48904, 294.04367, 508.48904, 53, 505.00003, 177, 505.00003, 53, 493.99997, 177, 493.99997], '/T': 'Alejandro Adorjan', '/Contents': 'What is semantics and sentiment in typical response?\\n\\nSemantics is the study of meaning in language. It can be used to analyze how the meaning of a word or phrase changes in different contexts. Sentiment is the emotional reaction that people have to a piece of content.', '/CreationDate': \"D:20220702162548-07'00'\", '/M': \"D:20220702162548-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [148, 505.00003, 173, 516], '/C': [1, 1, 0], '/QuadPoints': [148, 516, 173, 516, 148, 505.00003, 173, 505.00003], '/T': 'Alejandro Adorjan', '/Contents': 'What is GPT-2?\\n\\nGPT-2 is an open-source natural language processing (NLP) model which was created by OpenAI. It is a large-scale unsupervised language model which can generate coherent paragraphs of text.', '/CreationDate': \"D:20220702162458-07'00'\", '/M': \"D:20220702162458-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [432, 300.99997, 479, 312], '/C': [1, 1, 0], '/QuadPoints': [432, 312, 479, 312, 432, 300.99997, 479, 300.99997], '/T': 'Alejandro Adorjan', '/Contents': 'How to train GPT-2?\\n\\nThere is no one-size-fits-all answer to this question, as the best way to train GPT-2 will vary depending on the specific task you are using it for. However, some tips on how to train GPT-2 effectively include:\\n\\n1. Use a large amount of training data: The more data you use to train GPT-2, the better it will perform.\\n\\n2. Use high-quality training data: The quality of the training data is also important. Make sure to use data that is representative of the real-world data you want GPT-2 to be able to generate.\\n\\n3. Train for a long time: GPT-2 takes a long time to train, so be patient.\\n\\n4. Try different hyperparameter settings: The hyperparameters of GPT-2 can have a significant impact on its performance. Try different settings to see what works best on your task.', '/CreationDate': \"D:20220702163623-07'00'\", '/M': \"D:20220702163623-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [415, 424, 448.99997, 436], '/C': [1, 1, 0], '/QuadPoints': [415, 436, 448.99997, 436, 415, 424, 448.99997, 424], '/T': 'Alejandro Adorjan', '/Contents': 'Notar que una vez que se accede ya puede quedar la referencia', '/CreationDate': \"D:20220702163457-07'00'\", '/M': \"D:20220702163457-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [124, 392.00003, 223, 403.00003], '/C': [1, 1, 0], '/QuadPoints': [124, 403.00003, 223, 403.00003, 124, 392.00003, 223, 392.00003], '/T': 'Alejandro Adorjan', '/Contents': 'What is Twitter streaming API ?\\n\\nThe Twitter streaming API is a set of tools used by developers to access Twitter data in real time. The API provides access to tweets, users, and other data from the Twitter platform. The API is designed to be used by applications that need to process tweets in real time, such as live-tweeting applications or tweet analysis tools.', '/CreationDate': \"D:20220702162800-07'00'\", '/M': \"D:20220702162800-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [148, 450.99997, 190, 462.99997], '/C': [1, 1, 0], '/QuadPoints': [148, 462.99997, 190, 462.99997, 148, 450.99997, 190, 450.99997], '/T': 'Alejandro Adorjan', '/Contents': 'What is Github?\\n\\nGithub is a web-based code hosting service that uses the Git revision control system. It is primarily used for software development, but can also be used to keep track of changes in any type of file.', '/CreationDate': \"D:20220702162714-07'00'\", '/M': \"D:20220702162714-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [87.00001, 461, 260, 473], '/C': [1, 1, 0], '/QuadPoints': [87.00001, 473, 260, 473, 87.00001, 461, 260, 461], '/T': 'Alejandro Adorjan', '/Contents': 'What is natural language generation (NLG) literature.\\n\\nNLG literature is a type of literature that uses natural language to generate text. This can be done using a computer program or by using a human writer.', '/CreationDate': \"D:20220702162636-07'00'\", '/M': \"D:20220702162636-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [277, 136.99998, 296, 147.99998], '/C': [1, 1, 0], '/QuadPoints': [277, 147.99998, 296, 147.99998, 277, 136.99998, 296, 136.99998], '/T': 'Alejandro Adorjan', '/Contents': 'Summary the paper \"Unmasking the conversation on\\nmasks: Natural language processing for topical sentiment analysis of COVID-19\\nTwitter discourse\" in 100 words\\n\\nThe paper discusses the use of natural language processing for sentiment analysis of tweets about masks during the COVID-19 pandemic. The authors used a topic modeling approach to identify tweets about masks, and then used a sentiment analysis approach to classify the tweets as positive, negative, or neutral. The results showed that the majority of tweets about masks were positive, and that the sentiment of tweets about masks varied depending on the topic of the tweet.', '/CreationDate': \"D:20220702163329-07'00'\", '/M': \"D:20220702163355-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Text', '/Rect': [277, 136.99998, 296, 147.99998], '/IRT': IndirectObject(121, 0), '/T': 'Alejandro Adorjan', '/Contents': 'Notar que debe acceder a la biblio', '/CreationDate': \"D:20220702163355-07'00'\", '/M': \"D:20220702163355-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [132, 170, 168.00002, 181], '/C': [1, 1, 0], '/QuadPoints': [132, 181, 168.00002, 181, 132, 170, 168.00002, 170], '/T': 'Alejandro Adorjan', '/Contents': 'Who is CDCgov?\\n\\nCDCgov is the website of the Centers for Disease Control and Prevention, a national public health institute in the United States. The CDC is responsible for protecting public health and promoting human well-being by providing leadership and direction for disease control and prevention.\\nWhat is the url of CDCgov?\\n\\nThe URL of CDCgov is https://www.cdc.gov/.', '/CreationDate': \"D:20220702163128-07'00'\", '/M': \"D:20220702163128-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 81.00002, 559.7195, 167.22008], '/C': [1, 1, 0], '/QuadPoints': [493.96033, 167.22008, 558.2026, 167.22008, 493.96033, 161.365, 558.2026, 161.365, 317.955, 156.26105, 559.1926, 156.26105, 317.955, 150.40602, 559.1926, 150.40602, 317.623, 145.30206, 559.7195, 145.30206, 317.623, 139.44699, 559.7195, 139.44699, 317.955, 134.34303, 558.2023, 134.34303, 317.955, 128.488, 558.2023, 128.488, 317.955, 123.38405, 558.20013, 123.38405, 317.955, 117.52898, 558.20013, 117.52898, 317.955, 112.42507, 558.19855, 112.42507, 317.955, 106.57, 558.19855, 106.57, 317.955, 101.46604, 559.7143, 101.46604, 317.955, 95.61102, 559.7143, 95.61102, 317, 92.00002, 340.00003, 92.00002, 317, 81.00002, 340.00003, 81.00002], '/T': 'Alejandro Adorjan', '/Contents': 'Can you explain me in few words what this paragraph means: \"Specifically, given\\na known sample of responses to a particular message and author,\\nwe need to determine how well a model-generated sample of responses captures the semantics (e.g., meaning, topic, intent) and the sentiment polarity (e.g., positive, negative, neutral) of the known\\nresponses. This is akin to measuring retrieval recall how well the model generated response distribution “covers” that of the groundtruth.\"\\n\\nThis paragraph is discussing how well a model can generate responses that match the meaning and sentiment of known responses. This is important in order to measure how well the model can generate appropriate responses.', '/CreationDate': \"D:20220702164305-07'00'\", '/M': \"D:20220702164305-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 158, 416.99997, 169.00002], '/C': [1, 1, 0], '/QuadPoints': [317, 169.00002, 416.99997, 169.00002, 317, 158, 416.99997, 158], '/T': 'Alejandro Adorjan', '/Contents': \"How is implemented using GPT-2 a model-generated responses? Get some python code please.\\n\\nI'm not sure what you're asking for exactly, but the GPT-2 model can be implemented in python using the open-source library huggingface transformers. You can find an example notebook here: https://huggingface.co/transformers/model_doc/gpt2.html\", '/CreationDate': \"D:20220702164106-07'00'\", '/M': \"D:20220702164106-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [96, 295, 158.00002, 306], '/C': [1, 1, 0], '/QuadPoints': [96, 306, 158.00002, 306, 96, 295, 158.00002, 295], '/T': 'Alejandro Adorjan', '/Contents': 'What is Elasticsearch3?\\n\\nElasticsearch is a search and analytics engine designed to help users find the information they need. It is based on the Lucene search engine library and can be used to search for documents, images, and other files.\\n\\nWhat is Lucene search engine library?\\n\\nThe Lucene search engine library is a Java-based library that provides indexing and search capabilities for text-based data. It is used by many applications to provide search functionality, including the Elasticsearch engine.', '/CreationDate': \"D:20220702163019-07'00'\", '/M': \"D:20220702163019-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [65, 303.99997, 97, 316], '/C': [1, 1, 0], '/QuadPoints': [65, 316, 97, 316, 65, 303.99997, 97, 303.99997], '/T': 'Alejandro Adorjan', '/Contents': 'What is Tweepy?\\nTweepy is a Python library for accessing the Twitter API.', '/CreationDate': \"D:20220702162855-07'00'\", '/M': \"D:20220702162855-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [349, 191.00002, 447, 201.99998], '/C': [1, 1, 0], '/QuadPoints': [349, 201.99998, 447, 201.99998, 349, 191.00002, 447, 191.00002], '/T': 'Alejandro Adorjan', '/Contents': \"What is temperature sampling in GPT-2? Explain me also with an example.\\n\\nGPT-2 temperature sampling is a method of tuning the model's output by sampling from a range of possible outputs, rather than just the most likely output. This can help the model to explore different possibilities and find a better overall solution. For example, if you are training a model to generate text, you might sample from a range of temperatures, rather than just the highest-probability output, in order to encourage the model to explore different possibilities and find a more interesting and diverse output.\", '/CreationDate': \"D:20220702163938-07'00'\", '/M': \"D:20220702163938-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [522, 81.00002, 560, 92.00002], '/C': [1, 1, 0], '/QuadPoints': [522, 92.00002, 560, 92.00002, 522, 81.00002, 560, 81.00002], '/T': 'Alejandro Adorjan', '/Contents': 'What is RoBERTa model?\\n\\nRoBERTa is a transformer-based machine learning model designed to provide state-of-the-art performance on a wide range of natural language processing tasks. RoBERTa is a variant of the popular BERT model and is designed to optimize performance on the task of natural language understanding.\\n\\nAre other transformer-base ML models ?\\n\\nYes. Other transformer-based machine learning models include GPT-2 and XLNet.', '/CreationDate': \"D:20220702164412-07'00'\", '/M': \"D:20220702164412-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [52, 439, 294.0427, 459.55008], '/C': [1, 1, 0], '/QuadPoints': [221.79543, 459.55008, 294.0427, 459.55008, 221.79543, 453.695, 294.0427, 453.695, 52, 452, 196, 452, 52, 439, 196, 439], '/T': 'Alejandro Adorjan', '/Contents': 'Summary the terms of compliance with the\\nTwitter content redistribution policy\\n\\nThe Twitter content redistribution policy is as follows:\\n\\n1. You may not redistribute or sell Twitter content without prior written consent from Twitter.\\n\\n2. If you wish to redistribute or sell Twitter content, you must first enter into a written agreement with Twitter.\\n\\n3. Under the agreement, you may only redistribute or sell Twitter content in certain specified ways, and you must comply with all Twitter policies and guidelines.\\n\\n4. You may not modify or create derivative works of Twitter content.\\n\\n5. You may not sublicense, lease, or otherwise transfer any rights to redistribute or sell Twitter content to any third party.\\n\\n6. If you violate any of these terms, your agreement with Twitter will automatically terminate, and you will be required to stop redistributing or selling Twitter content.', '/CreationDate': \"D:20220702180949-07'00'\", '/M': \"D:20220702180949-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [57, 652, 124, 661], '/C': [1, 1, 0], '/QuadPoints': [57, 661, 124, 661, 57, 652, 124, 652], '/T': 'Alejandro Adorjan', '/Contents': 'what are the official twitter accounts @ of : cdcgov cdcdirector\\n\\nThe official twitter account for the Centers for Disease Control and Prevention is @CDCgov. The official twitter account for the director of the CDC is @CDCDirector.', '/CreationDate': \"D:20220702180858-07'00'\", '/M': \"D:20220702180858-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [493.00003, 537, 549, 549], '/C': [1, 1, 0], '/QuadPoints': [493.00003, 549, 549, 549, 493.00003, 537, 549, 537], '/T': 'Alejandro Adorjan', '/Contents': 'Show me an exmple of code in python using streaming API\\n\\nimport tweepy\\nfrom tweepy import OAuthHandler\\n\\n#Twitter API credentials\\nconsumer_key = \"XXXXXXXXXXXXXXXXXXXXXXX\"\\nconsumer_secret = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\\naccess_key = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\\naccess_secret = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\\n\\n\\nauth = OAuthHandler(consumer_key, consumer_secret)\\nauth.set_access_token(access_key, access_secret)\\n\\napi = tweepy.API(auth)\\n\\n\\n#initialize a list to hold all the tweepy Tweets\\nalltweets = []\\t\\n\\n#make initial request for most recent tweets (200 is the maximum allowed count)\\nnew_tweets = api.user_timeline(screen_name = \"realDonaldTrump\",count=200)\\n\\n#save most recent tweets\\nalltweets.extend(new_tweets)\\n\\n#save the id of the oldest tweet less one\\noldest = alltweets[-1].id - 1\\n\\n#keep grabbing tweets until there are no tweets left to grab\\nwhile len(new_tweets) > 0:\\nprint (\"getting tweets before %s\" % (oldest))\\n\\n#all subsiquent requests use the max_id param to prevent duplicates\\nnew_tweets = api.user_timeline(screen_name = \"realDonaldTrump\",count=200,max_id=oldest)\\n\\n#save most recent tweets\\nalltweets.extend(new_tweets)\\n\\n#update the id of the oldest tweet less one\\noldest = alltweets[-1].id - 1\\n\\nprint (\"...%s tweets downloaded so far\" % (len(alltweets)))\\n\\n#transform the tweepy tweets into a 2D array that will populate the csv\\t\\nouttweets = [[tweet.id_str, tweet.created_at, tweet.text.encode(\"utf-8\")] for tweet in alltweets]\\n\\n#write the csv\\t\\nimport csv\\nwith open(\\'%s_tweets.csv\\' % screen_name, \\'wb\\') as f:\\nwriter = csv.writer(f)\\nwriter.writerow([\"id\",\"created_at\",\"text\"])\\nwriter.writerows(outtweets)\\n\\npass', '/CreationDate': \"D:20220702181205-07'00'\", '/M': \"D:20220702181205-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.DBLP:journals/corr/abs-1907-11692', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [56.026, 559.592, 66.357, 567.219]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'Hfootnote.6', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [92.643, 557.969, 98.515, 569.429]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.barbieri-etal-2020-tweeteval', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [137.838, 548.633, 143.999, 556.261]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.wang2020minilm', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [234.933, 472.001, 245.264, 479.548]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'Hfootnote.7', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [271.429, 469.907, 277.301, 481.758]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'table.caption.7', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [210.637, 182.791, 216.799, 193.06]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'Hfootnote.8', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [276.457, 147.409, 282.33, 159.259]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [99.149, 98.089, 286.159, 108.493]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [99.023, 89.677, 288.797, 100.081]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://huggingface.co/gpt2-large'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [99.149, 81.265, 196.679, 91.67]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'table.caption.8', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [545.332, 371.87, 551.494, 382.352]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.loshchilov2018decoupled', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [320.176, 340.979, 330.508, 348.607]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'table.caption.9', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [548.56, 273.213, 554.722, 283.482]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [165, 469, 277, 481.99997], '/C': [1, 1, 0], '/QuadPoints': [165, 481.99997, 277, 481.99997, 165, 469, 277, 469], '/T': 'Alejandro Adorjan', '/Contents': 'Where is the available MiniLM model?\\n\\nThe available MiniLM model is in the \"Models\" section of the NLP Architect website.\\nWhats the URL?\\n\\nThe URL for the NLP Architect website is https://nlparchitect.ai/\\n\\nWhat is it about? Explain pros and cons of using it.\\n\\nNLP Architect is a toolkit for natural language processing (NLP) that is developed by Intel. It is designed to be used by developers and data scientists who want to build NLP applications. The toolkit provides a variety of pre-trained models and algorithms that can be used for a variety of tasks, such as text classification, sequence labeling, and question answering. NLP Architect also includes a number of tools for debugging and visualizing NLP models.', '/CreationDate': \"D:20220702165234-07'00'\", '/M': \"D:20220702165234-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [77.00001, 415, 162.00002, 428.00003], '/C': [1, 1, 0], '/QuadPoints': [77.00001, 428.00003, 162.00002, 428.00003, 77.00001, 415, 162.00002, 415], '/T': 'Alejandro Adorjan', '/Contents': 'What is the difference between Train / Test Split?\\n\\nTrain / Test split is a method of splitting a dataset into two parts: a training set and a test set. The training set is used to train the model, while the test set is used to evaluate the model.\\n\\nWhats the best proportion of each one to use it?\\n\\nThere is no definitive answer to this question. It depends on the dataset and the model.', '/CreationDate': \"D:20220702165426-07'00'\", '/M': \"D:20220702165426-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [176.00002, 358.00003, 296, 368.99997], '/C': [1, 1, 0], '/QuadPoints': [176.00002, 368.99997, 296, 368.99997, 176.00002, 358.00003, 296, 358.00003], '/T': 'Alejandro Adorjan', '/Contents': \"How do you removing hyperlinks and emojis in a dataset?\\n.replace('', '')\\n.replace('', '')\\nCan you show me a complete example in python so I can try it?\\n\\nAssuming you have a list of strings called 'data':\\n\\nnew_data = []\\nfor d in data:\\nnew_data.append(d.replace('', '').replace('', ''))\\n\\nprint(new_data)\", '/CreationDate': \"D:20220702165907-07'00'\", '/M': \"D:20220702165907-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [174.00002, 502.00003, 212, 514], '/C': [1, 1, 0], '/QuadPoints': [174.00002, 514, 212, 514, 174.00002, 502.00003, 212, 502.00003], '/T': 'Alejandro Adorjan', '/Contents': 'Create a python example with cosine semantic similarity \\n\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nfrom sklearn.metrics.pairwise import cosine_similarity\\ntext = [\"London Paris London\", \"Paris Paris London\"]\\ncv = CountVectorizer()\\ncount_matrix = cv.fit_transform(text)\\n\\n#Print the cosine similarity scores\\nprint(cosine_similarity(count_matrix))', '/CreationDate': \"D:20220702164819-07'00'\", '/M': \"D:20220702164819-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [138, 502.00003, 212, 514], '/C': [1, 1, 0], '/QuadPoints': [138, 514, 212, 514, 138, 502.00003, 212, 502.00003], '/T': 'Alejandro Adorjan', '/Contents': \"What is semantic similarity? \\nSemantic similarity is the degree to which two concepts are related.\\nCreate an example in python that use a dataset an apply semantic similarity\\n\\nI couldn't find a good example in Python that uses a dataset and applies semantic similarity.\", '/CreationDate': \"D:20220702164707-07'00'\", '/M': \"D:20220702164707-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 327.00003, 346, 339], '/C': [1, 1, 0], '/QuadPoints': [317, 339, 346, 339, 317, 327.00003, 346, 327.00003], '/T': 'Alejandro Adorjan', '/Contents': 'What is a epochs in ML? \\n\\nA epoch is one complete cycle through the training data.\\n\\nWhat is the most promising epoch for training data?\\n\\nThe most promising epoch is the one where the training data results in the lowest error rate.\\n\\nCan you show me an example of lowest error rate\\n\\nThere is no definitive answer to this question since it can vary depending on the data and the model. However, typically, the lowest error rate is achieved when the model has converged, meaning that the weights have stabilized and are not changing much with each epoch.', '/CreationDate': \"D:20220702171147-07'00'\", '/M': \"D:20220702171147-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [260, 280.99997, 294, 292], '/C': [1, 1, 0], '/QuadPoints': [260, 292, 294, 292, 260, 280.99997, 294, 280.99997], '/T': 'Alejandro Adorjan', '/Contents': 'show me example of triples that can be used for fine-tuning GPT-2\\n\\n1. (Subject, Verb, Object)\\n\\n2. (Person, Action, Object)\\n\\n3. (Location, Adjective, Noun)', '/CreationDate': \"D:20220702170147-07'00'\", '/M': \"D:20220702170147-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [185, 480, 234, 492], '/C': [1, 1, 0], '/QuadPoints': [185, 492, 234, 492, 185, 480, 234, 480], '/T': 'Alejandro Adorjan', '/Contents': 'Create a python unit test to measure cosine similarity between embeddings.\\n\\nfrom sklearn.metrics.pairwise import cosine_similarity\\n\\ndef test_cosine_similarity(embeddings):\\n\\nassert cosine_similarity(embeddings[0], embeddings[1]) == 1.0', '/CreationDate': \"D:20220702165031-07'00'\", '/M': \"D:20220702165031-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [52, 480, 234, 492], '/C': [1, 1, 0], '/QuadPoints': [52, 492, 234, 492, 52, 480, 234, 480], '/T': 'Alejandro Adorjan', '/Contents': 'Create a python example to measure cosine similarity between embeddings.\\n\\nfrom sklearn.metrics.pairwise import cosine_similarity\\n\\nembeddings_1 = [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]\\nembeddings_2 = [[1, 1, 0, 0], [0, 1, 1, 0], [0, 0, 1, 1], [0, 0, 0, 1]]\\n\\nsimilarity = cosine_similarity(embeddings_1, embeddings_2)\\nprint(similarity)', '/CreationDate': \"D:20220702164920-07'00'\", '/M': \"D:20220702164920-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [52, 358.00003, 295.55673, 389.01904], '/C': [1, 1, 0], '/QuadPoints': [119.50539, 389.01904, 294.04318, 389.01904, 119.50539, 383.16397, 294.04318, 383.16397, 53.798, 378.06006, 295.55673, 378.06006, 53.798, 372.205, 295.55673, 372.205, 52, 368.99997, 70, 368.99997, 52, 358.00003, 70, 358.00003], '/T': 'Alejandro Adorjan', '/Contents': 'Explain to me: \"a sample size of 30 responses, ensuring that we can randomly select two distinct samples for the ground-truth base-line.\"\\n\\nA sample size of 30 responses means that we can randomly select two distinct samples for the ground-truth baseline. This ensures that the results of the study are not biased by the particular samples that were chosen.\\n\\nWhat statistical model should be use if you have 30 responses?\\n\\nThere is no definitive answer to this question, as it depends on the specific data and the research question. However, some common models that could be used with 30 responses include regression, ANOVA, and chi-square.', '/CreationDate': \"D:20220702165716-07'00'\", '/M': \"D:20220702165716-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [364, 337.99997, 448, 351], '/C': [1, 1, 0], '/QuadPoints': [364, 351, 448, 351, 364, 337.99997, 448, 337.99997], '/T': 'Alejandro Adorjan', '/Contents': 'What is a initial learning rate in ML?\\n\\nA initial learning rate is the step size that is used when training a machine learning model. This step size is used to determine how much the model weights are updated after each training iteration.\\n\\nWho pose this idea of initial learning rate?\\n\\nThe idea of an initial learning rate was first proposed by Geoffrey Hinton in his paper \"A Practical Guide to Training Restricted Boltzmann Machines\"\\n\\nShow me an example in python of using this learning rate concept\\n\\nHere is an example of using an initial learning rate in a Python machine learning script:\\n\\nfrom sklearn.neural_network import MLPClassifier\\n\\nclf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=10, alpha=1e-4,\\n\\nsolver=\\'sgd\\', tol=1e-4, random_state=1,\\n\\nlearning_rate_init=.1)\\n\\nclf.fit(X_train, y_train)\\n\\nprint(\"Training set score: %f\" % clf.score(X_train, y_train))\\n\\nprint(\"Test set score: %f\" % clf.score(X_test, y_test))', '/CreationDate': \"D:20220702170903-07'00'\", '/M': \"D:20220702170903-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [52, 546, 294.04172, 566.546], '/C': [1, 1, 0], '/QuadPoints': [99.771, 566.546, 294.04172, 566.546, 99.771, 560.691, 294.04172, 560.691, 52, 558.00006, 135, 558.00006, 52, 546, 135, 546], '/T': 'Alejandro Adorjan', '/Contents': 'What is a fine-tuned on the sentiment classification task of the\\nTweetEval benchmark?\\n\\nA fine-tuned on the sentiment classification task of the TweetEval benchmark is a model that has been specifically designed and trained to perform well on that particular task.', '/CreationDate': \"D:20220702164522-07'00'\", '/M': \"D:20220702164522-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [360, 348.99997, 560, 361.00003], '/C': [1, 1, 0], '/QuadPoints': [360, 361.00003, 560, 361.00003, 360, 348.99997, 560, 348.99997], '/T': 'Alejandro Adorjan', '/Contents': \"Explain to me what is Fine-tuning in ML?\\n\\nFine-tuning is the process of adjusting the hyperparameters of a machine learning model to optimize its performance on a specific dataset.\\n\\nWhat is the AdamW optimizer?\\n\\nAdamW is an optimizer proposed by Loshchilov & Hutter in the paper “Fixing Weight Decay Regularization in Adam”. It is a variant of the Adam optimizer, which is a popular choice for training deep learning models. AdamW is designed to address the issue of weight decay regularization in Adam, which can lead to suboptimal performance.\\n\\nCan you show me a python code example of using AdamW optimizer?\\n\\nHere is a simple example of using AdamW optimizer in Python:\\n\\nfrom keras.optimizers import AdamW\\n\\nopt = AdamW(lr=0.001, decay=1e-6)\\n\\nmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\\n\\nmodel.fit(x_train, y_train, epochs=10, batch_size=32)\", '/CreationDate': \"D:20220702170708-07'00'\", '/M': \"D:20220702170708-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [529, 192.99998, 558, 204.99998], '/C': [1, 1, 0], '/QuadPoints': [529, 204.99998, 558, 204.99998, 529, 192.99998, 558, 192.99998], '/T': 'Alejandro Adorjan', '/Contents': 'What scientific article do you recomend for reading groundtruth and random-chance baselines?\\n\\nThere is no one scientific article that would be recommended for reading groundtruth and random-chance baselines. However, there are a number of articles that could be useful in understanding these concepts. Some potential articles include:\\n\\n\"A tutorial on support vector machines for pattern recognition\" by Christopher J. C. Burges\\n\"Pattern Recognition and Machine Learning\" by Christopher M. Bishop\\n\"The Elements of Statistical Learning\" by Trevor Hastie, Robert Tibshirani, and Jerome Friedman', '/CreationDate': \"D:20220702182246-07'00'\", '/M': \"D:20220702182415-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Text', '/Rect': [529, 192.99998, 558, 204.99998], '/IRT': IndirectObject(161, 0), '/T': 'Alejandro Adorjan', '/Contents': 'What scientific article do you recomend for reading groundtruth and random-chance baselines?\\n\\nThere is no one scientific article that would be recommended for reading groundtruth and random-chance baselines. However, there are a number of articles that could be useful in understanding these concepts. Some potential articles include:\\n\\n\"A tutorial on support vector machines for pattern recognition\" by Christopher J. C. Burges\\n\"Pattern Recognition and Machine Learning\" by Christopher M. Bishop\\n\"The Elements of Statistical Learning\" by Trevor Hastie, Robert Tibshirani, and Jerome Friedman\\n\\nsumarize me in 100 words \"A tutorial on support vector machines for pattern recognition\"\\n\\nSupport vector machines are a type of machine learning algorithm that can be used for both classification and regression tasks. The algorithm works by finding a hyperplane that best separates the data points in the training set. For classification tasks, the data points are separated into two classes, and the hyperplane is chosen so that it maximizes the margin between the two classes. For regression tasks, the data points are separated into two groups, and the hyperplane is chosen so that it minimizes the sum of the squared errors.\\n\\nCan you show me an example in python ?\\n\\nYes. Below is a simple example of a support vector machine for a classification task. The dataset used is the Iris dataset, which includes three classes of Iris flowers.\\n\\n\\nimport numpy as np\\nfrom sklearn import datasets\\nfrom sklearn.svm import SVC\\n\\n# Load the Iris dataset\\niris = datasets.load_iris()\\nX = iris.data\\ny = iris.target\\n\\n# Create a support vector classifier\\nclf = SVC(kernel=\\'linear\\')\\n\\n# Fit the classifier to the data\\nclf.fit(X, y)\\n\\n# Predict the labels for the data\\ny_pred = clf.predict(X)\\n\\n# Calculate the accuracy\\naccuracy = np.mean(y_pred == y)\\n\\nprint(\"Accuracy:\", accuracy)', '/CreationDate': \"D:20220702182415-07'00'\", '/M': \"D:20220702182415-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 229, 559.7132, 260.26303], '/C': [1, 1, 0], '/QuadPoints': [517.1947, 260.26303, 559.7132, 260.26303, 517.1947, 254.40797, 559.7132, 254.40797, 317.955, 249.30406, 559.1925, 249.30406, 317.955, 243.44899, 559.1925, 243.44899, 317, 240, 440.99997, 240, 317, 229, 440.99997, 229], '/T': 'Alejandro Adorjan', '/Contents': 'Create an example in python that use the generation is done with beam sampling using num_beams=3, top_k=50,\\n\\ntop_p=0.95, and temperature=1.5.\\n\\nIn [ ]:\\n\\n# generation is done with beam sampling\\n\\nnum_beams = 3\\ntop_k = 50\\ntop_p = 0.95\\ntemperature = 1.5\\n\\n# input text\\ntext = \"The quick brown fox jumps over the lazy dog\"\\n\\n# load model\\nmodel = load_model(\\'gpt2_model.h5\\')\\n\\n# generate text\\ngenerated_text = generate(model, text, num_beams=num_beams, top_k=top_k, top_p=top_p, temperature=temperature)\\n\\nprint(generated_text)', '/CreationDate': \"D:20220702171636-07'00'\", '/M': \"D:20220702171636-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [405, 262.00003, 472, 273.00003], '/C': [1, 1, 0], '/QuadPoints': [405, 273.00003, 472, 273.00003, 405, 262.00003, 472, 262.00003], '/T': 'Alejandro Adorjan', '/Contents': 'What is the difference in fine-tuned model GPT-2 and GPT-3?\\n\\nThere is no significant difference between the two models. Both are equally effective at generating text.', '/CreationDate': \"D:20220702171537-07'00'\", '/M': \"D:20220702171537-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [348.00003, 306, 406, 317], '/C': [1, 1, 0], '/QuadPoints': [348.00003, 317, 406, 317, 348.00003, 306, 406, 306], '/T': 'Alejandro Adorjan', '/Contents': 'What is validation loss?\\n\\nValidation loss is a measure of how well a model is able to predict the outcomes of a new, unseen data set. It is typically used to tune model hyperparameters and to compare different models.\\n\\nCan you show me a python example of this?\\n\\nYes. The following code shows how to calculate validation loss for a logistic regression model using the scikit-learn library:\\n\\nfrom sklearn.linear_model import LogisticRegression from sklearn.metrics import log_loss X_train, y_train = # your training data X_val, y_val = # your validation data model = LogisticRegression() model.fit(X_train, y_train) y_pred = model.predict_proba(X_val) val_loss = log_loss(y_val, y_pred)', '/CreationDate': \"D:20220702171340-07'00'\", '/M': \"D:20220702171340-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [87.00001, 147, 282, 160.00002], '/C': [1, 1, 0], '/QuadPoints': [87.00001, 160.00002, 282, 160.00002, 87.00001, 147, 282, 147], '/T': 'Alejandro Adorjan', '/Contents': 'what does it mean fine-tune the 762 million parameter GPT-2 model?\\n\\nIt means to adjust the parameters of the GPT-2 model so that it better matches the data.', '/CreationDate': \"D:20220702170253-07'00'\", '/M': \"D:20220702170253-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [394, 295, 505.00003, 306], '/C': [1, 1, 0], '/QuadPoints': [394, 306, 505.00003, 306, 394, 295, 505.00003, 295], '/T': 'Alejandro Adorjan', '/Contents': 'What is lowest validation perplexity in ML?\\n\\n\\nThe lowest validation perplexity is the point at which the model is most accurate.', '/CreationDate': \"D:20220702171429-07'00'\", '/M': \"D:20220702171429-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [322, 642, 551.4166, 669.8894], '/C': [1, 1, 0], '/QuadPoints': [323.031, 669.8894, 548.6976, 669.8894, 323.031, 665.986, 548.6976, 665.986, 323.031, 662.9164, 545.9955, 662.9164, 323.031, 659.013, 545.9955, 659.013, 323.031, 655.9424, 551.4166, 655.9424, 323.031, 652.039, 551.4166, 652.039, 322, 651, 458, 651, 322, 642, 458, 642], '/T': 'Alejandro Adorjan', '/Contents': \"Create a python example for training this using GPT-3:\\n<|message|>Is your child worried about #COVID19? Learn the facts so you can answer your\\nchildren’s questions. Make sure to explain the simple things they can do, like washing their\\nhands often. Learn more here:<|author|>CDCgov<|response|>Great resource for parents and\\nteachers. #COVID19 #ProtectKidsHealth<|endoftext|> \\n\\nimport os\\nimport requests\\n\\nopen_ai_key = os.environ.get('OPEN_AI_KEY')\\n\\nurl = 'https://api.openai.com/v1/engines/davinci/completions'\\n\\nheaders = {\\n'Content-Type': 'application/json',\\n'Authorization': 'Bearer ' + open_ai_key\\n}\\n\\ndata = {\\n'context': 'Is your child worried about #COVID19? Learn the facts so you can answer your children’s questions. Make sure to explain the simple things they can do, like washing their hands often. Learn more here:',\\n'max_tokens': 50\\n}\\n\\nresponse = requests.post(url, headers=headers, json=data)\\nprint(response.json()['choices'][0]['text'])\", '/CreationDate': \"D:20220702170446-07'00'\", '/M': \"D:20220702170446-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [325, 495, 550, 527.4909], '/C': [1, 1, 0], '/QuadPoints': [377.422, 527.4909, 498.43863, 527.4909, 377.422, 521.86, 498.43863, 521.86, 325, 504, 550, 504, 325, 495, 550, 495], '/T': 'Alejandro Adorjan', '/Contents': 'Generate me examples for a ML Table : Model training statistics\\n\\nDataset # of train ex. # of val ex. # of epochs Final val PPL. Best val PPL. Model size (MB)\\n\\n1 100 10 5 0.1 0.01 1\\n\\n2 1000 100 10 0.5 0.05 10\\n\\n3 10000 1000 100 5.0 0.5 100', '/CreationDate': \"D:20220702182117-07'00'\", '/M': \"D:20220702182135-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Text', '/Rect': [325, 495, 550, 527.4909], '/IRT': IndirectObject(169, 0), '/T': 'Alejandro Adorjan', '/Contents': 'Notar que le agrega Model size', '/CreationDate': \"D:20220702182135-07'00'\", '/M': \"D:20220702182135-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'figure.caption.10', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [77.208, 398.806, 83.287, 409.075]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'section.5', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [185.872, 365.93, 192.034, 376.198]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'figure.caption.11', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [86.973, 311.677, 93.051, 321.946]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'section.5', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [82.733, 267.842, 88.979, 278.276]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 180.00002, 558.36865, 243.93205], '/C': [1, 1, 0], '/QuadPoints': [317.525, 243.93205, 558.2038, 243.93205, 317.525, 238.07698, 558.2038, 238.07698, 317.955, 232.97302, 558.1984, 232.97302, 317.955, 227.11801, 558.1984, 227.11801, 317.955, 222.01404, 558.36865, 222.01404, 317.955, 216.15898, 558.36865, 216.15898, 317.955, 211.05507, 558.20416, 211.05507, 317.955, 205.2, 558.20416, 205.2, 317.955, 200.09708, 558.2016, 200.09708, 317.955, 194.242, 558.2016, 194.242, 317, 191.00002, 461.00003, 191.00002, 317, 180.00002, 461.00003, 180.00002], '/T': 'Alejandro Adorjan', '/Contents': 'What are the advantages and dissadvantages of anticipating that public health organizations may find value in\\nbeing able to “preview” public reception to any potential message\\non health policy or recommendations. As such, we envision our\\nmethod being incorporated as a social media insights tool that\\ncan help avoid negative receptions where possible with the aim to\\nimprove adherence to health guidance.\\n\\nOne advantage of this tool is that it could help public health organizations to gauge public reaction to potential messages on health policy or recommendations. This could help them to avoid negative reactions and improve adherence to health guidance. However, there are also some potential disadvantages. For example, this tool could be abused to manipulate public opinion, or it could be used to target vulnerable people with misinformation.', '/CreationDate': \"D:20220702183203-07'00'\", '/M': \"D:20220702183203-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 337.99997, 371, 348.99997], '/C': [1, 1, 0], '/QuadPoints': [317, 348.99997, 371, 348.99997, 317, 337.99997, 371, 337.99997], '/T': 'Alejandro Adorjan', '/Contents': 'What is FDA approval?\\n\\n\\n\\nThe FDA approval process is a regulatory pathway that allows drugs and medical devices to be marketed in the United States. The process is overseen by the FDA, a federal agency that is responsible for protecting the public health by ensuring the safety and efficacy of drugs and medical devices. The FDA approval process is designed to ensure that new products are safe and effective for their intended use.', '/CreationDate': \"D:20220702183045-07'00'\", '/M': \"D:20220702183045-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [166.00002, 278, 253, 290.00003], '/C': [1, 1, 0], '/QuadPoints': [166.00002, 290.00003, 253, 290.00003, 166.00002, 278, 253, 278], '/T': 'Alejandro Adorjan', '/Contents': 'What is mean cosine similarity? \\n\\nThe cosine similarity is a measure of how similar two vectors are. The cosine of the angle between two vectors is a measure of how close they are to being the same.\\n\\nHow are apply in ML?\\n\\nThe cosine similarity can be used to determine how similar two vectors are. This can be used for instance to compute the similarity between two documents, or between two sets of words.\\n\\nCan you show me an example in python?\\n\\nThe following example shows how to compute the cosine similarity between two vectors in Python.\\n\\nimport numpy as np\\n\\ndef cosine_similarity(v1,v2):\\n\\ndot = np.dot(v1,v2)\\n\\nnorm = np.linalg.norm(v1)*np.linalg.norm(v2)\\n\\nreturn dot/norm\\n\\nv1 = np.array([1,2,3])\\n\\nv2 = np.array([4,5,6])\\n\\nprint(cosine_similarity(v1,v2))\\n\\nHow can I interepret this results?\\n\\nA result of 1.0 means that the two vectors are exactly the same. A result of 0 means that the two vectors are orthogonal, and a result of -1 means that the two vectors are exactly opposite.\\n\\nCan you explain me the lineal algebra concept of orthogonality?\\n\\nOrthogonality is a concept in linear algebra that refers to the relationship between two vectors that are perpendicular to each other. Two vectors are orthogonal if the angle between them is 90 degrees.\\n\\nHow this concept is asoated with a diagonal matrix?\\n\\nA diagonal matrix is a matrix whose diagonal elements are all non-zero. The orthogonality of a matrix is related to its diagonal elements. If a matrix is orthogonal, then its diagonal elements must be 1.\\n\\nan what about the expectral theorem?\\n\\nThe spectral theorem is a result from linear algebra that states that every matrix can be diagonalized. A matrix is diagonalizable if it can be transformed into a diagonal matrix through a similarity transformation.\\n\\nCan you show me an example of this theorem in python?\\n\\nThe following example shows how to diagonalize a matrix in Python.\\n\\nimport numpy as np\\n\\nA = np.array([[1,2,3],\\n\\n[4,5,6],\\n\\n[7,8,9]])\\n\\nw, v = np.linalg.eig(A)\\n\\nprint(w)\\n\\nprint(v)', '/CreationDate': \"D:20220702182937-07'00'\", '/M': \"D:20220702182937-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [361, 147, 402, 158], '/C': [1, 1, 0], '/QuadPoints': [361, 158, 402, 158, 361, 147, 402, 147], '/T': 'Alejandro Adorjan', '/Contents': \"What is ECDC_EU?\\n\\nECDC_EU is the European Centre for Disease Prevention and Control. It is a European Union agency whose mission is to strengthen Europe's defences against infectious diseases.\", '/CreationDate': \"D:20220702184044-07'00'\", '/M': \"D:20220702184044-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [348.00003, 81.00002, 521, 92.00002], '/C': [1, 1, 0], '/QuadPoints': [348.00003, 92.00002, 521, 92.00002, 348.00003, 81.00002, 521, 81.00002], '/T': 'Alejandro Adorjan', '/Contents': 'What is the difference between compute the mean and standard deviation ?\\n\\nThe mean is the sum of all the values in a data set divided by the number of values in the data set. The standard deviation is the square root of the sum of the squares of all the values in a data set divided by the number of values in the data set.\\n\\nHow are related ?\\n\\nThe mean and standard deviation are related in that they are both measures of central tendency. The mean is the average of all the values in a data set, while the standard deviation is a measure of how spread out the values in a data set are.\\n\\nCan you show me an example of this with money?\\n\\n\\n\\nSuppose you have a data set of the amounts of money people spend in a day. The mean of this data set would be the sum of all the values divided by the number of values. The standard deviation of this data set would be the square root of the sum of the squares of all the values divided by the number of values.\\n\\ncan you create a code in python of the previous example ?\\n\\nThere is no one correct answer to this question. Here is one possible way to calculate the mean and standard deviation of the amounts of money people spend in a day:\\n\\n# calculate the mean\\n\\ntotal = 0\\n\\nfor amount in amounts:\\n\\ntotal = total + amount\\n\\nmean = total / len(amounts)\\n\\n# calculate the standard deviation\\n\\ntotal = 0\\n\\nfor amount in amounts:\\n\\ntotal = total + (amount - mean)**2\\n\\nstandard_deviation = (total / len(amounts))**0.5\\n\\nprint(\"Mean:\", mean)\\n\\nprint(\"Standard deviation:\", standard_deviation)', '/CreationDate': \"D:20220702183732-07'00'\", '/M': \"D:20220702183732-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [331, 92.00002, 443, 102.99998], '/C': [1, 1, 0], '/QuadPoints': [331, 102.99998, 443, 102.99998, 331, 92.00002, 443, 92.00002], '/T': 'Alejandro Adorjan', '/Contents': \"Explain RoBERTa sentiment classifier\\n\\nThe RoBERTa sentiment classifier is a type of neural network that is designed to perform sentiment analysis. It is based on the Transformer architecture and is trained on a large corpus of text data. The RoBERTa sentiment classifier is able to identify the sentiment of a text by looking at the words used in the text and the context in which they are used.\\n\\nWhat is the source code of RoBERTa ?\\n\\nThe source code for RoBERTa is available on Github.\\n\\ncan you provide me the url?\\n\\nThe source code for RoBERTa is available at the following URL: https://github.com/pytorch/pytorch/tree/master/torch/nn/modules/transformer.\\n\\nWhat algorithms are simmilar to RoBERTa ?\\n\\nSome algorithms that are similar to RoBERTa include the BERT algorithm and the GPT-2 algorithm.\\n\\nExplain me a differente beetween these algorithms\\n\\nThere are a few differences between the RoBERTa, BERT, and GPT-2 algorithms. First, RoBERTa is based on the Transformer architecture, while BERT is based on the Bi-LSTM architecture. Second, RoBERTa is trained on a large corpus of text data, while BERT is trained on a smaller corpus of text data. Third, RoBERTa is able to identify the sentiment of a text, while BERT is not.\\n\\nShow me a pice of code in python using RoBERTa \\n\\nHere is a piece of code in Python that uses the RoBERTa sentiment classifier:\\n\\nfrom transformers import *\\n\\nmodel = RobertaModel.from_pretrained('roberta-base')\\n\\ninput_ids = torch.tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]) \\n\\noutputs = model(input_ids)\\n\\nlast_hidden_states = outputs[0]\", '/CreationDate': \"D:20220702183501-07'00'\", '/M': \"D:20220702183501-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [310, 465.00003, 482, 475], '/C': [1, 1, 0], '/QuadPoints': [310, 475, 482, 475, 310, 465.00003, 482, 465.00003], '/T': 'Alejandro Adorjan', '/Contents': 'What are sentence embeddings and sentiment scores?\\n\\nSentence embeddings are mathematical representations of text, designed to capture the meaning of a sentence. Sentiment scores are numerical scores assigned to a piece of text, typically ranging from -1 (very negative) to 1 (very positive), that indicate the overall emotional tone of the text.', '/CreationDate': \"D:20220702182526-07'00'\", '/M': \"D:20220702182526-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'figure.caption.12', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [135.866, 387.513, 142.111, 397.782]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.gupta-etal-2019-investigating', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [444.994, 345.69, 455.325, 353.318]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.bi2003regression', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [320.192, 312.894, 326.354, 320.442]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.bi2003regression', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [475.533, 204.182, 481.695, 211.729]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [73, 81.00002, 261, 92.00002], '/C': [1, 1, 0], '/QuadPoints': [73, 92.00002, 261, 92.00002, 73, 81.00002, 261, 81.00002], '/T': 'Alejandro Adorjan', '/Contents': 'Completa a python example and test case for max cosine similarity values for each test message.\\n\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nfrom sklearn.metrics.pairwise import cosine_similarity\\n\\ntext = [\"London Paris London\", \"Paris Paris London\"]\\ncv = CountVectorizer()\\ncount_matrix = cv.fit_transform(text)\\n\\nsimilarity_scores = cosine_similarity(count_matrix)\\nprint(similarity_scores)\\n\\n# Expected output: [[1. 0.8] [0.8 1. ]]', '/CreationDate': \"D:20220702184425-07'00'\", '/M': \"D:20220702184425-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [52, 113.99998, 295, 124.99999], '/C': [1, 1, 0], '/QuadPoints': [52, 124.99999, 295, 124.99999, 52, 113.99998, 295, 113.99998], '/T': 'Alejandro Adorjan', '/Contents': 'How to compute max pairwise cosine similarity between the sentence embedding?\\n\\nWe can use the cosine similarity metric to compute the maximum pairwise cosine similarity between the sentence embeddings.\\n\\nCan you show me a scientific article that use this concept?\\n\\nA recent scientific article that discusses the use of cosine similarity for sentence embedding comparison is \"A Systematic Comparison of Sentence Embedding Methods\" by Reimers and Gurevych (2017).', '/CreationDate': \"D:20220702184327-07'00'\", '/M': \"D:20220702184327-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [125, 160.00002, 178, 173], '/C': [1, 1, 0], '/QuadPoints': [125, 173, 178, 173, 125, 160.00002, 178, 160.00002], '/T': 'Alejandro Adorjan', '/Contents': \"What is Semantic Similarity?\\n\\nSemantic similarity is a measure of the similarity between two pieces of text, typically in terms of their meaning or content.\\n\\nWhat are the main scienfific references for Semantic Similarity?\\n\\nThe main scienfific references for Semantic Similarity are:\\n\\n1. Leacock, C. and Chodorow, M. (1998). Combining local context and WordNet similarity for word sense identification. In Proceedings of the 17th annual international ACM SIGIR conference on Research and development in information retrieval (SIGIR '98), pp.253-262.\\n\\n2. Resnik, P. (1995). Using information content to evaluate semantic similarity in a taxonomy. In Proceedings of the 14th international joint conference on Artificial intelligence (IJCAI '95), pp.448-453.\\n\\n3. Lin, D. (1998). An information-theoretic definition of similarity. In Proceedings of the 15th international conference on Machine learning (ICML '98), pp.296-304.\", '/CreationDate': \"D:20220702184211-07'00'\", '/M': \"D:20220702184211-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [516, 320.99997, 560, 333], '/C': [1, 1, 0], '/QuadPoints': [516, 333, 560, 333, 516, 320.99997, 560, 320.99997], '/T': 'Alejandro Adorjan', '/Contents': 'What is (AUC-REC)?\\n\\n(AUC-REC) is a formula that can be used to calculate the overall accuracy of a model. It takes into account both the true positive and true negative rates of the model, and provides a more complete picture of the model\\'s performance.\\n\\nCan you show me a pice of code in python ?\\n\\nYes. The code below shows how to calculate the AUC-REC for a binary classification model:\\n\\nfrom sklearn.metrics import roc_auc_score\\n\\ny_pred = model.predict(X_test)\\n\\nauc_rec = roc_auc_score(y_test, y_pred)\\n\\nprint(\"AUC-REC: %.3f\" % auc_rec)', '/CreationDate': \"D:20220702185330-07'00'\", '/M': \"D:20220702185330-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 343, 558.2041, 385.52106], '/C': [1, 1, 0], '/QuadPoints': [481.33688, 385.52106, 558.20013, 385.52106, 481.33688, 379.666, 558.20013, 379.666, 317.955, 374.56308, 558.2041, 374.56308, 317.955, 368.708, 558.2041, 368.708, 317.955, 363.6041, 558.201, 363.6041, 317.955, 357.74902, 558.201, 357.74902, 317, 355.00003, 442, 355.00003, 317, 343, 442, 343], '/T': 'Alejandro Adorjan', '/Contents': 'Is this reasonable for ML algorithm ? max instead of mean\\ncosine similarity so that primary ground-truth responses will be\\nconsidered “covered” by the model if at least one similar response\\nis predicted above a certain threshold, and covered by the model if\\nthe average cosine similarity of all similar responses is above a\\ncertain threshold.\\n\\nYes, this is a reasonable approach for an ML algorithm.', '/CreationDate': \"D:20220702185222-07'00'\", '/M': \"D:20220702185222-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 378.00003, 558.20056, 396.4801], '/C': [1, 1, 0], '/QuadPoints': [332.04318, 396.4801, 558.20056, 396.4801, 332.04318, 390.62503, 558.20056, 390.62503, 317, 387, 438, 387, 317, 378.00003, 438, 378.00003], '/T': 'Alejandro Adorjan', '/Contents': 'Simplify this concept : ground-truth baseline, one for the model evaluation, and one\\nfor the random-chance baseline.\\n\\nThere are three types of baselines: ground-truth, model evaluation, and random-chance.\\n\\nShow the differences and similarities \\n\\nGround-truth baselines are determined by humans and are used to measure the performance of models. Model evaluation baselines are calculated by machine learning models and are used to compare the performance of different models. Random-chance baselines are generated by random sampling and are used to determine whether a model is better than random chance.\\n\\nHow a human can interpret this models?\\n\\nA human can interpret the ground-truth and model evaluation baselines to understand how well a machine learning model is performing. The random-chance baseline can be used to determine whether a model is better than random chance.', '/CreationDate': \"D:20220702185102-07'00'\", '/M': \"D:20220702185102-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 81.00002, 558.19946, 101.46604], '/C': [1, 1, 0], '/QuadPoints': [317.955, 101.46604, 558.19946, 101.46604, 317.955, 95.61102, 558.19946, 95.61102, 317, 92.00002, 543, 92.00002, 317, 81.00002, 543, 81.00002], '/T': 'Alejandro Adorjan', '/Contents': 'Explain to me : accuracy is the percentage of examples for which the continuous\\ntarget value can be predicted within the given error tolerance.\\n\\nAccuracy is a measure of how well a model can predict a target value. The higher the accuracy, the better the model is at predicting the target value.\\n\\nExplain what is the target value and why is important?\\n\\nThe target value is the value that the model is trying to predict. It is important because it is the value that the model is trying to get closer to.\\n\\nShow me an example \\n\\nFor example, if the target value is 10 and the model predicts a value of 9, the accuracy is 90%.\\n\\nShow the code in python please\\n\\naccuracy = (10 - 9) / 10\\n\\naccuracy = 0.9', '/CreationDate': \"D:20220702192809-07'00'\", '/M': \"D:20220702192809-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 277, 397, 289], '/C': [1, 1, 0], '/QuadPoints': [317, 289, 397, 289, 317, 277, 397, 277], '/T': 'Alejandro Adorjan', '/Contents': 'What is the Pearson’s correlation?\\n\\nThe Pearson’s correlation is a statistical measure of the linear relationship between two variables.\\n\\nCan you show me an article that explains this?\\n\\nhttps://www.investopedia.com/terms/p/pearsons-correlation-coefficient.asp\\n\\nCan you express in latex?\\n\\nThe Pearson’s correlation coefficient is given by:\\n\\n\\\\rho_{X,Y} = \\\\frac{cov(X,Y)}{\\\\sigma_X \\\\sigma_Y}\\n\\nwhere\\n\\ncov(X,Y) is the covariance between X and Y\\n\\n\\\\sigma_X is the standard deviation of X\\n\\n\\\\sigma_Y is the standard deviation of Y', '/CreationDate': \"D:20220702185808-07'00'\", '/M': \"D:20220702185808-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 102.99998, 558.20404, 123.38405], '/C': [1, 1, 0], '/QuadPoints': [494.31198, 123.38405, 558.20404, 123.38405, 494.31198, 117.52898, 558.20404, 117.52898, 317, 113.99998, 342, 113.99998, 317, 102.99998, 342, 102.99998], '/T': 'Alejandro Adorjan', '/Contents': 'What does it means “accuracy” of the\\nmodel?\\n\\nThe accuracy of a model is the degree to which the model predicts the correct outcome.\\n\\nIs the only way to reference this concept?\\n\\nNo, there are other ways to reference this concept, such as precision, recall, and specificity.\\n\\nCan you show me an example of this \\nconcept?\\n\\nThe accuracy of a model can be represented by a confusion matrix, which shows the number of correct and incorrect predictions made by the model.\\n\\nCan you create a python code to example this concept?\\n\\nYes.\\nShow me :) \\n\\n\\nimport numpy as np\\nfrom sklearn.metrics import accuracy_score\\n\\ny_true = [0, 1, 1, 0]\\ny_pred = [0, 1, 0, 0]\\n\\naccuracy = accuracy_score(y_true, y_pred)\\nprint(accuracy)', '/CreationDate': \"D:20220702192620-07'00'\", '/M': \"D:20220702192620-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 288, 558.2016, 308.80908], '/C': [1, 1, 0], '/QuadPoints': [382.2225, 308.80908, 558.2016, 308.80908, 382.2225, 302.954, 558.2016, 302.954, 317, 300, 525, 300, 317, 288, 525, 288], '/T': 'Alejandro Adorjan', '/Contents': 'Can you explain the concept \"a two-tailed paired t-test to compare the average\\nmax cosine similarity between the model and baselines\"\\n\\nA two-tailed paired t-test is used to compare the average maximum cosine similarity between two models. The test is used to determine whether there is a significant difference between the two models.\\n\\nCan you show me similar statitistical approaches?\\n\\nThere are many statistical approaches that can be used to compare two models. Some other approaches include:\\n\\n-A two-sample t-test\\n-A Wilcoxon rank-sum test\\n-A Mann-Whitney U test\\n\\nWhat are the difference between this approaches?\\n\\nThere are many differences between statistical approaches. Some key differences between the two-tailed paired t-test and other approaches include:\\n\\n-The two-tailed paired t-test is used when the data are paired, meaning that there is a matched set of data for each model. Other tests, such as the two-sample t-test, do not require that the data be paired.\\n-The two-tailed paired t-test is used to compare the means of the two models. Other tests, such as the Wilcoxon rank-sum test, can be used to compare other statistics, such as medians.', '/CreationDate': \"D:20220702185528-07'00'\", '/M': \"D:20220702185528-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 158, 558.20404, 178.17906], '/C': [1, 1, 0], '/QuadPoints': [432.31406, 178.17906, 558.20404, 178.17906, 432.31406, 172.32399, 558.20404, 172.32399, 317, 169.00002, 363, 169.00002, 317, 158, 363, 158], '/T': 'Alejandro Adorjan', '/Contents': 'How can I interpret The area under the resulting curve (AUC-ROC)?\\n\\nAUC-ROC stands for Area Under the Curve - Receiver Operating Characteristic. The AUC-ROC is used to measure the performance of a binary classification model. The AUC-ROC can be interpreted as the probability that a randomly chosen positive example is ranked higher than a randomly chosen negative example.\\n\\nwhat is the scientific paper that poses AUC-ROC?\\n\\nThe AUC-ROC was originally proposed in a paper by Fawcett in 2006.\\n\\nCan you summarize the paper?\\n\\nThe paper by Fawcett proposes the use of the AUC-ROC as a measure of the performance of binary classification models. The AUC-ROC can be interpreted as the probability that a randomly chosen positive example is ranked higher than a randomly chosen negative example.\\n\\nShow me an example with datasets in python\\n\\nHere is an example of using the AUC-ROC to measure the performance of a binary classification model:\\n\\nfrom sklearn.metrics import roc_auc_score\\n\\ny_true = [0, 0, 1, 1]\\ny_scores = [0.5, 0.6, 0.7, 0.8]\\n\\nauc_roc = roc_auc_score(y_true, y_scores)\\n\\nprint(auc_roc)\\n\\n# The AUC-ROC is 0.75', '/CreationDate': \"D:20220702192229-07'00'\", '/M': \"D:20220702192229-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 180.00002, 558.2023, 211.05507], '/C': [1, 1, 0], '/QuadPoints': [507.0204, 211.05507, 558.1999, 211.05507, 507.0204, 205.2, 558.1999, 205.2, 317.955, 200.09708, 558.2023, 200.09708, 317.955, 194.242, 558.2023, 194.242, 317, 191.00002, 448.99997, 191.00002, 317, 180.00002, 448.99997, 180.00002], '/T': 'Alejandro Adorjan', '/Contents': \"How true is : ROC curve is typically used to present the quality of a binary classification model by comparing its true-positive rate and false-positive rate at different thresholds?\\n\\nThe ROC curve is a graphical plot that illustrates the diagnostic ability of a binary classification model as its discrimination threshold is varied. The true-positive rate is the proportion of positive cases that are correctly identified by the model, and the false-positive rate is the proportion of negative cases that are incorrectly identified by the model.\\n\\nCan you show me a python code that use ROC?\\n\\nHere is a Python code example that uses the ROC curve to assess the quality of a binary classification model:\\n\\nfrom sklearn.metrics import roc_curve\\n\\nimport matplotlib.pyplot as plt\\n\\n# compute the false positive rate and true positive rate\\n\\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\\n\\n# plot the ROC curve\\n\\nplt.plot(fpr, tpr)\\n\\nplt.xlabel('False Positive Rate')\\n\\nplt.ylabel('True Positive Rate')\\n\\nplt.show()\", '/CreationDate': \"D:20220702192010-07'00'\", '/M': \"D:20220702192010-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [316.00003, 124.99999, 558.36975, 145.30206], '/C': [1, 1, 0], '/QuadPoints': [442.8351, 145.30206, 558.36975, 145.30206, 442.8351, 139.44699, 558.36975, 139.44699, 316.00003, 136, 431, 136, 316.00003, 124.99999, 431, 124.99999], '/T': 'Alejandro Adorjan', '/Contents': \"What is the premise of the REC curve applies a similar premise to regression models:\\n\\nThe REC curve applies a similar premise to regression models by minimizing the squared error between the predicted values and the actual values.\\n\\nShow me an example in python of the REC curve:\\n\\nThe REC curve can be demonstrated in Python by first creating a synthetic dataset:\\n\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Create synthetic dataset\\nx = np.linspace(0, 1, 100)\\ny = 2 * x + np.random.randn(100)\\n\\n# Fit a linear regression model\\nfrom sklearn.linear_model import LinearRegression\\nmodel = LinearRegression()\\nmodel.fit(x[:, np.newaxis], y)\\n\\n# Predict values using the model\\npredicted = model.predict(x[:, np.newaxis])\\n\\n# Plot the data and the model predictions\\nplt.scatter(x, y, s=10)\\nplt.plot(x, predicted, lw=2)\\nplt.xlabel('x')\\nplt.ylabel('y')\\nplt.show()\", '/CreationDate': \"D:20220702192352-07'00'\", '/M': \"D:20220702192352-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 201.99998, 559.7142, 222.01404], '/C': [1, 1, 0], '/QuadPoints': [451.36322, 222.01404, 559.7142, 222.01404, 451.36322, 216.15898, 559.7142, 216.15898, 317, 212.99998, 361, 212.99998, 317, 201.99998, 361, 201.99998], '/T': 'Alejandro Adorjan', '/Contents': 'What is Receiver Operator Characteristic (ROC)?\\n\\nROC is a curve that shows the performance of a binary classification model at different thresholds. The curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at different threshold values.\\n\\nWhat are the most influential researcher that use ROC?\\n\\nThere are many influential researchers that use ROC, but some of the most notable are David Hand, Tom Fawcett, and Heikki Mannila.\\n\\nWhat are the main articles?\\n\\nThere are many articles that discuss ROC, but some of the most influential are \"ROC Curves: A Tool for Visualizing Performance\" by David Hand and \"An Introduction to ROC Analysis\" by Tom Fawcett.', '/CreationDate': \"D:20220702191743-07'00'\", '/M': \"D:20220702191743-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [397, 223, 534, 235], '/C': [1, 1, 0], '/QuadPoints': [397, 235, 534, 235, 397, 223, 534, 223], '/T': 'Alejandro Adorjan', '/Contents': 'What is Regression Error Characteristic (REC)?\\n\\nREC is a statistical tool used to measure the goodness-of-fit of a regression model. It is used to evaluate how well the model predicts the dependent variable, based on the independent variables. REC can be used to compare different regression models, or to compare the same model with different data sets.\\n\\nWaht regression models can be compared?\\n\\nThere are many types of regression models, and any two models can be compared using REC. Some common types of regression models include linear regression, logistic regression, and polynomial regression.\\n\\nShow me the difference between this models\\n\\nThere is no definitive answer to this question, as the difference between any two models depends on the specific data set and the goals of the analysis. However, in general, linear regression is used when the dependent variable is a continuous variable, while logistic regression is used when the dependent variable is a binary variable. Polynomial regression can be used for either type of dependent variable, but is typically used when the relationship between the independent and dependent variables is non-linear.\\n\\nan the similarities ?\\n\\nThere is no definitive answer to this question, as the similarity between any two models depends on the specific data set and the goals of the analysis. However, in general, all regression models are used to predict the value of a dependent variable, based on one or more independent variables.\\n\\nwhat is the paper that poses Regression Error Characteristic (REC) ?\\n\\nThe paper that first proposed the use of REC is \"A Characterization of the Predictive Power of a Regression Model\" by David G. Kendall and Alan Stuart.\\n\\nCan you summarize it ?\\n\\nThe paper introduces the concept of REC and provides a framework for comparing different regression models. It shows how REC can be used to assess the predictive power of a model, and to compare the performance of different models.\\nShow me an example in python code \\n\\n\\n\\nimport numpy as np\\nfrom sklearn.linear_model imp', '/CreationDate': \"D:20220702191613-07'00'\", '/M': \"D:20220702191613-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [341, 245.00002, 381, 257], '/C': [1, 1, 0], '/QuadPoints': [341, 257, 381, 257, 341, 245.00002, 381, 245.00002], '/T': 'Alejandro Adorjan', '/Contents': 'What is AUC-REC?\\n\\nAUC-REC is an acronym for Area Under the Curve - Receiver Operating Characteristic. It is a statistical tool used to measure the performance of a binary classification model. The AUC-REC measures the area under the curve of the Receiver Operating Characteristic (ROC) curve. The ROC curve is a plot of the true positive rate (TPR) against the false positive rate (FPR) for a binary classification model. The AUC-REC is a measure of how well the model can distinguish between positive and negative examples. A model with a high AUC-REC will have a small FPR and a large TPR.\\n\\nwhats the originaL paper that poses AUC-REC?\\n\\n\\nThe AUC-REC was first proposed by Fawcett in 2006.\\nIn what conference ?\\n\\n\\n\\nThe AUC-REC was first proposed by Fawcett in 2006 at the annual conference of the Association for Computing Machinery.\\n\\nWhat is the name of the paper ?\\n\\nThe name of the paper is \"An Introduction to ROC Analysis\".\\n\\nWhat is the doi of \"An Introduction to ROC Analysis\"?\\n\\nThe DOI of \"An Introduction to ROC Analysis\" is 10.1109/TKDE.2006.77.\\n\\nsummarize me An Introduction to ROC Analysis\".\\n\\n\\n\\n\"An Introduction to ROC Analysis\" is a paper that introduces the AUC-REC and explains how it can be used to measure the performance of a binary classification model. The paper discusses the advantages of the AUC-REC over other measures of model performance, such as accuracy and precision. The paper also provides guidance on how to interpret the results of an AUC-REC analysis.\\n\\ncan you show me a python example of this?\\n\\nHere is a Python example of how to calculate the AUC-REC for a binary classification model:\\n\\nfrom sklearn.metrics import roc_auc_score\\n\\ny_true = [0, 0, 1, 1]\\ny_scores = [0.1, 0.2, 0.3, 0.4]\\n\\nauc_rec = roc_auc_score(y_true, y_scores)\\n\\nprint(auc_rec)\\n\\n0.75\\nwhat does it mean this result?\\n\\nThis result means that the model has a good ability to distinguish between positive and negative examples.\\n\\nHow can i plot this results?\\n\\nHere is a Python example of how to plot the AUC-REC for a binary classification model:\\n\\nimport', '/CreationDate': \"D:20220702191008-07'00'\", '/M': \"D:20220702191008-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [400, 201.99998, 471, 212.99998], '/C': [1, 1, 0], '/QuadPoints': [400, 212.99998, 471, 212.99998, 400, 201.99998, 471, 201.99998], '/T': 'Alejandro Adorjan', '/Contents': 'What different regression models are in ML?\\n\\nThere are many different regression models in machine learning, but some of the most common are linear regression, logistic regression, and polynomial regression.\\n\\ncan you create a pseudo-code algorithm of logistic regression?\\n\\nLogistic regression is a type of regression analysis that is used to predict the probability of a binary outcome. In logistic regression, the outcome is either 0 or 1, which represents the two possible outcomes of a binary dependent variable.\\n\\nThe logistic regression algorithm can be summarized as follows:\\n\\n1. Collect data on the independent and dependent variables.\\n\\n2. Calculate the odds of the dependent variable.\\n\\n3. Use a logit function to model the relationship between the independent and dependent variables.\\n\\n4. Estimate the coefficients of the logit function.\\n\\n5. Use the coefficients to predict the probability of the dependent variable.', '/CreationDate': \"D:20220702191859-07'00'\", '/M': \"D:20220702191859-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [77.00001, 160.00002, 178, 173], '/C': [1, 1, 0], '/QuadPoints': [77.00001, 173, 178, 173, 77.00001, 160.00002, 178, 160.00002], '/T': 'Alejandro Adorjan', '/Contents': 'What is Semantic Similarity?\\n\\nSemantic similarity is a measure of the similarity between two pieces of text, typically in terms of their meaning or content.', '/CreationDate': \"D:20220702184123-07'00'\", '/M': \"D:20220702184123-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [53, 277, 294.0454, 297.8501], '/C': [1, 1, 0], '/QuadPoints': [176.34253, 297.8501, 294.0454, 297.8501, 176.34253, 291.995, 294.0454, 291.995, 53, 289, 189, 289, 53, 277, 189, 277], '/T': 'Alejandro Adorjan', '/Contents': 'How do you indexing existing tweets and their responses in Elasticsearch?\\n\\n\\n\\nYou can use the Twitter API to index tweets in Elasticsearch. The Twitter API will allow you to search for tweets and their responses.', '/CreationDate': \"D:20220702183854-07'00'\", '/M': \"D:20220702183854-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.bi2003regression', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [284.992, 357.606, 291.154, 365.154]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'figure.caption.14', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [77.89, 344.554, 83.972, 354.822]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'table.caption.13', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [251.166, 333.595, 257.319, 343.863]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'appendix.A', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [256.58, 289.759, 264.805, 300.028]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'table.caption.15', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [356.81, 318.936, 362.888, 329.205]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [342, 136, 386, 147], '/C': [1, 1, 0], '/QuadPoints': [342, 147, 386, 147, 342, 136, 386, 136], '/T': 'Alejandro Adorjan', '/Contents': 'What is Correlation?\\n\\nCorrelation is a statistical technique that can show whether and how strongly pairs of variables are related.\\n\\nFor example?\\n\\nFor example, height and weight are correlated; taller people tend to be heavier than shorter people.\\n\\nShow me a antromorfical aplication \\n\\nOne example of a correlation is the relationship between height and weight. Generally, taller people tend to weigh more than shorter people.\\n\\na Sociologial example\\n\\nOne example of a correlation in sociology is the relationship between education and income. Generally, people with more education tend to earn more money than those with less education.\\n\\na education example \\n\\nOne example of a correlation in education is the relationship between GPA and test scores. Generally, students with higher GPAs tend to score higher on tests than those with lower GPAs.\\n\\nshow me a python code of this last example\\n\\nThere is no definitive answer to this question since there are many ways to code a correlation in Python. However, one way to code a correlation between GPA and test scores might look something like this:\\n\\nimport numpy as np\\n\\ndef correlation(x, y):\\nreturn np.mean(x * y) - np.mean(x) * np.mean(y)\\n\\nx = [1, 2, 3, 4, 5]\\ny = [2, 4, 6, 8, 10]\\n\\nprint(correlation(x, y))', '/CreationDate': \"D:20220702194442-07'00'\", '/M': \"D:20220702194442-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 439, 559.7197, 481.3281], '/C': [1, 1, 0], '/QuadPoints': [467.44632, 481.3281, 558.19946, 481.3281, 467.44632, 475.47296, 558.19946, 475.47296, 317.955, 470.3691, 559.7197, 470.3691, 317.955, 464.51398, 559.7197, 464.51398, 317.955, 459.41006, 559.7183, 459.41006, 317.955, 453.555, 559.7183, 453.555, 317, 450, 409, 450, 317, 439, 409, 439], '/T': 'Alejandro Adorjan', '/Contents': \"Create a simple example of : REC-AUC analysis with confirmatory two-tailed paired t-tests to directly compare the dif-\\nferences in average max cosine similarity between the model eval-\\nuation and the baselines.\\n\\nThe data consists of two vectors, one for the model evaluation and one for the baselines. The vector for the model evaluation has a mean of 0.5 and the vector for the baselines has a mean of 0.6. The difference in the means is 0.1.\\n\\nThe confirmatory two-tailed paired t-test is used to compare the differences in the means. The t-test statistic is -2.718 and the p-value is 0.011. The results of the t-test indicate that the difference in the means is statistically significant.\\n\\nCreate a python code to test the below example:\\n\\nimport numpy as np\\nfrom scipy import stats\\n\\n#create two vectors, one for the model evaluation and one for the baselines\\nmodel_evaluation = [0.5, 0.4, 0.3, 0.2, 0.1]\\nbaselines = [0.6, 0.5, 0.4, 0.3, 0.2]\\n\\n#calculate the mean of each vector\\nmean_model_evaluation = np.mean(model_evaluation)\\nmean_baselines = np.mean(baselines)\\n\\n#calculate the difference in the means\\ndifference_in_means = mean_model_evaluation - mean_baselines\\n\\n#calculate the t-test statistic\\nt_statistic, p_value = stats.ttest_rel(model_evaluation, baselines)\\n\\n#print the results\\nprint('t-statistic:', t_statistic)\\nprint('p-value:', p_value)\\n\\nif p_value < 0.05:\\nprint('The difference in the means is statistically significant.')\\nelse:\\nprint('The difference in the means is not statistically significant.')\", '/CreationDate': \"D:20220702193647-07'00'\", '/M': \"D:20220702193647-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [342, 472, 396, 483], '/C': [1, 1, 0], '/QuadPoints': [342, 483, 396, 483, 342, 472, 396, 472], '/T': 'Alejandro Adorjan', '/Contents': 'What are the drawbacks of using Paired t-Tests?\\n\\nPaired t-tests make the assumption that the difference between the two groups is normally distributed. This assumption may not always be met, which can lead to inaccurate results. Additionally, paired t-tests require a large sample size in order to be reliable.', '/CreationDate': \"D:20220702193510-07'00'\", '/M': \"D:20220702193510-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [53, 377, 294.26013, 463.11005], '/C': [1, 1, 0], '/QuadPoints': [225.45958, 463.11005, 294.04922, 463.11005, 225.45958, 457.25497, 294.04922, 457.25497, 53.798, 452.15106, 294.04654, 452.15106, 53.798, 446.296, 294.04654, 446.296, 53.798, 441.19208, 154.93951, 441.19208, 53.798, 435.337, 154.93951, 435.337, 157.09, 439.25534, 164.29898, 439.25534, 157.09, 435.337, 164.29898, 435.337, 167.26, 441.19208, 294.049, 441.19208, 167.26, 435.337, 294.049, 435.337, 53.798, 430.23404, 150.33276, 430.23404, 53.798, 424.37897, 150.33276, 424.37897, 152.244, 428.2973, 159.45299, 428.2973, 152.244, 424.37897, 159.45299, 424.37897, 161.51201, 430.71826, 294.04758, 430.71826, 161.51201, 424.37897, 294.04758, 424.37897, 53.529, 419.75928, 244.80753, 419.75928, 53.529, 413.42, 244.80753, 413.42, 247.599, 417.26212, 252.9071, 417.26212, 247.599, 413.42, 252.9071, 413.42, 255.698, 419.27505, 294.26013, 419.27505, 255.698, 413.42, 294.26013, 413.42, 53.798, 408.3161, 294.04346, 408.3161, 53.798, 402.46103, 294.04346, 402.46103, 53.798, 397.35712, 294.25153, 397.35712, 53.798, 391.50204, 294.25153, 391.50204, 53, 388, 189, 388, 53, 377, 189, 377], '/T': 'Alejandro Adorjan', '/Contents': 'construct a python example with\\nREC curve as follows: (1) we concatenate the sets of 30 max cosine\\nsimilarity scores for each of M test messages, yielding a single list\\nof cosine similarities for all M ×30 primary ground-truth responses\\n; (2) normalize the resulting list so that the\\nhighest score is 1; and (3) subtract all values in the list from 1\\nto convert them to cosine distances.\\n\\nWe then compute the REC curve by thresholding this list at a range of\\ncosine distances and counting the number of times a response is\\nconsidered a match at each threshold. This number is divided by M to\\nget the REC curve.\\n\\nimport numpy as np\\n\\ndef compute_recall(M, cosine_similarities):\\nrecall = np.zeros(M)\\nfor i in range(M):\\nrecall[i] = np.sum(cosine_similarities[i] >= np.linspace(0, 1, M)) / float(M)\\nreturn recall\\n\\nM = 30\\ncosine_similarities = np.random.rand(M, M)\\nrecall = compute_recall(M, cosine_similarities)\\n\\nimport matplotlib.pyplot as plt\\nplt.plot(recall)\\nplt.show()', '/CreationDate': \"D:20220702193356-07'00'\", '/M': \"D:20220702193356-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [52, 453.99997, 294.58392, 495.98706], '/C': [1, 1, 0], '/QuadPoints': [108.23669, 495.98706, 294.04123, 495.98706, 108.23669, 490.132, 294.04123, 490.132, 53.798, 485.02808, 294.27576, 485.02808, 53.798, 479.173, 294.27576, 479.173, 53.574, 474.0691, 294.58392, 474.0691, 53.574, 468.21396, 294.58392, 468.21396, 52, 465.00003, 224, 465.00003, 52, 453.99997, 224, 453.99997], '/T': 'Alejandro Adorjan', '/Contents': 'Create an example of : REC curves to directly compare the ground-truth\\nbaseline (Primary vs. Reference), the model evaluation (Primary\\nvs. Model), and the random-chance baseline (Primary vs. Random)\\nusing min cosine distance as the error metric. \\n\\nA possible example of REC curves to compare the ground-truth baseline (Primary vs. Reference), the model evaluation (Primary vs. Model), and the random-chance baseline (Primary vs. Random) using min cosine distance as the error metric is shown below. The three curves represent the percentage of pairs of items that are considered to be similar, according to the cosine distance metric, for a given threshold. As can be seen, the model evaluation curve is closest to the ground-truth baseline, followed by the random-chance baseline.', '/CreationDate': \"D:20220702193214-07'00'\", '/M': \"D:20220702193214-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 102.99998, 559.7183, 145.30206], '/C': [1, 1, 0], '/QuadPoints': [465.03314, 145.30206, 558.20245, 145.30206, 465.03314, 139.44699, 558.20245, 139.44699, 317.955, 134.34303, 559.7143, 134.34303, 317.955, 128.488, 559.7143, 128.488, 317.955, 123.38405, 559.7183, 123.38405, 317.955, 117.52898, 559.7183, 117.52898, 317, 113.99998, 386, 113.99998, 317, 102.99998, 386, 102.99998], '/T': 'Alejandro Adorjan', '/Contents': 'Explain why: correlation study between the max cosine similarity scores of the ground-truth baseline (Primary vs. Reference) and those of the random-chance baseline (Primary vs. Random).\\n\\n\\nThe max cosine similarity scores of the ground-truth baseline should be higher than those of the random-chance baseline because the ground-truth baseline represents a true relationship between the Primary and Reference objects, while the random-chance baseline represents a relationship that is not meaningful.\\n\\nShow me an example of how this could be used:\\n\\nThis could be used to evaluate the strength of the relationship between two objects. If the max cosine similarity score of the ground-truth baseline is significantly higher than the score of the random-chance baseline, then the relationship between the Primary and Reference objects is likely to be strong.\\n\\nCreate a python code and a test case of these example\\n\\n\\ndef evaluate_relationship(ground_truth_score, random_chance_score):\\nif ground_truth_score > random_chance_score:\\nreturn \"The relationship between the Primary and Reference objects is likely to be strong.\"\\nelse:\\nreturn \"The relationship between the Primary and Reference objects is likely to be weak.\"\\n\\nprint(evaluate_relationship(0.8, 0.6)) # The relationship between the Primary and Reference objects is likely to be strong.\\nprint(evaluate_relationship(0.6, 0.8)) # The relationship between the Primary and Reference objects is likely to be weak.\\n\\nplot it please?\\n\\nimport matplotlib.pyplot as plt\\n\\nscores = [0.8, 0.6, 0.4, 0.2]\\n\\nplt.plot(scores, label=\"Ground-truth score\")\\nplt.plot(scores, label=\"Random-chance score\")\\nplt.legend()\\nplt.show()\\n\\ntest case ?\\n\\ndef test_evaluate_relationship():\\nassert evaluate_relationship(0.8, 0.6) == \"The relationship between the Primary and Reference objects is likely to be strong.\"\\nassert evaluate_relationship(0.6, 0.8) == \"The relationship between the Primary and Reference objects is likely to be weak.\"\\n\\ntest_evaluate_relationship()', '/CreationDate': \"D:20220702194856-07'00'\", '/M': \"D:20220702194856-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 153.99998, 559.58344, 295.02704], '/C': [1, 1, 0], '/QuadPoints': [505.83566, 295.02704, 559.19183, 295.02704, 505.83566, 289.17197, 559.19183, 289.17197, 317.623, 284.06805, 558.2054, 284.06805, 317.623, 278.21298, 558.2054, 278.21298, 317.955, 273.10907, 558.202, 273.10907, 317.955, 267.254, 558.202, 267.254, 317.955, 262.1501, 558.2039, 262.1501, 317.955, 256.295, 558.2039, 256.295, 317.955, 251.19106, 558.2034, 251.19106, 317.955, 245.33598, 558.2034, 245.33598, 317.668, 240.23203, 558.2006, 240.23203, 317.668, 234.37701, 558.2006, 234.37701, 317.955, 229.27304, 558.20404, 229.27304, 317.955, 223.41798, 558.20404, 223.41798, 317.955, 218.31406, 558.1993, 218.31406, 317.955, 212.459, 558.1993, 212.459, 317.955, 207.35509, 558.48755, 207.35509, 317.955, 201.50002, 558.48755, 201.50002, 317.955, 196.39705, 559.58344, 196.39705, 317.955, 190.54202, 559.58344, 190.54202, 317.686, 185.43806, 558.2002, 185.43806, 317.686, 179.583, 558.2002, 179.583, 317.641, 174.47908, 558.2046, 174.47908, 317.641, 168.62401, 558.2046, 168.62401, 317, 164.99998, 557, 164.99998, 317, 153.99998, 557, 153.99998], '/T': 'Alejandro Adorjan', '/Contents': 'Can you explain if its correct: for AUC-REC,\\nwe compare model performance across datasets and test accounts\\nusing Model % Difference. This time we do so using the differences\\nin means for max cosine similarity confirmed via the t-tests. We\\nobserve an absolute difference of less than 1% between the Model\\n% Differences obtained for the paired t-tests and those obtained\\nfor the AUC-REC scores (e.g., on the full COVID-19 test set we\\nhave Model % Difference = 71.7% for AUC-REC and 70.8% for the\\npaired t-tests, and on the full Vaccines test set we have Model %\\nDifference = 66.7% for AUC-REC and 67.6% for the paired t-tests).\\nThis provides confirmation for the conclusions drawn from the\\nAUC-REC results; that is, that the model can meaningfully capture\\nand reproduce response semantics for test messages and authors.\\n\\nWe can observe that the model performs well in terms of AUC-REC,\\nwith a difference of less than 1% between the two scores. This\\nconfirms that the model is able to meaningfully capture and\\nreproduce response semantics for test messages and authors.', '/CreationDate': \"D:20220702193826-07'00'\", '/M': \"D:20220702193826-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [53, 498, 294.04706, 517.905], '/C': [1, 1, 0], '/QuadPoints': [106.7335, 517.905, 294.04706, 517.905, 106.7335, 512.05, 294.04706, 512.05, 53, 509, 286, 509, 53, 498, 286, 498], '/T': 'Alejandro Adorjan', '/Contents': \"the area under the curve can be used to approximate model quality in the same manner as ROC curves. This make sense in ML modeling ? \\nThis reference shows a way to use precision recall curve to evaluate a model.\\n\\nThe area under the curve can not be used to approximate model quality in the same manner as ROC curves. This make sense in ML modeling ? \\n\\nA: ROC curves are a way of measuring the performance of a binary classifier.\\nPrecision-recall curves are a way of measuring the performance of a binary classifier. \\nThat's all there is to it. You can use either one to measure the performance of a binary classifier.\", '/CreationDate': \"D:20220702193013-07'00'\", '/M': \"D:20220702193013-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'figure.caption.16', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [105.561, 256.883, 111.639, 267.151]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'section.3', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [414.137, 465.102, 420.286, 475.37]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'table.caption.17', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [357.27, 256.883, 363.348, 267.151]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 453.99997, 558.19977, 474.0691], '/C': [1, 1, 0], '/QuadPoints': [450.8184, 474.0691, 558.19977, 474.0691, 450.8184, 468.21396, 558.19977, 468.21396, 317, 465.00003, 407, 465.00003, 317, 453.99997, 407, 453.99997], '/T': 'Alejandro Adorjan', '/Contents': 'What are the bias of using RoBERTa to assign sentiment scores for each response?\\n\\nThere are a few potential biases of using RoBERTa to assign sentiment scores for each response. First, RoBERTa may not be trained on data that is representative of the data that it will be used to score. This could lead to inaccurate results. Second, RoBERTa may be biased towards certain types of responses (e.g. positive responses) due to the way it was trained. Finally, the use of RoBERTa to score sentiment may be less accurate than other methods, such as human annotation.', '/CreationDate': \"D:20220702195447-07'00'\", '/M': \"D:20220702195447-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 476, 559.71326, 506.94608], '/C': [1, 1, 0], '/QuadPoints': [441.27597, 506.94608, 559.71326, 506.94608, 441.27597, 501.091, 559.71326, 501.091, 317.955, 495.98706, 558.20404, 495.98706, 317.955, 490.132, 558.20404, 490.132, 317, 487, 486, 487, 317, 476, 486, 476], '/T': 'Alejandro Adorjan', '/Contents': 'How assess if the sentiments expressed by the Model and the Primary, Reference and Random populations are distributed similarly.Model and the Primary, Reference and Random populations are distributed similarly.\\n\\nThe easiest way to assess if the sentiments expressed by the Model and the Primary, Reference and Random populations are distributed similarly would be to look at the means of each group. If the means are close together, then the distributions are likely to be similar. Another way to assess this would be to look at the variance of each group. If the variances are similar, then again, the distributions are likely to be similar.\\n\\nExample in python Model and the Primary, Reference and Random populations are distributed similarly.lease.\\n\\n\\n\\nfrom scipy import stats\\n\\n#The Primary, Reference and Random populations\\n\\nPrimary = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\\n\\nReference = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\\n\\nRandom = [3, 6, 9, 12, 15, 18, 21, 24, 27, 30]\\n\\n#The Model\\n\\nModel = [1.5, 3, 4.5, 6, 7.5, 9, 10.5, 12, 13.5, 15]\\n\\n#Compare the means\\n\\nprint(stats.ttest_ind(Primary, Model))\\n\\nprint(stats.ttest_ind(Reference, Model))\\n\\nprint(stats.ttest_ind(Random, Model))\\n\\n#Compare the variances\\n\\nprint(stats.levene(Primary, Model))\\n\\nprint(stats.levene(Reference, Model))\\n\\nprint(stats.levene(Random, Model))', '/CreationDate': \"D:20220702195353-07'00'\", '/M': \"D:20220702195353-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [342, 555, 447, 568], '/C': [1, 1, 0], '/QuadPoints': [342, 568, 447, 568, 342, 555, 447, 555], '/T': 'Alejandro Adorjan', '/Contents': 'What is Sentiment Similarity?\\n\\nSentiment similarity is a metric used to compare the similarity of two pieces of text. The higher the similarity, the more likely the two pieces of text are to express the same sentiment.\\n\\nFor example?\\n\\nIf two pieces of text are both about the same topic and have the same sentiment, they would have a high similarity score. However, if one piece of text is positive and the other is negative, they would have a low similarity score.\\n\\nExample in education?\\n\\nIn education, sentiment similarity can be used to compare the similarity of two students\\' essays. If two essays are about the same topic and have the same sentiment, they would have a high similarity score. However, if one essay is positive and the other is negative, they would have a low similarity score.\\n\\nCode please in Javascript\\n\\nvar text1 = \"I love learning\";\\nvar text2 = \"I hate school\";\\n\\nvar similarity = JaccardCoefficient(text1, text2);\\n\\nconsole.log(similarity); // prints 0.25', '/CreationDate': \"D:20220702195153-07'00'\", '/M': \"D:20220702195153-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 410, 558.2028, 430.23404], '/C': [1, 1, 0], '/QuadPoints': [498.00262, 430.23404, 558.2028, 430.23404, 498.00262, 424.37897, 558.2028, 424.37897, 317, 421, 336.00003, 421, 317, 410, 336.00003, 410], '/T': 'Alejandro Adorjan', '/Contents': 'What is Chi-square tests?\\n\\nA chi-square test is a statistical test used to determine whether there is a significant difference between the expected frequencies and the observed frequencies in one or more categories.\\n\\nWhat is the correct number of observations to use Chi-square test?\\n\\nThere is no definitive answer to this question, as the appropriateness of using a chi-square test depends on the specific circumstances and data involved. However, generally speaking, a chi-square test can be used with data sets that have at least 5 observations in each category.\\n\\nshow me the formula of Chi-square test\\n\\nThe chi-square test statistic is calculated as follows:\\n\\nchi-square = sum((observed frequency - expected frequency)^2 / expected frequency)\\n\\nis there an interpretation of Chi-square values obtained?\\n\\nYes, the chi-square test statistic can be interpreted in terms of the probability of obtaining a given value, or more extreme values, if the null hypothesis is true. The smaller the chi-square value, the more likely it is that the null hypothesis is true.\\n\\nWhat is the bias of using Chi-square?\\n\\nOne potential bias of using a chi-square test is that it can be sensitive to small changes in the data set. This means that a chi-square test might not be the best choice of statistical test if the data set is small or if the expected frequencies are very close to the observed frequencies.', '/CreationDate': \"D:20220702195742-07'00'\", '/M': \"D:20220702195742-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'figure.caption.18', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [133.961, 289.759, 140.206, 300.028]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'figure.caption.19', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [272.012, 191.129, 278.173, 201.398]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'table.caption.17', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [222.401, 81.845, 228.563, 91.975]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.zhang-etal-2020-dialogpt', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [320.176, 324.649, 330.508, 332.277]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.bao-etal-2020-plato', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [436.717, 302.812, 442.879, 310.359]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.bao-etal-2021-plato', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [488.24, 302.812, 494.402, 310.359]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.roller-etal-2021-recipes', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [320.215, 291.772, 330.546, 299.4]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.ccetinkaya2020developing', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [549.908, 269.855, 556.07, 277.482]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.10.1007/978-981-16-4807-6_24', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [477.251, 215.06, 487.583, 222.688]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.tran-popowich-2016-automatic', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [489.844, 215.141, 500.175, 222.688]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.10.1007/978-3-642-29035-0_24', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [515.893, 193.223, 526.224, 200.77]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.GARVEY2021113497', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [519.039, 182.183, 525.201, 189.811]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 158, 558.20404, 178.17911], '/C': [1, 1, 0], '/QuadPoints': [400.09274, 178.17911, 558.20404, 178.17911, 400.09274, 172.32404, 558.20404, 172.32404, 317, 169.00002, 510, 169.00002, 317, 158, 510, 158], '/T': 'Alejandro Adorjan', '/Contents': 'What is the drawbacks of aid social media content managers design\\ntweets that will be received well and become popular.\\n\\nThe main drawback is that it can be difficult to design tweets that will be popular without knowing the specific interests of the people who will see them. In addition, some Twitter users may be more likely to retweet or share content that is controversial or humorous, rather than tweets that are simply informative or positive.', '/CreationDate': \"D:20220702200847-07'00'\", '/M': \"D:20220702200847-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [347, 256.00003, 516, 268], '/C': [1, 1, 0], '/QuadPoints': [347, 268, 516, 268, 347, 256.00003, 516, 256.00003], '/T': 'Alejandro Adorjan', '/Contents': 'What it is a neural encoder-decoder-reranker framework?\\n\\nA neural encoder-decoder-reranker framework is a system that takes in input data, encodes it into a vector representation, then decodes it back into a output data. The system then reranks the output data according to some criterion.\\n\\nScientific papers and related authors ?\\n\\nNeural encoder-decoder-reranker frameworks have been used to develop systems for a variety of tasks, including machine translation, text summarization, and question answering.\\n\\nSome notable papers that have used this approach include:\\n\\n\"Neural Machine Translation by Jointly Learning to Align and Translate\" (https://arxiv.org/abs/1409.0473)\\n\\n\"Abstractive Sentence Summarization with Attentive Recurrent Neural Networks\" (https://arxiv.org/abs/1602.06023)\\n\\n\"Reading Wikipedia to Answer Open-Domain Questions\" (https://arxiv.org/abs/1809.08854)', '/CreationDate': \"D:20220702200701-07'00'\", '/M': \"D:20220702200701-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [376, 300.99997, 404, 312], '/C': [1, 1, 0], '/QuadPoints': [376, 312, 404, 312, 376, 300.99997, 404, 300.99997], '/T': 'Alejandro Adorjan', '/Contents': \"What is Reddit?\\n\\nReddit is a social media platform that allows users to submit content, vote on submissions, and comment on submissions.\\n\\nHow confident is ?\\n\\n\\n\\nThis answer is a bit difficult to quantify. However, we can say that Reddit is a very popular social media platform with a large user base.\\n\\nIs there an API?\\n\\nYes. Reddit has an API that allows developers to access and interact with the site's data.\\n\\nShow me an example of quering this API in python\\n\\n\\n\\nimport praw\\n\\nr = praw.Reddit(user_agent='my_user_agent')\\n\\nsubmissions = r.get_subreddit('subreddit').get_hot(limit=5)\\n\\nfor submission in submissions:\\n\\nprint(submission.title)\", '/CreationDate': \"D:20220702200400-07'00'\", '/M': \"D:20220702200400-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [521, 333, 560, 344.00003], '/C': [1, 1, 0], '/QuadPoints': [521, 344.00003, 560, 344.00003, 521, 333, 560, 333], '/T': 'Alejandro Adorjan', '/Contents': \"What is DialoGPT?\\n\\nDialoGPT is a state-of-the-art, open-source natural language generation (NLG) model that can generate human-like responses to questions in any topic domain, making it an ideal candidate for building conversational agents.\\n\\nWho poses DialoGPT?\\n\\nMicrosoft\\nwhat scientific article?\\n\\nhttps://www.nature.com/articles/s41586-019-1708-7\\n\\nHow can be compared with other NLG models?\\n\\nDialoGPT can be compared with other NLG models in terms of accuracy and fluency.\\nHow?\\n\\nIn terms of accuracy, DialoGPT outperforms all other NLG models in terms of perplexity. In terms of fluency, DialoGPT generates responses that are more human-like and less stilted compared to other NLG models.\\n\\nis there an API for DialoGPT?\\n\\nYes, there is an API for DialoGPT.\\n\\nURL?\\n\\nThe URL for the API is https://api.dialogpt.com/.\\n\\nis open source?\\n\\nYes, DialoGPT is open source.\\n\\nGithub repo?\\n\\nThe GitHub repository for DialoGPT is https://github.com/microsoft/DialoGPT.\\n\\nshow me an example of using DialoGPT in python\\n\\nHere is an example of using DialoGPT in python:\\n\\nimport requests\\n\\nresponse = requests.post('https://api.dialogpt.com/v1/dialogues',\\njson={'question': 'How are you?'})\\n\\nprint(response.json())\", '/CreationDate': \"D:20220702200236-07'00'\", '/M': \"D:20220702200236-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [500, 300.99997, 560, 312], '/C': [1, 1, 0], '/QuadPoints': [500, 312, 560, 312, 500, 300.99997, 560, 300.99997], '/T': 'Alejandro Adorjan', '/Contents': 'What is PLATO?\\n\\nPLATO was an educational computer system created in the 1960s. It was one of the first systems to allow users to create and share their own content. It was also used by universities and colleges to offer distance learning courses.\\n\\nand PLATO-2?\\n\\nPLATO-2 was an updated version of the PLATO system that was released in the 1970s. It included new features and capabilities, such as the ability to create and run programs written in the BASIC programming language.\\n\\nand BlenderBot?\\n\\nBlenderBot is a chatbot that runs on the PLATO system. It was created by students at the University of Illinois at Urbana-Champaign.\\nis open source?\\n\\nBlenderBot is open source software. This means that anyone can view and modify the source code.\\n\\nURL?\\n\\nThe URL for the BlenderBot project is https://github.com/uiuc-cs-plato/BlenderBot\\n\\nshow me an example of using in python code\\n\\nHere is an example of how to use the BlenderBot chatbot in Python code:\\n\\nfrom BlenderBot import BlenderBot\\n\\nbot = BlenderBot()\\n\\nbot.connect()\\n\\nbot.send_message(\"Hello, world!\")\\n\\nbot.disconnect()', '/CreationDate': \"D:20220702200600-07'00'\", '/M': \"D:20220702200600-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.liu2021token', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [196.608, 291.853, 206.939, 299.4]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'figure.caption.11', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [179.316, 278.8, 185.394, 289.069]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'figure.caption.12', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [201.037, 278.8, 207.115, 289.069]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.lewis2020retrieval', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [56.058, 149.387, 66.389, 156.934]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.rosenthal-etal-2017-semeval', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [451.696, 598.622, 462.027, 606.25]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'section.6', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [482.461, 371.951, 488.707, 382.386]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'cite.brown2020language', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [0, 1, 0], '/H': '/I', '/Rect': [365.043, 341.087, 371.205, 348.715]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'subsection.4.2', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [491.838, 147.294, 504.018, 157.562]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [203, 124.99999, 280, 136], '/C': [1, 1, 0], '/QuadPoints': [203, 136, 280, 136, 203, 124.99999, 280, 124.99999], '/T': 'Alejandro Adorjan', '/Contents': 'What is constant re-training in AI?\\n\\nConstant re-training in AI is the process of continually training an AI system with new data in order to improve its performance. This can be done by adding new data to the training set, or by retraining the system from scratch with a new dataset.\\n\\nExample:\\n\\nIf we have a system that is trained to recognize objects in images, we can improve its performance by constantly re-training it with new images. We can add new images of objects to the training set, or we can retrain the system from scratch with a new dataset of images.\\n\\nCode in python?\\n\\nThere is no one specific way to code constant re-training in AI. The approach will depend on the particular AI system being used.', '/CreationDate': \"D:20220702205108-07'00'\", '/M': \"D:20220702205108-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 673, 559.7131, 693.2471], '/C': [1, 1, 0], '/QuadPoints': [381.11536, 693.2471, 559.7131, 693.2471, 381.11536, 687.392, 559.7131, 687.392, 317, 684, 434, 684, 317, 673, 434, 673], '/T': 'Alejandro Adorjan', '/Contents': 'scientific academic papers that mention: pre-trained models for computing sentence em-\\nbeddings and sentiment scores.\\n\\n\\n\\\\section{Related Work}\\n\\n\\\\label{sec:related}\\n\\nOur work is related to several strands of research. \\nFirst, our work is related to the area of opinion mining and sentiment analysis. \\nThere are numerous methods proposed to perform sentiment analysis, e.g., \\\\newcite{Rao2012}, \\\\newcite{Li2013}, \\\\newcite{Pang2008}, \\\\newcite{Taschek2013}, \\\\newcite{Taschek2014}, \\\\newcite{Taschek2016}. \\n\\\\newcite{Pang2008} performed sentiment analysis for reviews stored in a database. \\n\\\\newcite{Taschek2013} proposed to generate a sentiment lexicon by mining a database of tweets. \\n\\\\newcite{Taschek2014} performed sentiment analysis on a set of tweets stored in a database. \\n\\\\newcite{Taschek2016} proposed a method to predict the sentiment of a sentence stored in a database.\\nOur work is also related to the area of text classification. \\nThere are a number of methods proposed to perform text classification, e.g., \\\\newcite{Deng2012}, \\\\newcite{Deng2013}, \\\\newcite{Deng2014}, \\\\newcite{Deng2015}, \\\\newcite{Deng2016}, \\\\newcite{Deng2017}. \\n\\\\newcite{Deng2012} performed text classification for documents stored in a database. \\n\\\\newcite{Deng2013} proposed to generate a text classifier by mining a database of tweets. \\n\\\\newcite{Deng2014} performed text classification on a set of tweets stored in a database. \\n\\\\newcite{Deng2015} proposed a method to predict the class of a document stored in a database.\\n\\\\newcite{Deng2016} proposed a method to predict the class of a sentence stored in a database.\\n\\\\newcite{Deng2017} performed text classification on a set of sentences stored in a database.\\nOur work is also related to the area of text similarity. \\nThere are a number of methods proposed to perform text similarity, e.g., \\\\newcite{Wang2012}, \\\\newcite{Wang2013}, \\\\newcite{Wang2014}, \\\\newcite{Wang2015}, \\\\newcite{Wang2016}, \\\\newcite{Wang2017}. \\n\\\\newcite{Wang2012} performed text similarity for sentences stored in a database. \\n\\\\newcite{Wang2013} proposed to g', '/CreationDate': \"D:20220702210201-07'00'\", '/M': \"D:20220702210201-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [75, 147, 234, 158], '/C': [1, 1, 0], '/QuadPoints': [75, 158, 234, 158, 75, 147, 234, 147], '/T': 'Alejandro Adorjan', '/Contents': \"What is Retrieval-augmented response generation?\\n\\nRetrieval-augmented response generation is a model of machine reading comprehension that combines a retrieval-based approach with a neural generation model. The retrieval component retrieves a set of relevant documents from a collection, and the generation component generates a response based on the retrieved documents.\\n\\nWhat is a neural generation model?\\n\\nA neural generation model is a type of machine learning model that uses artificial neural networks to generate text.\\n\\nPosed scientific authors and papers?\\n\\nRetrieval-augmented response generation has been used to generate responses to questions about scientific papers. For example, the model can be used to generate a summary of a paper, or to generate an answer to a question about the paper.\\n\\nExample of Retrieval-augmented response generation\\n\\nHere is an example of how retrieval-augmented response generation can be used to generate a response to a question about a scientific paper.\\n\\nQuestion: What are the main findings of the paper?\\n\\nThe retrieval component of the model retrieves a set of relevant documents from a collection, and the generation component generates a response based on the retrieved documents. In this case, the retrieved documents would be the paper itself and any related papers. The generation component would then generate a response that summarises the main findings of the paper.\\n\\npython code?\\n\\nRetrieval-augmented response generation can be implemented in Python using the Gensim library.\\n\\ncreate an example in python for Retrieval-augmented response generation\\n\\nimport gensim\\n\\nmodel = gensim.models.retrieval_rasa.RetrievalRasa()\\n\\nmodel.generate('What are the main findings of the paper?')\\n\\nThis code will generate a response that summarises the main findings of the paper.\", '/CreationDate': \"D:20220702204957-07'00'\", '/M': \"D:20220702204957-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [341, 695, 500, 706], '/C': [1, 1, 0], '/QuadPoints': [341, 706, 500, 706, 341, 695, 500, 695], '/T': 'Alejandro Adorjan', '/Contents': 'what is Semantic & Sentiment Measurement Quality in ML?\\n\\n\\nThere is no definitive answer to this question as it can depend on the specific ML algorithm and application. However, in general, semantic and sentiment measurement quality refers to how accurately the algorithm can identify and classify the meaning of text data. This can be important for applications such as sentiment analysis, where the accuracy of the classification can have a significant impact on the results.\\n\\nWhat software quality atributes are present?\\n\\n\\nThere are a number of software quality attributes that can be present in ML algorithms, including accuracy, precision, recall, and F1 score.\\n\\nHow can they be associated with software architecture attributes ?\\n\\nThere is no definitive answer to this question as it can depend on the specific ML algorithm and application. However, in general, the quality attributes of an ML algorithm can be associated with software architecture attributes such as modularity, extensibility, and maintainability.\\n\\n\\nSummary of accuracy, precision, recall, and F1 score.\\n\\nThe accuracy of an ML algorithm is a measure of how correctly it can classify data. The precision is a measure of how often the algorithm produces correct results, while the recall is a measure of how often the algorithm correctly identifies all relevant data. The F1 score is a combination of the precision and recall, and is a measure of the overall accuracy of the algorithm.\\n\\nF1 score example in python\\n\\nThe following is an example of how to calculate the F1 score in Python:\\n\\nfrom sklearn.metrics import f1_score\\n\\ny_true = [0, 1, 0, 1]\\ny_pred = [0, 1, 1, 1]\\n\\nf1_score(y_true, y_pred)\\n\\nThis would return an F1 score of 0.75.\\n\\nwhat does it means?\\n\\nIt means that the ML algorithm correctly classified 75% of the data.\\n\\nand what about precision and recall?\\n\\nThe precision is a measure of how often the algorithm produces correct results, while the recall is a measure of how often the algorithm correctly identifies all relevant data.\\n\\nExample of python code of precisio', '/CreationDate': \"D:20220702210015-07'00'\", '/M': \"D:20220702210015-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [302, 70.99999, 310, 78.00002], '/C': [1, 1, 0], '/QuadPoints': [302, 78.00002, 310, 78.00002, 302, 70.99999, 310, 70.99999], '/T': 'Alejandro Adorjan', '/Contents': 'Create a glossary of terms in ML\\n\\n-Algorithm: a set of rules to be followed in calculations or other problem-solving operations, especially by a computer.\\n-Artificial intelligence: the theory and development of computer systems able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages.\\n-Big data: a term for data sets that are so large or complex that traditional data processing applications are inadequate.\\n-Classification: the process of assigning items to classes or categories.\\n-Clustering: the process of grouping items together that are similar to each other and different from the items in other groups.\\n-Data: information that has been transformed into a form that is efficient for movement or processing.\\n-Data mining: the process of extracting patterns from data.\\n-Feature: a characteristic or attribute of an item.\\n-Label: a class or category to which an item belongs.\\n-Learning: the process of acquiring knowledge or skill through experience, study, or by being taught.\\n-Machine learning: a branch of artificial intelligence that deals with the design and development of algorithms that allow computers to learn from data.\\n-Model: a representation of something, typically an item or a system.\\n-Pattern: a regular and intelligible form or sequence discernible in certain actions or situations.\\n-Prediction: the action of saying that something will happen, especially something bad, in the future.\\n-Regression: the process of returning to a former or less developed state.\\n-Supervised learning: a type of machine learning that uses a labeled dataset to train a model to learn to predict the labels for new data.\\n-Unsupervised learning: a type of machine learning that uses an unlabeled dataset to train a model to learn to predict labels for new data.', '/CreationDate': \"D:20220702204727-07'00'\", '/M': \"D:20220702204727-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 147, 558.203, 189.13805], '/C': [1, 1, 0], '/QuadPoints': [465.315, 189.13805, 558.203, 189.13805, 465.315, 183.28302, 558.203, 183.28302, 317.955, 178.17906, 558.1988, 178.17906, 317.955, 172.32399, 558.1988, 172.32399, 317.955, 167.22008, 558.2023, 167.22008, 317.955, 161.365, 558.2023, 161.365, 317, 158, 359, 158, 317, 147, 359, 147], '/T': 'Alejandro Adorjan', '/Contents': \"Our statistical evaluations\\ndemonstrate the effectiveness of generative response modeling in\\nreproducing the sentiment and semantics of public health responses\\non Twitter.\\n\\n\\n\\\\section{Related Work}\\n\\n\\\\paragraph{Public health responses on Twitter}\\n\\nTwitter is a popular social media platform for sharing information about\\nnatural disasters and other public health emergencies\\n\\\\cite{TwitterDisaster}.\\nFor example, the US government uses Twitter in its\\npublic health communications \\\\cite{CDCTwitter}, and Twitter\\nis the primary platform for sharing information about the Ebola\\nepidemic \\\\cite{EbolaTwitter}.\\n\\nThe US government has developed a social media monitoring platform,\\nrecently called ``Promote,'' which monitors tweets,\\nFacebook posts, and other content in real time.\\nPromote is designed to automatically identify tweets that are\\nrelevant to public health emergencies.\\nIn the case of Ebola, the system was used to automatically\\nidentify tweets that were related to the Ebola outbreak\\n\\\\cite{PromoteEbola}.\\n\\nAnother system, called ``Twitter Alerts,''\\nwas designed to send text messages to people\\nnear a natural disaster.\\nThe system is used by the US government to send alerts to\\npeople in the path of a Hurricane \\\\cite{TwitterAlerts}.\\n\\n\\\\paragraph{Twitter bots}\\n\\nTwitter bots are programs that automatically\", '/CreationDate': \"D:20220702213537-07'00'\", '/M': \"D:20220702213537-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [275, 158, 295, 169.00002], '/C': [1, 1, 0], '/QuadPoints': [275, 169.00002, 295, 169.00002, 275, 158, 295, 158], '/T': 'Alejandro Adorjan', '/Contents': 'What is RAG in ML?\\n\\nRAG stands for red, amber, and green. It is a system used to classify data points in a dataset according to their predicted classifications. Red points are predicted to be in the wrong class, amber points are predicted to be in the correct class but are close to the boundary of the wrong class, and green points are predicted to be in the correct class and far from the boundary of the wrong class.\\n\\nExample ?\\n\\nLet\\'s say we have a dataset of animals, and we want to classify them into two classes: mammals and reptiles. We train a classifier on this dataset, and it outputs the following RAG classifications:\\n\\nRed: alligator, crocodile\\nAmber: turtle\\nGreen: cat, dog, mouse, rabbit\\n\\nThis means that the classifier is correctly classify mammals as mammals and reptiles as reptiles, but it is not sure about turtles (amber).\\n\\nPython example ?\\n\\nHere is a simple example of RAG classification using the scikit-learn library in Python:\\n\\nfrom sklearn.datasets import load_iris\\nfrom sklearn.linear_model import LogisticRegression\\n\\n#Load the dataset\\niris = load_iris()\\nX, y = iris.data, iris.target\\n\\n#Train a logistic regression classifier\\nclf = LogisticRegression()\\nclf.fit(X, y)\\n\\n#Predict the class labels of the dataset\\ny_pred = clf.predict(X)\\n\\n#Print the RAG classification for each instance\\nfor i in range(len(y_pred)):\\nif y_pred[i] == y[i]:\\nprint(\"Instance\", i, \"is green\")\\nelif abs(y_pred[i] - y[i]) == 1:\\nprint(\"Instance\", i, \"is amber\")\\nelse:\\nprint(\"Instance\", i, \"is red\")\\n \\n \\n \\nInstance 0 is green\\nInstance 1 is green\\nInstance 2 is green\\nInstance 3 is green\\nInstance 4 is amber\\nInstance 5 is green\\nInstance 6 is green\\n...\\n\\nand how to plot this?\\n\\nHere is an example of how to plot RAG classifications using matplotlib in Python:\\n\\nimport matplotlib.pyplot as plt\\n\\n#Create a scatter plot of the RAG classifications\\nplt.scatter(range(len(y_pred)), y_pred, c=y_pred)\\n\\n#Add a title and axis labels\\nplt.title(\"RAG classifications\")\\nplt.xlabel(\"Instance\")\\nplt.ylabel(\"Class\")\\n\\n#Show the plot\\nplt.show()\\n\\nand interpret?\\n\\nThis plot s', '/CreationDate': \"D:20220702204639-07'00'\", '/M': \"D:20220702204639-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [465.00003, 651, 508, 662], '/C': [1, 1, 0], '/QuadPoints': [465.00003, 662, 508, 662, 465.00003, 651, 508, 651], '/T': 'Alejandro Adorjan', '/Contents': 'What is Wikipedia?\\n\\nWikipedia is a collaborative online encyclopedia that anyone can edit. It is written in a neutral point of view and is one of the most popular websites in the world.\\nlist countries that do not use Wikipedia\\n\\nThere are many countries that do not use Wikipedia. Some of these countries are China, Iran, Pakistan, and Russia.\\n\\nWhy?\\n\\nThere are many reasons why these countries may not use Wikipedia. One reason could be that the governments of these countries may not want their citizens to have access to information that could be critical of the government. Another reason could be that these countries may not have the infrastructure in place to support a website like Wikipedia.\\n\\nIs open source?\\n\\nWikipedia is an open source project, which means that anyone can contribute to it.\\nis there an API?\\n\\nYes, there is an API for Wikipedia.\\n\\npython code to access Wikipedia API\\n\\nimport wikipedia\\n\\nwikipedia.summary(\"Wikipedia\")\\n\\nand to query an article?\\n\\nTo query an article, you can use the following code:\\n\\nwikipedia.search(\"article name\")\\n\\nand to analise in NLP?\\n\\nYes, you can analyze Wikipedia articles using NLP techniques.\\nhow?\\n\\nOne way to analyze Wikipedia articles using NLP is to use the Natural Language Toolkit (NLTK). NLTK is a Python library that provides a set of tools for working with text data.\\n\\nshow me an example please\\n\\nHere is an example of how you could analyze a Wikipedia article using NLTK:\\n\\nimport nltk\\nfrom nltk.tokenize import sent_tokenize, word_tokenize\\nfrom nltk.corpus import stopwords\\nfrom nltk.stem import PorterStemmer\\n\\narticle = wikipedia.page(\"Natural Language Processing\").content\\n\\nsentences = sent_tokenize(article)\\nwords = [word_tokenize(sentence) for sentence in sentences]\\n\\nfiltered_words = []\\n\\nfor w in words:\\nif w not in stopwords.words(\"english\"):\\nfiltered_words.append(w)\\n\\nps = PorterStemmer()\\n\\nstemmed_words = []\\n\\nfor w in filtered_words:\\nstemmed_words.append(ps.stem(w))\\n\\nprint(stemmed_words)', '/CreationDate': \"D:20220702210855-07'00'\", '/M': \"D:20220702210855-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 421, 558.20215, 441.19208], '/C': [1, 1, 0], '/QuadPoints': [529.1084, 441.19208, 558.20215, 441.19208, 529.1084, 435.337, 558.20215, 435.337, 317, 431.99997, 529, 431.99997, 317, 421, 529, 421], '/T': 'Alejandro Adorjan', '/Contents': 'How to labeling new tweets for sentiment polarity\\n\\nThere is no definitive answer to this question, as different people may have different opinions on what constitutes a positive or negative sentiment. However, some tips on how to label new tweets for sentiment polarity include:\\n\\n-Read the tweet carefully and consider the overall tone and message.\\n-Look at the individual words used and see if they are generally positive or negative in nature.\\n-Think about whether the tweet is likely to make people feel good or bad.\\n-If you are still unsure, ask someone else for their opinion.\\n\\nexample in python: \\n\\n\\n\\ndef label_tweet(tweet):\\n\"\"\"\\nLabels the sentiment of a tweet (positive or negative).\\n\"\"\"\\n# YOUR CODE HERE\\nif tweet[\\'text\\'].startswith(\\'RT\\'):\\nreturn \\'neutral\\'\\n \\npolarity = 0\\nfor word in tweet[\\'text\\'].split():\\nif word in positive_words:\\npolarity += 1\\nelif word in negative_words:\\npolarity -= 1\\n \\nif polarity > 0:\\nreturn \\'positive\\'\\nelif polarity < 0:\\nreturn \\'negative\\'\\nelse:\\nreturn \\'neutral\\'', '/CreationDate': \"D:20220702212157-07'00'\", '/M': \"D:20220702212157-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 496.99997, 558.2056, 517.905], '/C': [1, 1, 0], '/QuadPoints': [456.1947, 517.905, 558.2056, 517.905, 456.1947, 512.05, 558.2056, 512.05, 317, 509, 474, 509, 317, 496.99997, 474, 496.99997], '/T': 'Alejandro Adorjan', '/Contents': \"What is additional fine-tuning of the\\nsentence embedding and sentiment models?\\n\\nAdditional fine-tuning of the sentence embedding and sentiment models can help to improve the overall accuracy of the model. This can be done by adjusting the parameters of the model, or by using different data sets for training.\\n\\nExample:\\n\\nOne method of additional fine-tuning is adjusting the parameters of the model. This can be done by changing the values of the weights in the model, or by changing the way the model processes data.\\n\\nAnother method of additional fine-tuning is using different data sets for training. This can help the model to learn from different types of data, and to generalize better to new data.\\n\\nExample in python of fine-tuning of the\\nsentence embedding and sentiment models\\n\\nfrom gensim.models import Word2Vec\\n\\n# Load the model\\nmodel = Word2Vec.load('model.bin')\\n\\n# Adjust the parameters of the model\\nmodel.wv.vectors_norm = None\\nmodel.train(new_sentences, total_examples=len(new_sentences), epochs=5)\\n\\n# Save the model\\nmodel.save('model.bin')\", '/CreationDate': \"D:20220702212006-07'00'\", '/M': \"D:20220702212006-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 662, 558.19855, 682.288], '/C': [1, 1, 0], '/QuadPoints': [494.30057, 682.288, 558.19855, 682.288, 494.30057, 676.433, 558.19855, 676.433, 317, 673, 383, 673, 317, 662, 383, 662], '/T': 'Alejandro Adorjan', '/Contents': 'What is MiniLM sentence embedding model?\\n\\nThe MiniLM sentence embedding model is a model that produces a low-dimensional vector representation of a sentence. This vector can then be used to compare the similarity of two sentences or to cluster similar sentences together.\\n\\nis open source ?\\n\\nYes, the MiniLM sentence embedding model is open source.\\nGithub?\\n\\nThe MiniLM sentence embedding model is available on Github at https://github.com/google-research/minilm.\\n\\nlast commit?\\n\\nThe last commit to the MiniLM repository was on May 8, 2019.\\ncontributors ?\\n\\nThere are four contributors to the MiniLM repository.\\nWho?\\n\\nThe four contributors to the MiniLM repository are Google employees.\\n\\nThey accept external Pull requests?\\n\\nNo, the MiniLM repository is closed to external Pull requests.\\n\\nOther opensource to MiniLM?\\n\\nNo, the MiniLM sentence embedding model is the only open source project from Google that produces sentence embeddings.\\n\\nPrivate products?\\n\\nYes, Google also offers a private product called Paragraph Vector that produces paragraph embeddings.\\n\\nWhat are the difference?\\n\\nThere is no publicly available information on the differences between the MiniLM sentence embedding model and the Paragraph Vector product.', '/CreationDate': \"D:20220702210523-07'00'\", '/M': \"D:20220702210523-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [450, 563, 560, 575], '/C': [1, 1, 0], '/QuadPoints': [450, 575, 560, 575, 450, 563, 560, 563], '/T': 'Alejandro Adorjan', '/Contents': 'How to measuring semantic similarity?\\n\\nThere are many ways to measure semantic similarity, but one common method is to use a word association test. In this test, subjects are given a list of words and are asked to write down the first word that comes to mind in response to each word. The responses are then analyzed to see how often similar words are produced in response to the same word.\\n\\nExample?\\n\\nOne example of a word association test is the Stroop task. In this task, subjects are asked to name the color of ink in which a word is printed. The word might be the name of a color (e.g., \"blue\"), but it is printed in a different color ink (e.g., green). The subject\\'s task is to name the ink color, not the word itself. This task is used to measure semantic similarity because it requires subjects to access the meaning of the word in order to name the ink color.\\n\\npython code?\\n\\nThere is no one \"correct\" way to measure semantic similarity in Python. However, the Natural Language Toolkit (NLTK) is a popular library that includes many tools for working with text data. One of these tools is a word association test, which can be used to measure semantic similarity.\\n\\nexample code of measuring semantic similarity in python\\n\\nfrom nltk.corpus import wordnet as wn\\n\\ndef semantic_similarity(word1, word2):\\n\\nsynset1 = wn.synsets(word1)[0]\\n\\nsynset2 = wn.synsets(word2)[0]\\n\\nreturn wn.wup_similarity(synset1, synset2)\\n\\nprint(semantic_similarity(\\'cat\\', \\'dog\\'))\\n\\nprint(semantic_similarity(\\'cat\\', \\'car\\'))\\nplot?\\n\\nThere is no one \"correct\" way to plot semantic similarity. However, one common method is to use a scatter plot. In this plot, each word is represented by a point, and the similarity between two words is represented by the distance between their points.\\nExample of scatter plot of measuring semantic similarity \\n\\nimport matplotlib.pyplot as plt\\n\\nfrom sklearn.decomposition import TruncatedSVD\\n\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\n\\nfrom sklearn.metrics.pairwise import cosine_similarity\\n\\n\\ndocuments = [\"cat dog tree\", \"', '/CreationDate': \"D:20220702211840-07'00'\", '/M': \"D:20220702211840-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [317, 574, 408, 586], '/C': [1, 1, 0], '/QuadPoints': [317, 586, 408, 586, 317, 574, 408, 574], '/T': 'Alejandro Adorjan', '/Contents': 'What is large-scale corpora ?\\n\\nLarge-scale corpora are text collections that are typically too large to fit on a single computer.\\n\\nExamples?\\n\\nSome large-scale corpora include the Google Books corpus, the English Wikipedia, and the Common Crawl corpus.\\n\\nis google books corpus open source?\\n\\nThe Google Books corpus is not open source.\\nand English Wikipedia?\\n\\n\\nThe English Wikipedia is open source.\\n\\nThe Common Crawl corpus is open source and can be found on GitHub.', '/CreationDate': \"D:20220702211606-07'00'\", '/M': \"D:20220702211606-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [53, 81.00002, 295.55585, 112.42507], '/C': [1, 1, 0], '/QuadPoints': [239.48643, 112.42507, 294.04535, 112.42507, 239.48643, 106.57, 294.04535, 106.57, 53.798, 101.46604, 295.55585, 101.46604, 53.798, 95.61102, 295.55585, 95.61102, 53, 92.00002, 280, 92.00002, 53, 81.00002, 280, 81.00002], '/T': 'Alejandro Adorjan', '/Contents': 'give an example of maintaining an up-to-date knowledge base of current events requires less compu-\\ntational resources than continually training language models.\\n\\nOne example of maintaining an up-to-date knowledge base of current events requires less computational resources than continually training language models is by using a news aggregator. A news aggregator can periodically check for new content from a set of predetermined sources and then provide users with a summary of the new content. This process requires less computational resources than continually training language models because the news aggregator only needs to check for new content from a set of predetermined sources, rather than from all sources of information.', '/CreationDate': \"D:20220702205454-07'00'\", '/M': \"D:20220702205454-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [53, 300, 294.04926, 331.60306], '/C': [1, 1, 0], '/QuadPoints': [197.13202, 331.60306, 294.04926, 331.60306, 197.13202, 325.74796, 294.04926, 325.74796, 53.798, 320.64508, 294.04706, 320.64508, 53.798, 314.79, 294.04706, 314.79, 53, 312, 160.00002, 312, 53, 300, 160.00002, 300], '/T': 'Alejandro Adorjan', '/Contents': 'is that correct that Language models such as\\nGPT-2 are prone to generate factually inaccurate output, often\\ntimes “hallucinating” details?\\n\\nYes, it is correct that GPT-2 and other language models are often inaccurate when generating output. This is because they are not designed to be fact-checkers; instead, they simply generate text based on the patterns they have learned from the training data. As a result, they may sometimes “hallucinate” details that are not actually present in the input.', '/CreationDate': \"D:20220702203719-07'00'\", '/M': \"D:20220702203818-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Text', '/Rect': [53, 300, 294.04926, 331.60306], '/IRT': IndirectObject(279, 0), '/T': 'Alejandro Adorjan', '/Contents': 'is not correct that Language models such as\\nGPT-2 are prone to generate factually inaccurate output, often\\ntimes “hallucinating” details?\\nNo, this is not correct. Language models such as GPT-2 are not prone to generating factually inaccurate output. Instead, they are often able to generate accurate output by hallucinating details that are not present in the input.', '/CreationDate': \"D:20220702203818-07'00'\", '/M': \"D:20220702203818-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [342, 404, 479, 416], '/C': [1, 1, 0], '/QuadPoints': [342, 416, 479, 416, 342, 404, 479, 404], '/T': 'Alejandro Adorjan', '/Contents': 'There are many reasons why one might not want to use machine learning, but some common reasons include:\\n\\n-The data is not appropriate for machine learning (for example, it is too small or too simple).\\n-The data is not available in a suitable format.\\n-The problem is not suited to a machine learning approach (for example, it requires real-time decision making).\\n-It is not possible to train a model that will generalize well to unseen data.\\n-There is a lack of expertise in the team to build and deploy machine learning models.', '/CreationDate': \"D:20220702213049-07'00'\", '/M': \"D:20220702213049-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [69, 604, 143, 615], '/C': [1, 1, 0], '/QuadPoints': [69, 615, 143, 615, 69, 604, 143, 604], '/T': 'Alejandro Adorjan', '/Contents': 'Reseach questions of the article Should we tweet this? Generative response modeling for\\npredicting reception of public health messaging on Twitter\\n\\n1.What factors does the study take into account when predicting the reception of public health messaging on Twitter?\\n2. How does the study define \"reception\" of public health messaging on Twitter?\\n3. How accurate is the study\\'s predictions?\\n4. What implications do the findings have for public health practitioners?', '/CreationDate': \"D:20220702214915-07'00'\", '/M': \"D:20220702214915-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [152, 245.00002, 192, 257], '/C': [1, 1, 0], '/QuadPoints': [152, 257, 192, 257, 152, 245.00002, 192, 245.00002], '/T': 'Alejandro Adorjan', '/Contents': \"Re-training in AI and ML refers to the process of updating a machine learning model with new data. This can be done to improve the model's performance on a new dataset or to adapt the model to a new domain.\", '/CreationDate': \"D:20220702203908-07'00'\", '/M': \"D:20220702203908-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [351, 393, 529, 405], '/C': [1, 1, 0], '/QuadPoints': [351, 405, 529, 405, 351, 393, 529, 393], '/T': 'Alejandro Adorjan', '/Contents': 'What type of model for response generation (GPT-2)?\\n\\nThere is no one-size-fits-all answer to this question, as the type of model for response generation will vary depending on the specific application. However, some common types of models for response generation include recurrent neural networks (RNNs), long short-term memory (LSTM) networks, and GPT-2 networks.\\n\\nother alternatives?\\n\\nSome other possible alternatives for response generation include support vector machines (SVMs), decision trees, and random forests.\\n\\nexample?\\n\\nAs an example, a GPT-2 network might be used to generate responses to questions in a chatbot application.\\n\\nwhen not to use ?\\n\\nIf the goal is simply to generate a response without any specific context or application, then a GPT-2 model may not be the best choice.\\n\\nalternatives?\\n\\nSome other possible alternatives for response generation include support vector machines (SVMs), decision trees, and random forests.\\n\\nexample of support vector machines (SVMs)?\\n\\nAs an example, a support vector machine (SVM) might be used to generate responses to questions in a chatbot application.\\n\\nframeworks?\\n\\nSome common frameworks for response generation include TensorFlow, Keras, PyTorch, and Theano.', '/CreationDate': \"D:20220702212831-07'00'\", '/M': \"D:20220702212831-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [316.00003, 596, 558.4098, 616.53503], '/C': [1, 1, 0], '/QuadPoints': [508.3273, 616.53503, 558.4098, 616.53503, 508.3273, 610.68, 558.4098, 610.68, 316.00003, 608, 448, 608, 316.00003, 596, 448, 596], '/T': 'Alejandro Adorjan', '/Contents': 'SemEval 2017 Twitter sentiment analysis dataset](https://www.figure-eight.com/data-for-everyone/)\\n* [Stanford Sentiment Treebank](http://nlp.stanford.edu/sentiment/treebank.html)\\n\\n## Uses\\n\\n* [Docker](https://www.docker.com/)\\n* [Python 3](https://www.python.org/)\\n* [scikit-learn](https://scikit-learn.org/stable/)\\n* [nltk](https://www.nltk.org/)\\n* [Flask](https://palletsprojects.com/p/flask/)\\n* [Flask-CORS](https://flask-cors.readthedocs.io/en/latest/)\\n\\n## Quickstart\\n\\n1. Install [Docker](https://docs.docker.com/install/)\\n2. Clone this repo\\n3. Build the Docker image\\n```\\ndocker build -t sentiment-demo-api .\\n```\\n4. Run the container\\n```\\ndocker run -p 8080:8080 sentiment-demo-api\\n```\\n5. Visit [http://localhost:8080](http://localhost:8080)', '/CreationDate': \"D:20220702211358-07'00'\", '/M': \"D:20220702211358-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [508, 651, 560, 662], '/C': [1, 1, 0], '/QuadPoints': [508, 662, 560, 662, 508, 651, 560, 651], '/T': 'Alejandro Adorjan', '/Contents': \"What is Q & A?\\n\\nA Q&A is a session where questions are submitted in advance and answered by a panel of experts.\\n\\nRoBERTa sentiment classifier can use Q & A ?\\n\\nI'm not sure if the RoBERTa sentiment classifier can use Q&A, but it's possible that it could be configured to do so.\\nWhat is the interfase of RoBERTa?\\n\\n\\nThere is no one-size-fits-all answer to this question, as the interface of RoBERTa may vary depending on the specific application or context in which it is being used. However, some possible interfaces for RoBERTa could include a graphical user interface (GUI), a command-line interface (CLI), or an application programming interface (API).\\n\\nis RoBERTa open source?\\n\\nYes, RoBERTa is an open-source software project.\\n\\ngithub?\\n\\nYes, RoBERTa is available on GitHub.\\n\\nurl?\\n\\nThe URL for the RoBERTa GitHub repository is https://github.com/pytorch/fairseq/tree/master/examples/roberta.\\n\\nis open for pull request?\\n\\nThe RoBERTa project is open for contributions via pull requests.\", '/CreationDate': \"D:20220702211257-07'00'\", '/M': \"D:20220702211257-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [454, 393, 544, 405], '/C': [1, 1, 0], '/QuadPoints': [454, 405, 544, 405, 454, 393, 544, 393], '/T': 'Alejandro Adorjan', '/Contents': 'when not to use (GPT-2)?\\n\\nThere is no one-size-fits-all answer to this question, as the appropriateness of using GPT-2 will depend on the specific task and data at hand. However, in general, GPT-2 may not be the best choice if the data is too small or too simple, as the model is likely to overfit. Additionally, GPT-2 may not be the best choice if the task is too open-ended, as the model may generate incoherent or nonsensical text.', '/CreationDate': \"D:20220702212937-07'00'\", '/M': \"D:20220702212937-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [92, 158, 172.00002, 169.00002], '/C': [1, 1, 0], '/QuadPoints': [92, 169.00002, 172.00002, 169.00002, 92, 158, 172.00002, 158], '/T': 'Alejandro Adorjan', '/Contents': 'What is information retrieval in ML?\\n\\nInformation retrieval is the process of extracting information from a dataset. It usually involves retrieving a set of records from a database or a search engine.\\n\\nlibraries ?\\n\\nThere are various libraries available for information retrieval in ML. Some of the popular ones include Apache Lucene, Elasticsearch and Solr.\\n\\nSummary of each library:\\n\\nApache Lucene: Apache Lucene is a high-performance, full-featured text search engine library written in Java.\\n\\nElasticsearch: Elasticsearch is a distributed, RESTful search and analytics engine capable of solving a growing number of use cases.\\n\\nSolr: Solr is a highly scalable, open source enterprise search platform built on Apache Lucene.\\n\\nGithub repos?\\n\\nThere are various Github repositories available for information retrieval in ML. Some of the popular ones include:\\n\\n1. https://github.com/apache/lucene-solr\\n\\n2. https://github.com/elastic/elasticsearch\\n\\n3. https://github.com/searchbox-io/Jest\\n\\nexample of information retrival in elasticsearch in python \\n\\nhttps://medium.com/the-artificial-impostor/information-retrieval-in-elasticsearch-using-python-d4a4eb46eae4\\nsource code ?\\n\\nThe source code for the example above can be found here: https://github.com/hongtaocai/elasticsearch-ir', '/CreationDate': \"D:20220702204419-07'00'\", '/M': \"D:20220702204419-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [189, 169.00002, 257, 180.00002], '/C': [1, 1, 0], '/QuadPoints': [189, 180.00002, 257, 180.00002, 189, 169.00002, 257, 169.00002], '/T': 'Alejandro Adorjan', '/Contents': 'What are generative models in ML?\\n\\nGenerative models are a type of machine learning algorithm that can learn to create data that is similar to the data it was trained on. For example, a generative model trained on a dataset of images of faces could learn to generate new images of faces that look realistic.\\n\\nFor example ?\\n\\nA generative model trained on a dataset of images of faces could learn to generate new images of faces that look realistic.\\n\\nLibraries or tools ?\\n\\nThere are many libraries and tools available for training and using generative models. Some popular ones include TensorFlow, Keras, and PyTorch.\\n\\ndifference between these models?\\n\\nThere are many different types of generative models, each with its own advantages and disadvantages. Some popular types include autoencoders, generative adversarial networks (GANs), and variational autoencoders (VAEs).\\n\\nsimilaties?\\n\\nAll generative models learn to create data that is similar to the data they were trained on.\\n\\nPapers to read about?\\n\\nThere are many papers on generative models, some of the most popular ones include \"Generative Adversarial Nets\" by Goodfellow et al. and \"Variational Autoencoders\" by Kingma and Welling.\\n\\ngithub repos ?\\n\\nThere are many Github repositories with code for training and using generative models. Some popular ones include https://github.com/keras-team/keras-gan and https://github.com/pytorch/examples/tree/master/vae.\\n\\nsimple examples in python?\\n\\nHere is a simple example of how to train a generative model using the Keras library:\\n\\n# Load the data (e.g. images of faces)\\n\\ndata = load_data()\\n\\n# Train the model\\n\\nmodel = train_model(data)\\n\\n# Generate new data (e.g. images of faces)\\n\\nnew_data = generate_data(model)', '/CreationDate': \"D:20220702204212-07'00'\", '/M': \"D:20220702204212-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [53, 355.00003, 294.04706, 375.31506], '/C': [1, 1, 0], '/QuadPoints': [257.95804, 375.31506, 294.04706, 375.31506, 257.95804, 369.46002, 294.04706, 369.46002, 53, 365.99997, 232, 365.99997, 53, 355.00003, 232, 355.00003], '/T': 'Alejandro Adorjan', '/Contents': 'List 10 bias of quality of semantic and sentiment similarity measurement\\n\\n1. Limited to a specific domain\\n2. Requires a training dataset\\n3. May not be accurate for all data\\n4. Sentiment may be subjective\\n5. May not be able to capture all nuances\\n6. May be biased towards particular perspectives\\n7. May be affected by noise\\n8. May be affected by outliers\\n9. May be affected by the choice of similarity metric\\n10. May be affected by the choice of data pre-processing', '/CreationDate': \"D:20220702201425-07'00'\", '/M': \"D:20220702201425-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [116, 365.99997, 244, 377], '/C': [1, 1, 0], '/QuadPoints': [116, 377, 244, 377, 116, 365.99997, 244, 365.99997], '/T': 'Alejandro Adorjan', '/Contents': 'are ethical papers that mention: factuality of generated responses;\\n\\ninformation security;\\nprivacy;\\nlegal issues.\\n\\nIn addition to the above listed ethical issues, there are a number of other ethical considerations that may be relevant to a particular chatbot. These additional ethical considerations may include, but are not limited to:\\n\\nthe user’s age and/or maturity;\\nthe user’s country of residence;\\nthe user’s cultural background;\\nthe user’s religious beliefs;\\nthe user’s sexual orientation;\\nthe user’s gender identity;\\nthe user’s political beliefs;\\nthe user’s physical or mental disability;\\nthe user’s social status;\\nthe user’s educational level;\\nthe user’s economic status.\\n\\nThe above listed ethical considerations are not exhaustive and other ethical considerations may also be relevant.', '/CreationDate': \"D:20220702201341-07'00'\", '/M': \"D:20220702201341-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [53, 428.00003, 294.04724, 547.046], '/C': [1, 1, 0], '/QuadPoints': [53.798, 547.046, 294.0454, 547.046, 53.798, 541.191, 294.0454, 541.191, 53.798, 536.08704, 294.04706, 536.08704, 53.798, 530.232, 294.04706, 530.232, 53.798, 525.12805, 294.04532, 525.12805, 53.798, 519.273, 294.04532, 519.273, 53.798, 514.16907, 294.04724, 514.16907, 53.798, 508.314, 294.04724, 508.314, 53.798, 503.21008, 294.04538, 503.21008, 53.798, 497.355, 294.04538, 497.355, 53.798, 492.25104, 294.04352, 492.25104, 53.798, 486.39597, 294.04352, 486.39597, 53.798, 481.29205, 294.04663, 481.29205, 53.798, 475.437, 294.04663, 475.437, 53.798, 470.33307, 294.047, 470.33307, 53.798, 464.47803, 294.047, 464.47803, 53.798, 459.3741, 294.04703, 459.3741, 53.798, 453.51904, 294.04703, 453.51904, 53.798, 448.41507, 294.04712, 448.41507, 53.798, 442.56, 294.04712, 442.56, 53, 439, 248, 439, 53, 428.00003, 248, 428.00003], '/T': 'Alejandro Adorjan', '/Contents': 'What scientific paper mentions: Our main contributions are as follows: (1) we collected two datasets\\nof public health messages and their responses on Twitter, one in\\ncontext of COVID-19 and one in context of Vaccines; (2) we trained\\ntwo GPT-2 text generators - one for each dataset - both capable of\\ncapturing and reproducing the semantic and sentiment distributions\\nin known responses to public health messages; (3) we demonstrate\\nour envisioned use case in which a public health organization uses\\nour models to optimize expected reception for important health\\nguidance; and (4) we introduce a novel evaluation scheme with\\nextensive statistical testing to confirm that our models capture\\nsemantics and sentiment as we qualitatively observe.\\n\\n\"COVID-19 and Vaccine Response Generation with GPT-2\"\\n\\nauthors?\\n\\nThe authors of \"COVID-19 and Vaccine Response Generation with GPT-2\" are William Wang, Alan Yu, and Percy Liang.\\n\\nRefererence bibtex?\\n\\n@article{wang2020covid,\\ntitle={COVID-19 and Vaccine Response Generation with GPT-2},\\nauthor={Wang, William and Yu, Alan and Liang, Percy},\\njournal={arXiv preprint arXiv:2006.02771},\\nyear={2020}\\n}', '/CreationDate': \"D:20220702201122-07'00'\", '/M': \"D:20220702201122-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [78.00001, 322, 195, 334], '/C': [1, 1, 0], '/QuadPoints': [78.00001, 334, 195, 334, 78.00001, 322, 195, 322], '/T': 'Alejandro Adorjan', '/Contents': 'What is Generated Response Factuality?\\n\\nGenerated Response Factuality is a term used to describe the accuracy of a computer-generated response. The response may be in the form of text, audio, or video.\\n\\nExample?\\n\\nOne example of generated response accuracy is in the field of automatic speech recognition (ASR). ASR systems are designed to convert spoken words into text. The accuracy of the ASR system is determined by how well it can recognize the spoken words and convert them into text.\\n\\nWhat ASR are available?\\n\\nThere are many ASR systems available on the market. Some of the more popular ASR systems include Google Voice, Siri, and Cortana.\\n\\nAre open source proyects that use ASR?\\n\\nYes, there are many open source projects that use ASR. Some of the more popular open source ASR projects include CMU Sphinx and Kaldi.\\n\\nand API available?\\n\\nYes, there are many ASR API available. Some of the more popular ASR API include Google Speech API, IBM Watson Speech to Text, and Microsoft Bing Voice Recognition.\\n\\nShow me an example of Google Speech API in python\\n\\nimport speech_recognition as sr\\n\\n# obtain audio from the microphone\\nr = sr.Recognizer()\\nwith sr.Microphone() as source:\\nprint(\"Say something!\")\\naudio = r.listen(source)\\n\\n# recognize speech using Google Speech Recognition\\ntry:\\n# for testing purposes, we\\'re just using the default API key\\n# to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\\n# instead of `r.recognize_google(audio)`\\nprint(\"Google Speech Recognition thinks you said \" + r.recognize_google(audio))\\nexcept sr.UnknownValueError:\\nprint(\"Google Speech Recognition could not understand audio\")\\nexcept sr.RequestError as e:\\nprint(\"Could not request results from Google Speech Recognition service; {0}\".format(e))', '/CreationDate': \"D:20220702201649-07'00'\", '/M': \"D:20220702201649-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'figure.caption.11', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [220.927, 625.278, 227.172, 635.546]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://doi.org/10.18653/v1/2020.acl-main.9'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [147.558, 377.232, 272.482, 385.662]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://doi.org/10.18653/v1/2021.findings-acl.222'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [215.01, 345.352, 295.041, 353.781]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://doi.org/10.18653/v1/2021.findings-acl.222'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [68.238, 337.382, 129.957, 345.811]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://doi.org/10.18653/v1/2020.findings-emnlp.148'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [202.783, 305.501, 295.041, 313.931]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://doi.org/10.18653/v1/2020.findings-emnlp.148'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [68.238, 297.531, 125.236, 305.961]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://doi.org/10.1109/ACCESS.2021.3059821'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [130.473, 201.562, 261.683, 210.121]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://doi.org/10.3115/v1/P15-2073'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [141.136, 153.741, 244.384, 162.171]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://doi.org/10.1016/j.dss.2021.113497'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [126.177, 121.861, 242.275, 130.419]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://doi.org/10.18653/v1/W19-5944'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [277.872, 89.981, 295.041, 98.41]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://doi.org/10.18653/v1/W19-5944'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [68.238, 82.01, 161.221, 90.44]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://arxiv.org/abs/1907.11692'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [432.048, 623.978, 464.76, 632.536]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'http://arxiv.org/abs/1907.11692'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [466.254, 623.978, 556.089, 632.536]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://openreview.net/forum?id=Bkg6RiCqY7'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [428.145, 576.143, 559.358, 584.653]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://doi.org/10.18653/v1/2021.eacl-main.24'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [383.973, 512.397, 515.257, 520.826]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://doi.org/10.18653/v1/S17-2088'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [361.462, 480.516, 467.563, 488.945]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://aclanthology.org/W16-3512'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [416.011, 376.905, 517.454, 385.334]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://arxiv.org/abs/2002.10957'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [376.804, 353.298, 409.517, 361.553]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://doi.org/10.1016/j.chb.2020.106568'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [332.395, 321.114, 449.56, 329.543]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://doi.org/10.1109/ICASSP.2019.8682634'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [455.8, 289.219, 559.198, 297.729]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://doi.org/10.1109/ICASSP.2019.8682634'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [332.395, 282.829, 357.087, 289.204]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/Type': '/Action', '/S': '/URI', '/URI': 'https://doi.org/10.18653/v1/2020.acl-demos.30'}, '/Border': [0, 0, 0], '/C': [0, 1, 1], '/H': '/I', '/Rect': [418.201, 241.413, 550.391, 249.842]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [52, 636, 294.0459, 656.163], '/C': [1, 1, 0], '/QuadPoints': [53.368, 656.163, 294.0459, 656.163, 53.368, 650.308, 294.0459, 650.308, 52, 647, 138, 647, 52, 636, 138, 636], '/T': 'Alejandro Adorjan', '/Contents': 'What are the potential dangers presented by the use of language\\nmodels such as GPT-2?\\n\\nSome potential dangers of using language models such as GPT-2 include the possibility of the model learning and repeating harmful stereotypes, misinformation, or hate speech. Additionally, if the model is not properly monitored, there is a risk that it could be used to generate fake news or to spread propaganda.', '/CreationDate': \"D:20220702213730-07'00'\", '/M': \"D:20220702213730-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [52, 478, 295.55896, 498.5301], '/C': [1, 1, 0], '/QuadPoints': [175.90604, 498.5301, 295.55896, 498.5301, 175.90604, 492.67496, 295.55896, 492.67496, 52, 490, 186, 490, 52, 478, 186, 478], '/T': 'Alejandro Adorjan', '/Contents': 'Who supports and financiate Rensselaer Institute for Data Ex-\\nploration and Applications (IDEA)?\\n\\nThe Rensselaer Institute for Data Exploration and Applications (IDEA) is supported by the National Science Foundation (NSF) and the Rensselaer Polytechnic Institute (RPI).\\n\\ncountry?\\n\\nThe Rensselaer Institute for Data Exploration and Applications (IDEA) is located in the United States.\\n\\nhow many dollars in research?\\n\\nThe Rensselaer Institute for Data Exploration and Applications (IDEA) has received $5 million in research funding from the National Science Foundation (NSF).\\n\\nprincipal researcher ?\\n\\nThe principal researcher at the Rensselaer Institute for Data Exploration and Applications (IDEA) is Christopher Carothers.\\n\\npapers?\\n\\nThe Rensselaer Institute for Data Exploration and Applications (IDEA) has published multiple papers on data exploration and applications.\\n\\nmention 3 most popular datasets?\\n\\nThe Rensselaer Institute for Data Exploration and Applications (IDEA) has worked with multiple datasets, including the Million Song Dataset, the ImageNet dataset, and the Yelp dataset.\\n\\nmention 3 most referenced articles \\n\\n\\nThe Rensselaer Institute for Data Exploration and Applications (IDEA) has published multiple papers on data exploration and applications. Some of the most referenced papers include \"Exploring Data with Dimensionality Reduction Techniques\", \"Data Exploration and Analysis with R\", and \"A Tutorial on Data Exploration and Analysis\".', '/CreationDate': \"D:20220702214512-07'00'\", '/M': \"D:20220702214512-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [53, 526, 294.21234, 557.533], '/C': [1, 1, 0], '/QuadPoints': [271.56802, 557.533, 294.04535, 557.533, 271.56802, 551.678, 294.04535, 551.678, 53.798, 546.57404, 294.21234, 546.57404, 53.798, 540.719, 294.21234, 540.719, 53, 538, 294, 538, 53, 526, 294, 526], '/T': 'Alejandro Adorjan', '/Contents': 'Translate to spanish, Portuguese and Chinese : We do not support or condone the use of our methods, models, or data for any purpose that may directly or indirectly cause harm to others.\\n\\n\\n\\nNo apoyamos ni condonamos el uso de nuestros métodos, modelos o datos con fines que puedan ocasionar directa o indirectamente daño a otras personas.\\n\\nNão apoiamos nem condonamos o uso de nossos métodos, modelos ou dados para qualquer finalidade que possa causar danos a outros, de forma directa ou indirecta.\\n\\n我们不支持或赞同使用我们的方法、模型或数据来直接或间接地对他人造成伤害。', '/CreationDate': \"D:20220702214205-07'00'\", '/M': \"D:20220702214205-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [53, 548, 294.047, 568.491], '/C': [1, 1, 0], '/QuadPoints': [224.00906, 568.491, 294.047, 568.491, 224.00906, 562.636, 294.047, 562.636, 53, 559, 271, 559, 53, 548, 271, 548], '/T': 'Alejandro Adorjan', '/Contents': 'What is real semantics and sentiment of social media discourse ?\\n\\nThe real semantics and sentiment of social media discourse can be difficult to determine. Social media platforms are often used to share opinions and feelings, which can be positive or negative. It can be difficult to determine the overall sentiment of social media discourse without reading through all of the posts and comments.', '/CreationDate': \"D:20220702213936-07'00'\", '/M': \"D:20220702213936-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [139, 603, 261, 614], '/C': [1, 1, 0], '/QuadPoints': [139, 614, 261, 614, 139, 603, 261, 603], '/T': 'Alejandro Adorjan', '/Contents': 'How could be obvious direction for misuse of AI?\\n\\nOne obvious direction for misuse of AI is creating biased algorithms. For example, an algorithm that is meant to predict whether or not someone will commit a crime could be biased against a certain race if the data used to train the algorithm is biased.', '/CreationDate': \"D:20220702213831-07'00'\", '/M': \"D:20220702213831-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Highlight', '/Rect': [332.00003, 552, 558.9712, 575.3829], '/C': [1, 1, 0], '/QuadPoints': [333.391, 575.3829, 558.9712, 575.3829, 333.391, 570.829, 558.9712, 570.829, 333.391, 567.4129, 558.20123, 567.4129, 333.391, 562.859, 558.20123, 562.859, 332.00003, 561.00006, 371, 561.00006, 332.00003, 552, 371, 552], '/T': 'Alejandro Adorjan', '/Contents': 'Who posed the article of fine-tune a GPT-2?\\n\\nOpenAI', '/CreationDate': \"D:20220702181841-07'00'\", '/M': \"D:20220702181841-07'00'\"}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'figure.caption.24', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [179.475, 670.581, 185.554, 680.85]}\n",
            "\n",
            "{'/Type': '/Annot', '/Subtype': '/Link', '/A': {'/D': 'figure.caption.25', '/S': '/GoTo'}, '/Border': [0, 0, 0], '/C': [1, 0, 0], '/H': '/I', '/Rect': [387.991, 670.581, 398.156, 680.85]}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reader = PdfReader(\"paperOAI.pdf\")\n",
        "\n",
        "for page in reader.pages:\n",
        "    if \"/Annots\" in page:\n",
        "        for annot in page[\"/Annots\"]:\n",
        "            subtype = annot.get_object()[\"/Subtype\"]\n",
        "            if subtype == \"/Text\":\n",
        "                print(annot.get_object()[\"/T\"])\n",
        "                print(annot.get_object()[\"/Contents\"])\n",
        "               "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95XbAdFZpJPv",
        "outputId": "7525f989-a091-4c51-a86e-c9e237eab6a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alejandro Adorjan\n",
            "Notar que debe acceder a la biblio\n",
            "Alejandro Adorjan\n",
            "What scientific article do you recomend for reading groundtruth and random-chance baselines?\n",
            "\n",
            "There is no one scientific article that would be recommended for reading groundtruth and random-chance baselines. However, there are a number of articles that could be useful in understanding these concepts. Some potential articles include:\n",
            "\n",
            "\"A tutorial on support vector machines for pattern recognition\" by Christopher J. C. Burges\n",
            "\"Pattern Recognition and Machine Learning\" by Christopher M. Bishop\n",
            "\"The Elements of Statistical Learning\" by Trevor Hastie, Robert Tibshirani, and Jerome Friedman\n",
            "\n",
            "sumarize me in 100 words \"A tutorial on support vector machines for pattern recognition\"\n",
            "\n",
            "Support vector machines are a type of machine learning algorithm that can be used for both classification and regression tasks. The algorithm works by finding a hyperplane that best separates the data points in the training set. For classification tasks, the data points are separated into two classes, and the hyperplane is chosen so that it maximizes the margin between the two classes. For regression tasks, the data points are separated into two groups, and the hyperplane is chosen so that it minimizes the sum of the squared errors.\n",
            "\n",
            "Can you show me an example in python ?\n",
            "\n",
            "Yes. Below is a simple example of a support vector machine for a classification task. The dataset used is the Iris dataset, which includes three classes of Iris flowers.\n",
            "\n",
            "\n",
            "import numpy as np\n",
            "from sklearn import datasets\n",
            "from sklearn.svm import SVC\n",
            "\n",
            "# Load the Iris dataset\n",
            "iris = datasets.load_iris()\n",
            "X = iris.data\n",
            "y = iris.target\n",
            "\n",
            "# Create a support vector classifier\n",
            "clf = SVC(kernel='linear')\n",
            "\n",
            "# Fit the classifier to the data\n",
            "clf.fit(X, y)\n",
            "\n",
            "# Predict the labels for the data\n",
            "y_pred = clf.predict(X)\n",
            "\n",
            "# Calculate the accuracy\n",
            "accuracy = np.mean(y_pred == y)\n",
            "\n",
            "print(\"Accuracy:\", accuracy)\n",
            "Alejandro Adorjan\n",
            "Notar que le agrega Model size\n",
            "Alejandro Adorjan\n",
            "is not correct that Language models such as\n",
            "GPT-2 are prone to generate factually inaccurate output, often\n",
            "times “hallucinating” details?\n",
            "No, this is not correct. Language models such as GPT-2 are not prone to generating factually inaccurate output. Instead, they are often able to generate accurate output by hallucinating details that are not present in the input.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zb_88TVUqUWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(page.extract_text())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp4aG2htnWB8",
        "outputId": "97c48f50-e69e-4d6e-aab2-35e9ca3ff861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A ADDITIONAL REC PLOTS\n",
            "The following shows the semantic similarity REC curves for each individual public health organization account with at least 20 messages in\n",
            "the test set of both datasets. Figure 9 shows REC curves for the COVID-19 dataset and Figure 10 for the Vaccines dataset. The REC curves for\n",
            "each full test set (left-most plot in each figure) are provided here again to facilitate comparison.\n",
            "\n",
            "\n",
            "Figure 9: REC curves using the min cosine distance error metric on the test set of the COVID-19 dataset.\n",
            "\n",
            "\n",
            "Figure 10: REC curves using the min cosine distance error metric on the test set of the Vaccines dataset.\n",
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pypdf2.readthedocs.io/en/latest/user/extract-text.html"
      ],
      "metadata": {
        "id": "4sqd_0KunjjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kc-x3yuUngN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IXK4m-0mgeO",
        "outputId": "fefd6098-3953-4a67-c520-6f5eeaf9fac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notar que debe acceder a la biblio\n",
            "What scientific article do you recomend for reading groundtruth and random-chance baselines?\n",
            "\n",
            "There is no one scientific article that would be recommended for reading groundtruth and random-chance baselines. However, there are a number of articles that could be useful in understanding these concepts. Some potential articles include:\n",
            "\n",
            "\"A tutorial on support vector machines for pattern recognition\" by Christopher J. C. Burges\n",
            "\"Pattern Recognition and Machine Learning\" by Christopher M. Bishop\n",
            "\"The Elements of Statistical Learning\" by Trevor Hastie, Robert Tibshirani, and Jerome Friedman\n",
            "\n",
            "sumarize me in 100 words \"A tutorial on support vector machines for pattern recognition\"\n",
            "\n",
            "Support vector machines are a type of machine learning algorithm that can be used for both classification and regression tasks. The algorithm works by finding a hyperplane that best separates the data points in the training set. For classification tasks, the data points are separated into two classes, and the hyperplane is chosen so that it maximizes the margin between the two classes. For regression tasks, the data points are separated into two groups, and the hyperplane is chosen so that it minimizes the sum of the squared errors.\n",
            "\n",
            "Can you show me an example in python ?\n",
            "\n",
            "Yes. Below is a simple example of a support vector machine for a classification task. The dataset used is the Iris dataset, which includes three classes of Iris flowers.\n",
            "\n",
            "\n",
            "import numpy as np\n",
            "from sklearn import datasets\n",
            "from sklearn.svm import SVC\n",
            "\n",
            "# Load the Iris dataset\n",
            "iris = datasets.load_iris()\n",
            "X = iris.data\n",
            "y = iris.target\n",
            "\n",
            "# Create a support vector classifier\n",
            "clf = SVC(kernel='linear')\n",
            "\n",
            "# Fit the classifier to the data\n",
            "clf.fit(X, y)\n",
            "\n",
            "# Predict the labels for the data\n",
            "y_pred = clf.predict(X)\n",
            "\n",
            "# Calculate the accuracy\n",
            "accuracy = np.mean(y_pred == y)\n",
            "\n",
            "print(\"Accuracy:\", accuracy)\n",
            "Notar que le agrega Model size\n",
            "is not correct that Language models such as\n",
            "GPT-2 are prone to generate factually inaccurate output, often\n",
            "times “hallucinating” details?\n",
            "No, this is not correct. Language models such as GPT-2 are not prone to generating factually inaccurate output. Instead, they are often able to generate accurate output by hallucinating details that are not present in the input.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vPzOKMOyiTTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spacy"
      ],
      "metadata": {
        "id": "DZ9O7s2SeQ2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeYou4Hfb6OW",
        "outputId": "95aa6fbd-a533-451d-973b-5a99fdfb2b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.24.3) or chardet (4.0.0) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "cols = (\"text\", \"lemma\", \"POS\", \"explain\", \"stopword\")\n",
        "rows = []\n",
        "\n",
        "for t in doc:\n",
        "    row = [t.text, t.lemma_, t.pos_, spacy.explain(t.pos_), t.is_stop]\n",
        "    rows.append(row)\n",
        "\n",
        "df = pd.DataFrame(rows, columns=cols)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "y7WtkOUfb9sf",
        "outputId": "a98cf4df-3ac0-4799-bffb-72f8c8b2666d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          text    lemma    POS      explain  stopword\n",
              "0            2        2    NUM      numeral     False\n",
              "1           \\n       \\n  SPACE        space     False\n",
              "2            2        2    NUM      numeral     False\n",
              "3           \\n       \\n  SPACE        space     False\n",
              "4            0        0    NUM      numeral     False\n",
              "...        ...      ...    ...          ...       ...\n",
              "13887  dataset  dataset   NOUN         noun     False\n",
              "13888        .        .  PUNCT  punctuation     False\n",
              "13889     \\n\\n     \\n\\n  SPACE        space     False\n",
              "13890       12       12    NUM      numeral     False\n",
              "13891    \\n\\n\n",
              "    \\n\\n\n",
              "  SPACE        space     False\n",
              "\n",
              "[13892 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aca8814c-df04-4521-a268-480900494335\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>lemma</th>\n",
              "      <th>POS</th>\n",
              "      <th>explain</th>\n",
              "      <th>stopword</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NUM</td>\n",
              "      <td>numeral</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n</td>\n",
              "      <td>\\n</td>\n",
              "      <td>SPACE</td>\n",
              "      <td>space</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>NUM</td>\n",
              "      <td>numeral</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\n</td>\n",
              "      <td>\\n</td>\n",
              "      <td>SPACE</td>\n",
              "      <td>space</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NUM</td>\n",
              "      <td>numeral</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13887</th>\n",
              "      <td>dataset</td>\n",
              "      <td>dataset</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13888</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>punctuation</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13889</th>\n",
              "      <td>\\n\\n</td>\n",
              "      <td>\\n\\n</td>\n",
              "      <td>SPACE</td>\n",
              "      <td>space</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13890</th>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>NUM</td>\n",
              "      <td>numeral</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13891</th>\n",
              "      <td>\\n\\n</td>\n",
              "      <td>\\n\\n</td>\n",
              "      <td>SPACE</td>\n",
              "      <td>space</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13892 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aca8814c-df04-4521-a268-480900494335')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aca8814c-df04-4521-a268-480900494335 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aca8814c-df04-4521-a268-480900494335');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wcK3nFnQcTUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kdUN7FhcBlb",
        "outputId": "9fdc5a2f-0be5-41c6-f4ff-54ac6c72af75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 CARDINAL\n",
            "2 CARDINAL\n",
            "0 CARDINAL\n",
            "2 CARDINAL\n",
            "3 CARDINAL\n",
            "1 CARDINAL\n",
            "2 CARDINAL\n",
            "3 CARDINAL\n",
            "4 CARDINAL\n",
            "4 CARDINAL\n",
            "2 CARDINAL\n",
            "2 CARDINAL\n",
            "Twitter\n",
            "\n",
            "Abraham Sanders LAW\n",
            "Rensselaer Polytechnic Institute ORG\n",
            "Troy GPE\n",
            "New York GPE\n",
            "USA GPE\n",
            "John S. Erickson PERSON\n",
            "Rensselaer Polytechnic Institute ORG\n",
            "Troy GPE\n",
            "New York GPE\n",
            "USA GPE\n",
            "Debjani Ray-Majumder PERSON\n",
            "Rensselaer Polytechnic Institute ORG\n",
            "Troy GPE\n",
            "New York GPE\n",
            "USA GPE\n",
            "Kristin P. Bennett PERSON\n",
            "Rensselaer Polytechnic Institute ORG\n",
            "Troy GPE\n",
            "New York GPE\n",
            "USA GPE\n",
            "bennek@rpi.edu\n",
            "\n",
            "ABSTRACT ORG\n",
            "the US Centers for Disease Control and Prevention ORG\n",
            "CDC ORG\n",
            "the World Health Organization ORG\n",
            "two CARDINAL\n",
            "Vaccines ORG\n",
            "GPT-2 GPE\n",
            "• Information ORG\n",
            "19 CARDINAL\n",
            "COVID-19 PERSON\n",
            "Twitter PRODUCT\n",
            "23 CARDINAL\n",
            "COVID-19 PERSON\n",
            "NLP ORG\n",
            "Sanders et al. PERSON\n",
            "20 CARDINAL\n",
            "the early days DATE\n",
            "7 CARDINAL\n",
            "the month DATE\n",
            "COVID-19 PERSON\n",
            "US CDC PERSON\n",
            "CDC ORG\n",
            "WHO ORG\n",
            "Twitter PRODUCT\n",
            "two CARDINAL\n",
            "1 CARDINAL\n",
            "March 1st, 2020 DATE\n",
            "September 30th, 2020 DATE\n",
            "2 CARDINAL\n",
            "October 1st, 2021 to January 31st, 2022 DATE\n",
            "16 CARDINAL\n",
            "ground-\n",
            "truth ORG\n",
            "two CARDINAL\n",
            "1 CARDINAL\n",
            "two CARDINAL\n",
            "Vaccines ORG\n",
            "2 CARDINAL\n",
            "GPT-2 ORG\n",
            "3 CARDINAL\n",
            "1 CARDINAL\n",
            "CDC Accounts ORG\n",
            "4 CARDINAL\n",
            "ecdc_eu GPE\n",
            "U.S. GPE\n",
            "CDC ORG\n",
            "5 CARDINAL\n",
            "CDC_NCBDDD CDC_NCEZID CDC_TB ORG\n",
            "CDCHaiti ORG\n",
            "CDChep ORG\n",
            "CDCInjury CDCKenya MONEY\n",
            "CDCMakeHealthEZ ORG\n",
            "CDCMMWR ORG\n",
            "CDCRwanda GPE\n",
            "CDCSTD ORG\n",
            "CDCTravel CPSTF ORG\n",
            "NIOSHMining PRODUCT\n",
            "NIOSH_TWH ORG\n",
            "NIOSHConstruct NIOSHespanol ORG\n",
            "4 CARDINAL\n",
            "GPT-2 GPE\n",
            "5 CARDINAL\n",
            "GitHub ORG\n",
            "1 CARDINAL\n",
            "20 CARDINAL\n",
            "COVID-19 & Vaccine ORG\n",
            "API ORG\n",
            "COVID-19 PRODUCT\n",
            "Vaccine PERSON\n",
            "Tweepy ORG\n",
            "the Twitter API PRODUCT\n",
            "Table 1 PRODUCT\n",
            "COVID-19 Public Health ORG\n",
            "COVID-19 PERSON\n",
            "8,475 CARDINAL\n",
            "70,331 CARDINAL\n",
            "between March 1st, 2020 and September 30th DATE\n",
            "WHO ORG\n",
            "CDCgov CARDINAL\n",
            "1 CARDINAL\n",
            "1 CARDINAL\n",
            "295,468,580 CARDINAL\n",
            "COVID-19 PERSON\n",
            "20 CARDINAL\n",
            "2See CARDINAL\n",
            "3See CARDINAL\n",
            "4See CARDINAL\n",
            "https://www.ecdc.europa.eu/en/about-us/press-and-media/ecdc-social-media ORG\n",
            "5See CARDINAL\n",
            "1 CARDINAL\n",
            "ten CARDINAL\n",
            "2 CARDINAL\n",
            "one CARDINAL\n",
            "Table 1 LAW\n",
            "3 CARDINAL\n",
            "Vaccine Public Health ORG\n",
            "Vaccine PERSON\n",
            "3,060 CARDINAL\n",
            "Table 1 LAW\n",
            "61,009 CARDINAL\n",
            "between October 1st, 2021 DATE\n",
            "January\n",
            "31st, 2022 DATE\n",
            "CDCgov ORG\n",
            "COVID-19 PERSON\n",
            "1 CARDINAL\n",
            "COVID-19 PERSON\n",
            "Section 2.1 LAW\n",
            "approximately 10,000 CARDINAL\n",
            "52,282,174 CARDINAL\n",
            "EXPERIMENTAL SETUP ORG\n",
            "Section 1 LAW\n",
            "GPT-2 ORG\n",
            "8 CARDINAL\n",
            "24 CARDINAL\n",
            "GPT-2 ORG\n",
            "2 CARDINAL\n",
            "Training & Test ORG\n",
            "3 CARDINAL\n",
            "Avg GPE\n",
            "5 CARDINAL\n",
            "9,300 CARDINAL\n",
            "Avg GPE\n",
            "140 CARDINAL\n",
            "60 CARDINAL\n",
            "27,878 CARDINAL\n",
            "8,400 CARDINAL\n",
            "16∗ DATE\n",
            "13 CARDINAL\n",
            "TweetEval PRODUCT\n",
            "3 CARDINAL\n",
            "1 CARDINAL\n",
            "−1 CARDINAL\n",
            "0 DATE\n",
            "1 CARDINAL\n",
            "MiniLM ORDINAL\n",
            "22 CARDINAL\n",
            "over one billion CARDINAL\n",
            "32 CARDINAL\n",
            "Train / Test Split ORG\n",
            "at least 60 CARDINAL\n",
            "30 CARDINAL\n",
            "two CARDINAL\n",
            "one CARDINAL\n",
            "COVID-19 PERSON\n",
            "Vaccine PERSON\n",
            "Table 2 PRODUCT\n",
            "762 million CARDINAL\n",
            "one CARDINAL\n",
            "three CARDINAL\n",
            "https://huggingface.co/gpt2-large ORG\n",
            "3 CARDINAL\n",
            "#COVID19 # MONEY\n",
            "THIS?<|author|>CDCdirector<|response| ORG\n",
            "1 CARDINAL\n",
            "2 CARDINAL\n",
            "N CARDINAL\n",
            "# CARDINAL\n",
            "4 CARDINAL\n",
            "35,118 CARDINAL\n",
            "25,090 CARDINAL\n",
            "2,788 CARDINAL\n",
            "2 CARDINAL\n",
            "2.82 CARDINAL\n",
            "1 CARDINAL\n",
            "2 CARDINAL\n",
            "3 CARDINAL\n",
            "GPT-2 ORG\n",
            "Table 3 LAW\n",
            "10% PERCENT\n",
            "AdamW GPE\n",
            "15 CARDINAL\n",
            "3 CARDINAL\n",
            "15 CARDINAL\n",
            "4 CARDINAL\n",
            "three CARDINAL\n",
            "GPT-2 ORG\n",
            "COVID-19 PRODUCT\n",
            "Vaccine PERSON\n",
            "30 CARDINAL\n",
            "num_beams=3 ORG\n",
            "Evaluation & Baselines ORG\n",
            "1 CARDINAL\n",
            "60 CARDINAL\n",
            "2 CARDINAL\n",
            "30 CARDINAL\n",
            "60 CARDINAL\n",
            "two CARDINAL\n",
            "30 CARDINAL\n",
            "1 CARDINAL\n",
            "30 CARDINAL\n",
            "2 CARDINAL\n",
            "30 CARDINAL\n",
            "2 CARDINAL\n",
            "3 CARDINAL\n",
            "30 CARDINAL\n",
            "2 CARDINAL\n",
            "Section 5 LAW\n",
            "4.1 CARDINAL\n",
            "3 CARDINAL\n",
            "two CARDINAL\n",
            "COVID-19 & Vaccines ORG\n",
            "five CARDINAL\n",
            "Section 5 LAW\n",
            "five CARDINAL\n",
            "60 CARDINAL\n",
            "× 4 EVENT\n",
            "first ORDINAL\n",
            "COVID-19 PERSON\n",
            "CDC ORG\n",
            "Trump ORG\n",
            "CDC ORG\n",
            "second ORDINAL\n",
            "WHO ORG\n",
            "WHO ORG\n",
            "China GPE\n",
            "third ORDINAL\n",
            "Vaccines ORG\n",
            "CDCgov CARDINAL\n",
            "FDA ORG\n",
            "fourth ORDINAL\n",
            "Vaccines ORG\n",
            "CDCDirector ORG\n",
            "COVID-19 PERSON\n",
            "first ORDINAL\n",
            "Vaccines ORG\n",
            "30 CARDINAL\n",
            "30 CARDINAL\n",
            "COVID-19 PERSON\n",
            "This fall DATE\n",
            "bookbags & homework ORG\n",
            "CDC ORG\n",
            "the upcoming school year DATE\n",
            "@CDC ORG\n",
            "@GOP LOC\n",
            "CDC ORG\n",
            "CDC ORG\n",
            "patsy PERSON\n",
            "American NORP\n",
            "CDC ORG\n",
            "America GPE\n",
            "cdc ORG\n",
            "the Republican Convention ORG\n",
            "CDC ORG\n",
            "American NORP\n",
            "one CARDINAL\n",
            "CDC ORG\n",
            "Trump ORG\n",
            "CDC ORG\n",
            "CDC ORG\n",
            "CDC ORG\n",
            "CDC ORG\n",
            "American NORP\n",
            "thousands CARDINAL\n",
            "Trump ORG\n",
            "COVID-19 PERSON\n",
            "COVID19 ORG\n",
            "# CARDINAL\n",
            "One CARDINAL\n",
            "COVID19 ORG\n",
            "@WHO ORG\n",
            "China GPE\n",
            "# CARDINAL\n",
            "WHOLiedPeopleDied ORG\n",
            "CCP ORG\n",
            "DefundWHO ORG\n",
            "#CCPVirus MONEY\n",
            "XiJinping ORG\n",
            "China GPE\n",
            "@WHO ORG\n",
            "the Wuhan Virus ORG\n",
            "china GPE\n",
            "China GPE\n",
            "The Chinese Communist Party ORG\n",
            "# CARDINAL\n",
            "China GPE\n",
            "@WHO @DrTedros WHO ORG\n",
            "Chinese NORP\n",
            "@WHO @DrTedros @DrTedros ORG\n",
            "China GPE\n",
            "CDCgov CARDINAL\n",
            "WIFE ORG\n",
            "only 31% PERCENT\n",
            "CDC ORG\n",
            "# CARDINAL\n",
            "GburgGHFall21\n",
            "\n",
            "@CDCgov WORK_OF_ART\n",
            "@CDC ORG\n",
            "COVID19Vaccine PRODUCT\n",
            "ArmyMedicine ORG\n",
            "# MONEY\n",
            "FDA ORG\n",
            "COVAXIN ORG\n",
            "WeArePalmGarden\n",
            "\n",
            "Message ORG\n",
            "Today DATE\n",
            "ACIP ORG\n",
            "5-11 CARDINAL\n",
            "US GPE\n",
            "HCG ORG\n",
            "Ivermetin ORG\n",
            "cdc ORG\n",
            "#Covid19vaxxed # MONEY\n",
            "5-11 year old DATE\n",
            "# CARDINAL\n",
            "5-11 years old DATE\n",
            "Pfizer COVID PERSON\n",
            "@ACIP ORG\n",
            "5-11 year olds DATE\n",
            "#COVID19 # MONEY\n",
            "Influenza / Flu Measles ORG\n",
            "HPV ORG\n",
            "Wear a Mask Public Places Public ORG\n",
            "3 CARDINAL\n",
            "first ORDINAL\n",
            "Avg GPE\n",
            "−0.253 CARDINAL\n",
            "± 0.491):∗ ORG\n",
            "FDA ORG\n",
            "COVAXIN ORG\n",
            "COVAXIN ORG\n",
            "#N564Health ORG\n",
            "EU ORG\n",
            "EU ORG\n",
            "US GPE\n",
            "# CARDINAL\n",
            "two CARDINAL\n",
            "@Eurosurveillanc ORG\n",
            "@EU_opendata @EU_EESC @eupatientsforum PERSON\n",
            "Avg GPE\n",
            "0.218 CARDINAL\n",
            "VaccinesWork ORG\n",
            "today DATE\n",
            "@EMA_News DATE\n",
            "@Eurosurveillanc ORG\n",
            "#VaccinesWork PERCENT\n",
            "2 CARDINAL\n",
            "1 Moderna GPE\n",
            "1 CARDINAL\n",
            "2nd ORDINAL\n",
            "2nd ORDINAL\n",
            "VaccinesWork ORG\n",
            "today DATE\n",
            "VaccinesSaveLives MONEY\n",
            "VaccinEquity PRODUCT\n",
            "@EMA_News DATE\n",
            "@EU_ECHA PERSON\n",
            "# CARDINAL\n",
            "First ORDINAL\n",
            "10 CARDINAL\n",
            "30 CARDINAL\n",
            "30 CARDINAL\n",
            "4 CARDINAL\n",
            "Vaccines NORP\n",
            "4 CARDINAL\n",
            "0.47 CARDINAL\n",
            "-1 ORG\n",
            "1 CARDINAL\n",
            "first ORDINAL\n",
            "ten CARDINAL\n",
            "Twitter PRODUCT\n",
            "GPT-2 GPE\n",
            "Twitter ORG\n",
            "Reddit GPE\n",
            "5.1 CARDINAL\n",
            "Semantic Similarity GPE\n",
            "max PERSON\n",
            "three CARDINAL\n",
            "30 CARDINAL\n",
            "max PERSON\n",
            "one CARDINAL\n",
            "one CARDINAL\n",
            "max PERSON\n",
            "at least one CARDINAL\n",
            "10 CARDINAL\n",
            "three CARDINAL\n",
            "1 CARDINAL\n",
            "4 CARDINAL\n",
            "2 CARDINAL\n",
            "two CARDINAL\n",
            "max PERSON\n",
            "3 CARDINAL\n",
            "max PERSON\n",
            "Regression Error Characteristic ORG\n",
            "ROC GPE\n",
            "4 CARDINAL\n",
            "ROC GPE\n",
            "AUC-ROC ORG\n",
            "5 CARDINAL\n",
            "Reference\n",
            "Primary ORG\n",
            "Model\n",
            "Primary ORG\n",
            "Random\n",
            "Model % ORG\n",
            "Difference∗ NORP\n",
            "0.571 MONEY\n",
            "0.458 CARDINAL\n",
            "0.565 CARDINAL\n",
            "0.517 MONEY\n",
            "0.442 CARDINAL\n",
            "0.544 ORG\n",
            "0.466 CARDINAL\n",
            "71.7% PERCENT\n",
            "61.0% PERCENT\n",
            "84.8% PERCENT\n",
            "0.610 CARDINAL\n",
            "0.500 CARDINAL\n",
            "86.4% PERCENT\n",
            "Reference\n",
            "Primary ORG\n",
            "Model\n",
            "Primary ORG\n",
            "Random\n",
            "Model % ORG\n",
            "100 CARDINAL\n",
            "0.653 MONEY\n",
            "0.620 MONEY\n",
            "0.616 CARDINAL\n",
            "0.592 MONEY\n",
            "0.599 MONEY\n",
            "0.576 CARDINAL\n",
            "0.538 CARDINAL\n",
            "66.7% PERCENT\n",
            "69.2% PERCENT\n",
            "62.3% PERCENT\n",
            "0.626 MONEY\n",
            "0.609 MONEY\n",
            "0.559 CARDINAL\n",
            "74.6% PERCENT\n",
            "ROC GPE\n",
            "Primary PERSON\n",
            "Reference PERSON\n",
            "Model ORG\n",
            "Random PERSON\n",
            "1 CARDINAL\n",
            "30 CARDINAL\n",
            "max PERSON\n",
            "𝑀 × ORG\n",
            "COVID-19 PERSON\n",
            "155 CARDINAL\n",
            "30 CARDINAL\n",
            "4 CARDINAL\n",
            "650 CARDINAL\n",
            "max PERSON\n",
            "2 CARDINAL\n",
            "1 CARDINAL\n",
            "3 CARDINAL\n",
            "1 CARDINAL\n",
            "three CARDINAL\n",
            "one CARDINAL\n",
            "two CARDINAL\n",
            "AUC ORG\n",
            "4 CARDINAL\n",
            "5 CARDINAL\n",
            "AUC ORG\n",
            "AUC ORG\n",
            "at least 20 CARDINAL\n",
            "WHO ORG\n",
            "CDCgov ORG\n",
            "CDCDirector CARDINAL\n",
            "Appendix A.\n",
            "\n",
            "To PERSON\n",
            "the Model % Difference ORG\n",
            "AUC ORG\n",
            "two CARDINAL\n",
            "100% PERCENT\n",
            "0% PERCENT\n",
            "AUC ORG\n",
            "Model % PERCENT\n",
            "71.7% PERCENT\n",
            "COVID-19 PERSON\n",
            "66.7% PERCENT\n",
            "Vaccines ORG\n",
            "COVID-19 PERSON\n",
            "CDCgov CARDINAL\n",
            "WHO ORG\n",
            "Model % PERCENT\n",
            "86.4% PERCENT\n",
            "CDCDirector ORG\n",
            "84.8% PERCENT\n",
            "CDCgov CARDINAL\n",
            "only 61.0% PERCENT\n",
            "WHO ORG\n",
            "Vaccines ORG\n",
            "CDCDirector PRODUCT\n",
            "WHO ORG\n",
            "CDCgov ORG\n",
            "Model % PERCENT\n",
            "74.6% PERCENT\n",
            "69.2% PERCENT\n",
            "WHO ORG\n",
            "only 62.3% PERCENT\n",
            "CDCgov CARDINAL\n",
            "5 CARDINAL\n",
            "REC-AUC ORG\n",
            "two CARDINAL\n",
            "max PERSON\n",
            "30 CARDINAL\n",
            "max PERSON\n",
            "three CARDINAL\n",
            "𝑀 × ORG\n",
            "one CARDINAL\n",
            "two CARDINAL\n",
            "two CARDINAL\n",
            "1 CARDINAL\n",
            "2 CARDINAL\n",
            "5% PERCENT\n",
            "at least 20 CARDINAL\n",
            "WHO ORG\n",
            "CDCgov CARDINAL\n",
            "CDCDirector CARDINAL\n",
            "Model % PERCENT\n",
            "max PERSON\n",
            "less than 1% PERCENT\n",
            "Model ORG\n",
            "Model % PERCENT\n",
            "71.7% PERCENT\n",
            "70.8% PERCENT\n",
            "Vaccines ORG\n",
            "Model % PERCENT\n",
            "66.7% PERCENT\n",
            "67.6% PERCENT\n",
            "the\n",
            "AUC-REC ORG\n",
            "max PERSON\n",
            "Reference PERSON\n",
            "Random PERSON\n",
            "6 CARDINAL\n",
            "Mean PERSON\n",
            "max PERSON\n",
            "Sim PERSON\n",
            "7 CARDINAL\n",
            "Chi-Square PERSON\n",
            "0.01 CARDINAL\n",
            "Random Baselines PERSON\n",
            "Random Baseline PERSON\n",
            "Model % PERCENT\n",
            "Difference∗ ORG\n",
            "83.9% PERCENT\n",
            "0.01 CARDINAL\n",
            "+0.080\n",
            "\n",
            "+0.124 PERSON\n",
            "70.8% PERCENT\n",
            "61.3% PERCENT\n",
            "86.4% PERCENT\n",
            "Random Baselines PERSON\n",
            "Random Baseline PERSON\n",
            "Model % PERCENT\n",
            "100 CARDINAL\n",
            "Random Baseline PERSON\n",
            "Random Baselines PERSON\n",
            "+0.061\n",
            "+0.038\n",
            "\n",
            " PRODUCT\n",
            "67.6% PERCENT\n",
            "68.5% PERCENT\n",
            "62.3% PERCENT\n",
            "74.6% PERCENT\n",
            "Reference\n",
            "Primary ORG\n",
            "Model\n",
            "Primary ORG\n",
            "Random ORG\n",
            "72.9% PERCENT\n",
            "55.5% PERCENT\n",
            "43.9% PERCENT\n",
            "77.1% PERCENT\n",
            "49.4% PERCENT\n",
            "41.0% PERCENT\n",
            "70.4% PERCENT\n",
            "65.9% PERCENT\n",
            "65.9% PERCENT\n",
            "Reference\n",
            "Primary ORG\n",
            "Model\n",
            "Primary ORG\n",
            "Random ORG\n",
            "63.6% PERCENT\n",
            "52.8% PERCENT\n",
            "43.6% PERCENT\n",
            "82.6% PERCENT\n",
            "34.8% PERCENT\n",
            "43.5% PERCENT\n",
            "59.1% PERCENT\n",
            "57.7% PERCENT\n",
            "45.0% PERCENT\n",
            "65.4% PERCENT\n",
            "57.7% PERCENT\n",
            "19.2% PERCENT\n",
            "58.1% PERCENT\n",
            "55.8% PERCENT\n",
            "44.2% PERCENT\n",
            "Random GPE\n",
            "Section 3 LAW\n",
            "three CARDINAL\n",
            "1 CARDINAL\n",
            "2 CARDINAL\n",
            "0.25 CARDINAL\n",
            "3 CARDINAL\n",
            "0.25 CARDINAL\n",
            "three CARDINAL\n",
            "Chi-square PERSON\n",
            "three CARDINAL\n",
            "one CARDINAL\n",
            "5% PERCENT\n",
            "Chi-Square PERSON\n",
            "Primary PERSON\n",
            "Reference PERSON\n",
            "Primary PERSON\n",
            "Model PERSON\n",
            "Primary PERSON\n",
            "Vaccine PERSON\n",
            "Primary PERSON\n",
            "Reference PERSON\n",
            "72.9% PERCENT\n",
            "COVID-19 PERSON\n",
            "63.6% PERCENT\n",
            "Vaccines ORG\n",
            "Primary ORG\n",
            "Model ORG\n",
            "55.5% PERCENT\n",
            "COVID-19 GPE\n",
            "52.8% PERCENT\n",
            "Vaccines ORG\n",
            "Model ORG\n",
            "Primary PERSON\n",
            "Random PERSON\n",
            "43.9% PERCENT\n",
            "COVID-19 PERSON\n",
            "43.6% PERCENT\n",
            "one CARDINAL\n",
            "Vaccine PERSON\n",
            "WHO ORG\n",
            "6 CARDINAL\n",
            "max PERSON\n",
            "two CARDINAL\n",
            "𝑀 × ORG\n",
            "max PERSON\n",
            "Pearson ORG\n",
            "two CARDINAL\n",
            "6 CARDINAL\n",
            "COVID-19 PERSON\n",
            "0.58 CARDINAL\n",
            "2.2 CARDINAL\n",
            "0.71 CARDINAL\n",
            "2.2 CARDINAL\n",
            "Vaccines NORP\n",
            "Vaccines ORG\n",
            "AUC ORG\n",
            "COVID-19 PERSON\n",
            "Model % PERCENT\n",
            "GPT-2 GPE\n",
            "COVID-19 PERSON\n",
            "Vaccine PERSON\n",
            "7 CARDINAL\n",
            "19 CARDINAL\n",
            "Vaccine PERSON\n",
            "8 CARDINAL\n",
            "19 CARDINAL\n",
            "Vaccine PERSON\n",
            "Model, Primary WORK_OF_ART\n",
            "Random PERSON\n",
            "7 CARDINAL\n",
            "Primary PERSON\n",
            "Primary PERSON\n",
            "Model ORG\n",
            "Random ORG\n",
            "8 CARDINAL\n",
            "CDCgov ORG\n",
            "CDCDirector CARDINAL\n",
            "WHO ORG\n",
            "Vaccine ORG\n",
            "DialoGPT ORG\n",
            "25 CARDINAL\n",
            "GPT-2 GPE\n",
            "147\n",
            "million MONEY\n",
            "Reddit GPE\n",
            "PLATO ORG\n",
            "1 CARDINAL\n",
            "2 CARDINAL\n",
            "BlenderBot ORG\n",
            "17 CARDINAL\n",
            "PLATO ORG\n",
            "Twitter ORG\n",
            "Reddit GPE\n",
            "6 CARDINAL\n",
            "Twitter PRODUCT\n",
            "Tran & ORG\n",
            "Popowich ORG\n",
            "Roy et al PERSON\n",
            "19 CARDINAL\n",
            "21 CARDINAL\n",
            "Lofi & Krestel ORG\n",
            "14 CARDINAL\n",
            "Garvey et al ORG\n",
            "9 CARDINAL\n",
            "Garvey et al ORG\n",
            "Garvey et al. ORG\n",
            "CONCLUSION ORG\n",
            "1 CARDINAL\n",
            "two CARDINAL\n",
            "Twitter ORG\n",
            "one CARDINAL\n",
            "COVID-19 PERSON\n",
            "Vaccines ORG\n",
            "2 CARDINAL\n",
            "two CARDINAL\n",
            "GPT-2 ORG\n",
            "3 CARDINAL\n",
            "4 CARDINAL\n",
            "1 CARDINAL\n",
            "2 CARDINAL\n",
            "3 CARDINAL\n",
            "4 CARDINAL\n",
            "12 CARDINAL\n",
            "3 CARDINAL\n",
            "COVID-19 PERSON\n",
            "the early months DATE\n",
            "RAG PRODUCT\n",
            "11 CARDINAL\n",
            "MiniLM PRODUCT\n",
            "32 CARDINAL\n",
            "Wikipedia ORG\n",
            "Q&A ORG\n",
            "Reddit GPE\n",
            "Quora, Stack Exchange ORG\n",
            "Yahoo Answers ORG\n",
            "TweetEval ORG\n",
            "SemEval ORG\n",
            "2017 DATE\n",
            "18 CARDINAL\n",
            "over 50,000 CARDINAL\n",
            "English NORP\n",
            "one CARDINAL\n",
            "Section 6 LAW\n",
            "GPT-3 ORG\n",
            "5 CARDINAL\n",
            "GPT-2 GPE\n",
            "Garvey et al. ORG\n",
            "Twitter PRODUCT\n",
            "Twitter ORG\n",
            "Section 4.2 LAW\n",
            "1 CARDINAL\n",
            "2 CARDINAL\n",
            "11 CARDINAL\n",
            "Perez ORG\n",
            "Piktus ORG\n",
            "F Petroni PERSON\n",
            "N Goyal ORG\n",
            "H Küttler PERSON\n",
            "T Rocktäschel PERSON\n",
            "2020 DATE\n",
            "33 CARDINAL\n",
            "2020 DATE\n",
            "9459–9474 CARDINAL\n",
            "12 CARDINAL\n",
            "Y Zhang PERSON\n",
            "Y Mao PERSON\n",
            "W Chen PERSON\n",
            "Dolan ORG\n",
            "2021 DATE\n",
            "arXiv:2104.08704 GPE\n",
            "2021 DATE\n",
            "13 CARDINAL\n",
            "] Y Liu PERSON\n",
            "N Goyal ORG\n",
            "M Joshi PERSON\n",
            "D Chen PERSON\n",
            "L Zettlemoyer GPE\n",
            "2019 DATE\n",
            "CoRR abs/1907.11692 ORG\n",
            "2019 DATE\n",
            "http://arxiv.org/abs/1907.11692\n",
            "iParticipate: ORG\n",
            "Automatic Tweet Generation WORK_OF_ART\n",
            "Database Systems for Advanced Applications ORG\n",
            "Lee PERSON\n",
            "Y-S Moon GPE\n",
            "Berlin GPE\n",
            "295–298 CARDINAL\n",
            "14 CARDINAL\n",
            "2012 DATE\n",
            "15 CARDINAL\n",
            "F Hutter PERSON\n",
            "2019 DATE\n",
            "Intl ORG\n",
            "16 CARDINAL\n",
            "Jeffrey Wu PERSON\n",
            "Rewon Child PERSON\n",
            "David Luan PERSON\n",
            "Dario Amodei PERSON\n",
            "Ilya Sutskever PERSON\n",
            "2019 DATE\n",
            "OpenAI ORG\n",
            "1 CARDINAL\n",
            "8 CARDINAL\n",
            "2019 DATE\n",
            "9 CARDINAL\n",
            "17 CARDINAL\n",
            "Dinan GPE\n",
            "N Goyal ORG\n",
            ", M Williamson PERSON\n",
            "Y Liu PERSON\n",
            "J Xu PERSON\n",
            "EM Smith PERSON\n",
            "Lan Boureau PERSON\n",
            "Weston GPE\n",
            "2021 DATE\n",
            "Building an Open-Domain Chatbot WORK_OF_ART\n",
            "Proc of the 16th DATE\n",
            "Conference of the European Chapter of the Assoc EVENT\n",
            "Association for Computational Linguistics ORG\n",
            "300–325 CARDINAL\n",
            "18 CARDINAL\n",
            "N Farra ORG\n",
            "Nakov PERSON\n",
            "2017 DATE\n",
            "SemEval-2017 Task 4 PRODUCT\n",
            "Twitter LOC\n",
            "11th ORDINAL\n",
            "Semantic Evaluation ORG\n",
            "Association for Computational Linguistics ORG\n",
            "Vancouver GPE\n",
            "Canada GPE\n",
            "502–518 CARDINAL\n",
            "19 CARDINAL\n",
            "P Dutta ORG\n",
            "S Choudhury GPE\n",
            "2022 DATE\n",
            "Probabilistic Traffic Tweet Generation\n",
            "Model ORG\n",
            "J P Sahoo ORG\n",
            "A K Tripathy PERSON\n",
            "K-C Li ORG\n",
            "A K Nayak (Eds PRODUCT\n",
            "Singapore GPE\n",
            "250–260 CARDINAL\n",
            "20 CARDINAL\n",
            "L S Severson GPE\n",
            "J S Erickson ORG\n",
            "K P Bennett ORG\n",
            "2021 DATE\n",
            "COVID-19\n",
            "Twitter ORG\n",
            "2021 DATE\n",
            "American Medical\n",
            "Informatics Association ORG\n",
            "555 CARDINAL\n",
            "21 CARDINAL\n",
            "F Popowich PERSON\n",
            "2016 DATE\n",
            "Automatic Tweet Generation From Traffic Incident EVENT\n",
            "2nd ORDINAL\n",
            "Intl Workshop on Natural Language Generation EVENT\n",
            "Association for Computational Linguistics ORG\n",
            "Edinburgh GPE\n",
            "Scotland GPE\n",
            "59–66 CARDINAL\n",
            "22 CARDINAL\n",
            "] W Wang PERSON\n",
            "F Wei PERSON\n",
            "L Dong GPE\n",
            "H Bao ORG\n",
            "N Yang ORG\n",
            "M Zhou PERSON\n",
            "2020 DATE\n",
            "23 CARDINAL\n",
            "H Hao ORG\n",
            "L Sundahl Platt GPE\n",
            "2021 DATE\n",
            "114 CARDINAL\n",
            "2021 DATE\n",
            "106568 DATE\n",
            "24 CARDINAL\n",
            "S Lu PERSON\n",
            "L Mou GPE\n",
            "H Zhou PERSON\n",
            "G Li PERSON\n",
            "Jin PERSON\n",
            "2019 DATE\n",
            "Meaningless Replies ORG\n",
            "Comparison ORG\n",
            "2019 - 2019 DATE\n",
            "IEEE Intl Conf ORG\n",
            "Acoustics ORG\n",
            "Speech ORG\n",
            "Signal Processing ( ORG\n",
            "ICASSP ORG\n",
            "7290–7294 CARDINAL\n",
            "25 CARDINAL\n",
            "M Galley PERSON\n",
            "Gao PERSON\n",
            "Gao PERSON\n",
            "J Liu PERSON\n",
            "Dolan ORG\n",
            "Conversational ORG\n",
            "58th ORDINAL\n",
            "Annual Meeting of the Association for\n",
            "Computational Linguistics: System Demonstrations. EVENT\n",
            "Online ORG\n",
            "270–278 CARDINAL\n",
            "3 CARDINAL\n",
            "GPT-2 ORG\n",
            "3 CARDINAL\n",
            "the Rensselaer Institute for Data ORG\n",
            "IDEA ORG\n",
            "Rensselaer Data PERSON\n",
            "the United Health Foundation ORG\n",
            "Brandyn Sigouin PERSON\n",
            "Thomas Shweh PERSON\n",
            "Haotian Zhang PERSON\n",
            "F Wang PERSON\n",
            "Wu PERSON\n",
            "2020 DATE\n",
            "PLATO ORG\n",
            "Dialogue ORG\n",
            "58th ORDINAL\n",
            "Computational Linguistics. ORG\n",
            "Online ORG\n",
            "85–96 CARDINAL\n",
            "2 CARDINAL\n",
            "F Wang PERSON\n",
            "H Wang PERSON\n",
            "W Wu PERSON\n",
            "Guo WORK_OF_ART\n",
            "Liu PERSON\n",
            "2021 DATE\n",
            "2 CARDINAL\n",
            "ACL-IJCNLP 2021 ORG\n",
            "Online ORG\n",
            "2513–2525 DATE\n",
            "3 CARDINAL\n",
            "J Camacho-Collados ORG\n",
            "Espinosa Anke PERSON\n",
            "L Neves GPE\n",
            "2020 DATE\n",
            "Benchmark PERSON\n",
            "Comparative Evaluation for Tweet Classification ORG\n",
            "2020 DATE\n",
            "Online ORG\n",
            "1644–1650 DATE\n",
            "4 CARDINAL\n",
            "] J Bi WORK_OF_ART\n",
            "K P Bennett ORG\n",
            "2003 DATE\n",
            "20th ORDINAL\n",
            "Intl ORG\n",
            "43–50 CARDINAL\n",
            "5 CARDINAL\n",
            "Brown PERSON\n",
            "B Mann PERSON\n",
            "N Ryder ORG\n",
            "Neelakantan GPE\n",
            "G Sastry ORG\n",
            "Askell ORG\n",
            "33 CARDINAL\n",
            "2020 DATE\n",
            "1877–1901 CARDINAL\n",
            "6 CARDINAL\n",
            "Y M Çetinkaya PRODUCT\n",
            "H Davulcu GPE\n",
            "2020 DATE\n",
            "10 CARDINAL\n",
            "1 CARDINAL\n",
            "2020 DATE\n",
            "1–21 CARDINAL\n",
            "7 CARDINAL\n",
            "C Delcea ORG\n",
            "F Tajariol PERSON\n",
            "2021 DATE\n",
            "The\n",
            "Longest Month DATE\n",
            "Analyzing COVID-19 Vaccination Opinions Dynamics ORG\n",
            "the Month DATE\n",
            "the First Vaccine Announcement ORG\n",
            "IEEE ORG\n",
            "9 CARDINAL\n",
            "2021 DATE\n",
            "33203–33223 CARDINAL\n",
            "8 CARDINAL\n",
            "C Brockett PERSON\n",
            "C Quirk ORG\n",
            "M Mitchell PERSON\n",
            "Gao PERSON\n",
            "Dolan ORG\n",
            "2015 DATE\n",
            "53rd ORDINAL\n",
            "Annual Meeting of the Assoc EVENT\n",
            "7th ORDINAL\n",
            "Intl Joint Conf ORG\n",
            "Natural Language\n",
            "Processing (Volume 2: Short Papers PRODUCT\n",
            "Association for Computational Linguistics ORG\n",
            "Beijing GPE\n",
            "China GPE\n",
            "445–450 GPE\n",
            "9 CARDINAL\n",
            "J Samuel PERSON\n",
            "2021 DATE\n",
            "144 CARDINAL\n",
            "2021 DATE\n",
            "113497 DATE\n",
            "10 CARDINAL\n",
            "S Mehri ORG\n",
            "J Bigham PERSON\n",
            "2019 DATE\n",
            "20th ORDINAL\n",
            "Association for Computational Linguistics ORG\n",
            "Stockholm GPE\n",
            "Sweden GPE\n",
            "379–391 CARDINAL\n",
            "5944 CARDINAL\n",
            "at least 20 CARDINAL\n",
            "9 CARDINAL\n",
            "COVID-19 PERSON\n",
            "10 CARDINAL\n",
            "Vaccines ORG\n",
            "9 CARDINAL\n",
            "COVID-19 PERSON\n",
            "10 CARDINAL\n",
            "Vaccines NORP\n",
            "12 CARDINAL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "htlppj86cFHE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}